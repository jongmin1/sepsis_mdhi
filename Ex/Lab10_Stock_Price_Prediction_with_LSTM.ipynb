{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Lab10_Stock_Price_Prediction_with_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkQQXRaaL2D8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "653af8e5-a233-4dcc-f669-87e56ec7430d"
      },
      "source": [
        "import pandas as pd\n",
        "import pandas_datareader.data as pdr\n",
        "import datetime\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import argparse\n",
        "from copy import deepcopy # Add Deepcopy for args\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "import seaborn as sns \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(torch.__version__)\n",
        "%matplotlib inline\n",
        "%pylab inline\n",
        "pylab.rcParams['figure.figsize'] = (15, 9)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.9.0+cu102\n",
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltMUKHqKoJ4i",
        "outputId": "79d9316e-020b-49c5-9db7-d15a13b36db4"
      },
      "source": [
        "!pip install yfinance"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting yfinance\n",
            "  Downloading https://files.pythonhosted.org/packages/85/13/5c0605a41d3d811ef508858d7fe75031fa324ec4fc620c4be01ddf90025d/yfinance-0.1.61.tar.gz\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.19.5)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from yfinance) (2.23.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.9)\n",
            "Collecting lxml>=4.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/c0/d0526314971fc661b083ab135747dc68446a3022686da8c16d25fcf6ef07/lxml-4.6.3-cp37-cp37m-manylinux2014_x86_64.whl (6.3MB)\n",
            "\u001b[K     |████████████████████████████████| 6.3MB 8.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2.8.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (2021.5.30)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24->yfinance) (1.15.0)\n",
            "Building wheels for collected packages: yfinance\n",
            "  Building wheel for yfinance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for yfinance: filename=yfinance-0.1.61-py2.py3-none-any.whl size=23818 sha256=463c7b7d7bba6f0b7df807dd8fd94868fcca77872fdd4940a78f116d4ad1915b\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/b3/31/b5f2bcf2e3fd3f42e5ca1a3d20ada27eae8cbda7de75a5a2a0\n",
            "Successfully built yfinance\n",
            "Installing collected packages: lxml, yfinance\n",
            "  Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "Successfully installed lxml-4.6.3 yfinance-0.1.61\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-koarehjL2D9"
      },
      "source": [
        "# Pandas Datareader Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPq2fR7ZL2D9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "27bc94ec-b486-4b5d-b0b9-27bba4acd094"
      },
      "source": [
        "import yfinance as yf\n",
        "import pandas_datareader.data as pdr\n",
        "\n",
        "yf.pdr_override()\n",
        "\n",
        "start = (2019, 5, 1)\n",
        "start = datetime.datetime(*start)\n",
        "end = datetime.date.today()\n",
        "\n",
        "google = pdr.get_data_yahoo('AAPL', data_source='yahoo', start=start, end=end)\n",
        "google"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2019-05-01</th>\n",
              "      <td>52.470001</td>\n",
              "      <td>53.827499</td>\n",
              "      <td>52.307499</td>\n",
              "      <td>52.630001</td>\n",
              "      <td>51.463013</td>\n",
              "      <td>259309200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-05-02</th>\n",
              "      <td>52.459999</td>\n",
              "      <td>53.162498</td>\n",
              "      <td>52.032501</td>\n",
              "      <td>52.287498</td>\n",
              "      <td>51.128105</td>\n",
              "      <td>127985200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-05-03</th>\n",
              "      <td>52.722500</td>\n",
              "      <td>52.959999</td>\n",
              "      <td>52.557499</td>\n",
              "      <td>52.937500</td>\n",
              "      <td>51.763695</td>\n",
              "      <td>83569600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-05-06</th>\n",
              "      <td>51.072498</td>\n",
              "      <td>52.209999</td>\n",
              "      <td>50.875000</td>\n",
              "      <td>52.119999</td>\n",
              "      <td>50.964329</td>\n",
              "      <td>129772400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-05-07</th>\n",
              "      <td>51.470001</td>\n",
              "      <td>51.855000</td>\n",
              "      <td>50.207500</td>\n",
              "      <td>50.715000</td>\n",
              "      <td>49.590477</td>\n",
              "      <td>155054800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-07-01</th>\n",
              "      <td>136.600006</td>\n",
              "      <td>137.330002</td>\n",
              "      <td>135.759995</td>\n",
              "      <td>137.270004</td>\n",
              "      <td>137.270004</td>\n",
              "      <td>52485800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-07-02</th>\n",
              "      <td>137.899994</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>137.750000</td>\n",
              "      <td>139.960007</td>\n",
              "      <td>139.960007</td>\n",
              "      <td>78852600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-07-06</th>\n",
              "      <td>140.070007</td>\n",
              "      <td>143.149994</td>\n",
              "      <td>140.070007</td>\n",
              "      <td>142.020004</td>\n",
              "      <td>142.020004</td>\n",
              "      <td>108181800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-07-07</th>\n",
              "      <td>143.539993</td>\n",
              "      <td>144.889999</td>\n",
              "      <td>142.660004</td>\n",
              "      <td>144.570007</td>\n",
              "      <td>144.570007</td>\n",
              "      <td>104911600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-07-08</th>\n",
              "      <td>141.580002</td>\n",
              "      <td>144.059998</td>\n",
              "      <td>140.669998</td>\n",
              "      <td>143.240005</td>\n",
              "      <td>143.240005</td>\n",
              "      <td>105410700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>552 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Open        High  ...   Adj Close     Volume\n",
              "Date                                ...                       \n",
              "2019-05-01   52.470001   53.827499  ...   51.463013  259309200\n",
              "2019-05-02   52.459999   53.162498  ...   51.128105  127985200\n",
              "2019-05-03   52.722500   52.959999  ...   51.763695   83569600\n",
              "2019-05-06   51.072498   52.209999  ...   50.964329  129772400\n",
              "2019-05-07   51.470001   51.855000  ...   49.590477  155054800\n",
              "...                ...         ...  ...         ...        ...\n",
              "2021-07-01  136.600006  137.330002  ...  137.270004   52485800\n",
              "2021-07-02  137.899994  140.000000  ...  139.960007   78852600\n",
              "2021-07-06  140.070007  143.149994  ...  142.020004  108181800\n",
              "2021-07-07  143.539993  144.889999  ...  144.570007  104911600\n",
              "2021-07-08  141.580002  144.059998  ...  143.240005  105410700\n",
              "\n",
              "[552 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sq6D8M7HL2D-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "31a9b51e-d1c4-4df3-b91d-6430693ea3d5"
      },
      "source": [
        "google.Low.plot(grid=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f33fcb40e90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0k8xkTCL2D-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9e347b0-77b5-4123-89e3-4d66e3803059"
      },
      "source": [
        "google.tail()\n",
        "print(google.isna().sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Open         0\n",
            "High         0\n",
            "Low          0\n",
            "Close        0\n",
            "Adj Close    0\n",
            "Volume       0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Airo6YjML2D-"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rWyVS5oL2D-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "16912d3a-9ae3-482d-fbb7-e9ff288ab6a6"
      },
      "source": [
        "class StockDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, symbol, x_frames, y_frames, start, end):\n",
        "        \n",
        "        self.symbol = symbol\n",
        "        self.x_frames = x_frames\n",
        "        self.y_frames = y_frames\n",
        "        \n",
        "        self.start = datetime.datetime(*start)\n",
        "        self.end = datetime.datetime(*end)\n",
        "\n",
        "        self.data = pdr.get_data_yahoo('AAPL', data_source='yahoo', start=self.start, end=self.end)\n",
        "        print(self.data.isna().sum())\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data) - (self.x_frames + self.y_frames) + 1\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        idx += self.x_frames\n",
        "        data = self.data.iloc[idx-self.x_frames:idx+self.y_frames]\n",
        "        data = data[['High', 'Low', 'Open', 'Close', 'Adj Close', 'Volume']]\n",
        "        data = data.apply(lambda x: np.log(x+1) - np.log(x[self.x_frames-1]+1))\n",
        "        data = data.values\n",
        "        X = data[:self.x_frames]\n",
        "        y = data[self.x_frames:]\n",
        "        \n",
        "        return X, y\n",
        "\n",
        "\n",
        "'''\n",
        "dataset = StockDatset('AAPL', 10, 5, start, end)\n",
        "dataloader = DataLoader(dataset, 2)\n",
        "for X, y in dataloader:\n",
        "  print(X.shape, y.shape)\n",
        "  break\n",
        "\n",
        "\n",
        "# -> [2, 10, 6] [2, 5, 6]; [batch size, 최근 10일, 6개의 features], [batch size, 이후 10일, 6개의 features]\n",
        "# LSTM에 넣고, X 넣고, y를 예측하기\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ndataset = StockDatset('AAPL', 10, 5, start, end)\\ndataloader = DataLoader(dataset, 2)\\nfor X, y in dataloader:\\n  print(X.shape, y.shape)\\n  break\\n\\n\\n# -> [2, 10, 6] [2, 5, 6]; [batch size, 최근 10일, 6개의 features], [batch size, 이후 10일, 6개의 features]\\n# LSTM에 넣고, X 넣고, y를 예측하기\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpzHNDglL2D_"
      },
      "source": [
        "# Model Define"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUU2vX-dL2EA"
      },
      "source": [
        "class LSTM(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers, batch_size, dropout, use_bn):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.input_dim = input_dim \n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        self.dropout = dropout\n",
        "        self.use_bn = use_bn \n",
        "        \n",
        "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers)\n",
        "        self.hidden = self.init_hidden()\n",
        "        self.regressor = self.make_regressor()\n",
        "        \n",
        "    def init_hidden(self):\n",
        "        return (torch.zeros(self.num_layers, self.batch_size, self.hidden_dim),\n",
        "                torch.zeros(self.num_layers, self.batch_size, self.hidden_dim))\n",
        "    \n",
        "    def make_regressor(self):\n",
        "        layers = []\n",
        "        if self.use_bn:\n",
        "            layers.append(nn.BatchNorm1d(self.hidden_dim))\n",
        "        layers.append(nn.Dropout(self.dropout))\n",
        "        \n",
        "        layers.append(nn.Linear(self.hidden_dim, self.hidden_dim // 2))\n",
        "        layers.append(nn.ReLU())\n",
        "        layers.append(nn.Linear(self.hidden_dim // 2, self.output_dim))\n",
        "        regressor = nn.Sequential(*layers)\n",
        "        return regressor\n",
        "    \n",
        "    def forward(self, x):\n",
        "        lstm_out, self.hidden = self.lstm(x, self.hidden)\n",
        "        y_pred = self.regressor(lstm_out[-1].view(self.batch_size, -1))\n",
        "        return y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgPKtrnvL2EA"
      },
      "source": [
        "def metric(y_pred, y_true):\n",
        "    print('y_pred: ',y_pred[0])\n",
        "    print('y_true:', y_true[0])\n",
        "    print(len(y_true))\n",
        "    perc_y_pred = np.exp(y_pred.cpu().detach().numpy())\n",
        "    perc_y_true = np.exp(y_true.cpu().detach().numpy())\n",
        "    mae = mean_absolute_error(perc_y_true, perc_y_pred, multioutput='raw_values')\n",
        "    return mae*100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEhYhYySoc8Q"
      },
      "source": [
        "cnt  = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ivD_zhHL2EB"
      },
      "source": [
        "# Train, Validate, Test "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4CCx_0XL2EB"
      },
      "source": [
        "def train(model, partition, optimizer, loss_fn, args):\n",
        "    trainloader = DataLoader(partition['train'], \n",
        "                             batch_size=args.batch_size, \n",
        "                             shuffle=True, drop_last=True)\n",
        "    model.train()\n",
        "    model.zero_grad()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    train_acc = 0.0\n",
        "    train_loss = 0.0\n",
        "    for i, (X, y) in enumerate(trainloader):\n",
        "        # print('@@@@@@@@@@@@')\n",
        "        # print(X)\n",
        "        # print('@@@@@@@@@@@@@@@')\n",
        "\n",
        "        global cnt\n",
        "        cnt += len(X)\n",
        "        # print(cnt)\n",
        "\n",
        "        X = X.transpose(0, 1).float().to(args.device)\n",
        "        y_true = y[:, :, 3].float().to(args.device)\n",
        "        #print(torch.max(X[:, :, 3]), torch.max(y_true))\n",
        "\n",
        "        model.zero_grad()\n",
        "        optimizer.zero_grad()\n",
        "        model.hidden = [hidden.to(args.device) for hidden in model.init_hidden()]\n",
        "\n",
        "        y_pred = model(X)\n",
        "        loss = loss_fn(y_pred.view(-1), y_true.view(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        train_acc += metric(y_pred, y_true)[0]\n",
        "\n",
        "    train_loss = train_loss / len(trainloader)\n",
        "    train_acc = train_acc / len(trainloader)\n",
        "    return model, train_loss, train_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpTQQXW5L2EB"
      },
      "source": [
        "def validate(model, partition, loss_fn, args):\n",
        "    valloader = DataLoader(partition['val'], \n",
        "                           batch_size=args.batch_size, \n",
        "                           shuffle=False, drop_last=True)\n",
        "    model.eval()\n",
        "\n",
        "    val_acc = 0.0\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for i, (X, y) in enumerate(valloader):\n",
        "\n",
        "            X = X.transpose(0, 1).float().to(args.device)\n",
        "            y_true = y[:, :, 3].float().to(args.device)\n",
        "            model.hidden = [hidden.to(args.device) for hidden in model.init_hidden()]\n",
        "\n",
        "            y_pred = model(X)\n",
        "            loss = loss_fn(y_pred.view(-1), y_true.view(-1))\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            val_acc += metric(y_pred, y_true)[0]\n",
        "\n",
        "    val_loss = val_loss / len(valloader)\n",
        "    val_acc = val_acc / len(valloader)\n",
        "    return val_loss, val_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GSkcG59L2EB"
      },
      "source": [
        "def test(model, partition, args):\n",
        "    testloader = DataLoader(partition['test'], \n",
        "                           batch_size=args.batch_size, \n",
        "                           shuffle=False, drop_last=True)\n",
        "    model.eval()\n",
        "\n",
        "    test_acc = 0.0\n",
        "    with torch.no_grad():\n",
        "        for i, (X, y) in enumerate(testloader):\n",
        "\n",
        "            X = X.transpose(0, 1).float().to(args.device)\n",
        "            y_true = y[:, :, 3].float().to(args.device)\n",
        "            model.hidden = [hidden.to(args.device) for hidden in model.init_hidden()]\n",
        "\n",
        "            y_pred = model(X)\n",
        "            test_acc += metric(y_pred, y_true)[0]\n",
        "\n",
        "    test_acc = test_acc / len(testloader)\n",
        "    return test_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKaS1TDmL2EC"
      },
      "source": [
        "def experiment(partition, args):\n",
        "\n",
        "    model = LSTM(args.input_dim, args.hid_dim, args.y_frames, args.n_layers, args.batch_size, args.dropout, args.use_bn)\n",
        "    model.to(args.device)\n",
        "    loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "    loss_fn = nn.MSELoss()\n",
        "    if args.optim == 'SGD':\n",
        "        optimizer = optim.RMSprop(model.parameters(), lr=args.lr, weight_decay=args.l2)\n",
        "    elif args.optim == 'RMSprop':\n",
        "        optimizer = optim.RMSprop(model.parameters(), lr=args.lr, weight_decay=args.l2)\n",
        "    elif args.optim == 'Adam':\n",
        "        optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.l2)\n",
        "    else:\n",
        "        raise ValueError('In-valid optimizer choice')\n",
        "    \n",
        "    # ===== List for epoch-wise data ====== #\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accs = []\n",
        "    val_accs = []\n",
        "    # ===================================== #\n",
        "        \n",
        "    for epoch in range(args.epoch):  # loop over the dataset multiple times\n",
        "        ts = time.time()\n",
        "        model, train_loss, train_acc = train(model, partition, optimizer, loss_fn, args)\n",
        "        val_loss, val_acc = validate(model, partition, loss_fn, args)\n",
        "        te = time.time()\n",
        "        \n",
        "        # ====== Add Epoch Data ====== #\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        train_accs.append(train_acc)\n",
        "        val_accs.append(val_acc)\n",
        "        # ============================ #\n",
        "        \n",
        "        print('Epoch {}, Acc(train/val): {:2.2f}/{:2.2f}, Loss(train/val) {:2.5f}/{:2.5f}. Took {:2.2f} sec'.format(epoch, train_acc, val_acc, train_loss, val_loss, te-ts))\n",
        "        \n",
        "    test_acc = test(model, partition, args)    \n",
        "    \n",
        "    # ======= Add Result to Dictionary ======= #\n",
        "    result = {}\n",
        "    result['train_losses'] = train_losses\n",
        "    result['val_losses'] = val_losses\n",
        "    result['train_accs'] = train_accs\n",
        "    result['val_accs'] = val_accs\n",
        "    result['train_acc'] = train_acc\n",
        "    result['val_acc'] = val_acc\n",
        "    result['test_acc'] = test_acc\n",
        "    return vars(args), result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwe-9ofgL2EC"
      },
      "source": [
        "# Manage Experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oviUxSiL2EC"
      },
      "source": [
        "import hashlib\n",
        "import json\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import pandas as pd\n",
        "\n",
        "def save_exp_result(setting, result):\n",
        "    exp_name = setting['exp_name']\n",
        "    del setting['epoch']\n",
        "\n",
        "    hash_key = hashlib.sha1(str(setting).encode()).hexdigest()[:6]\n",
        "    filename = './results/{}-{}.json'.format(exp_name, hash_key)\n",
        "    result.update(setting)\n",
        "    with open(filename, 'w') as f:\n",
        "        json.dump(result, f)\n",
        "\n",
        "    \n",
        "def load_exp_result(exp_name):\n",
        "    dir_path = './results'\n",
        "    filenames = [f for f in listdir(dir_path) if isfile(join(dir_path, f)) if '.json' in f]\n",
        "    list_result = []\n",
        "    for filename in filenames:\n",
        "        if exp_name in filename:\n",
        "            with open(join(dir_path, filename), 'r') as infile:\n",
        "                results = json.load(infile)\n",
        "                list_result.append(results)\n",
        "    df = pd.DataFrame(list_result) # .drop(columns=[])\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wX7YbwUNL2EC"
      },
      "source": [
        "\n",
        "def plot_acc(var1, var2, df):\n",
        "\n",
        "    fig, ax = plt.subplots(1, 3)\n",
        "    fig.set_size_inches(15, 6)\n",
        "    sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
        "\n",
        "    sns.barplot(x=var1, y='train_acc', hue=var2, data=df, ax=ax[0])\n",
        "    sns.barplot(x=var1, y='val_acc', hue=var2, data=df, ax=ax[1])\n",
        "    sns.barplot(x=var1, y='test_acc', hue=var2, data=df, ax=ax[2])\n",
        "    \n",
        "    ax[0].set_title('Train Accuracy')\n",
        "    ax[1].set_title('Validation Accuracy')\n",
        "    ax[2].set_title('Test Accuracy')\n",
        "\n",
        "    \n",
        "def plot_loss_variation(var1, var2, df, **kwargs):\n",
        "\n",
        "    list_v1 = df[var1].unique()\n",
        "    list_v2 = df[var2].unique()\n",
        "    list_data = []\n",
        "\n",
        "    for value1 in list_v1:\n",
        "        for value2 in list_v2:\n",
        "            row = df.loc[df[var1]==value1]\n",
        "            row = row.loc[df[var2]==value2]\n",
        "\n",
        "            train_losses = list(row.train_losses)[0]\n",
        "            val_losses = list(row.val_losses)[0]\n",
        "\n",
        "            for epoch, train_loss in enumerate(train_losses):\n",
        "                list_data.append({'type':'train', 'loss':train_loss, 'epoch':epoch, var1:value1, var2:value2})\n",
        "            for epoch, val_loss in enumerate(val_losses):\n",
        "                list_data.append({'type':'val', 'loss':val_loss, 'epoch':epoch, var1:value1, var2:value2})\n",
        "\n",
        "    df = pd.DataFrame(list_data)\n",
        "    g = sns.FacetGrid(df, row=var2, col=var1, hue='type', **kwargs)\n",
        "    g = g.map(plt.plot, 'epoch', 'loss', marker='.')\n",
        "    g.add_legend()\n",
        "    g.fig.suptitle('Train loss vs Val loss')\n",
        "    plt.subplots_adjust(top=0.89) # 만약 Title이 그래프랑 겹친다면 top 값을 조정해주면 됩니다! 함수 인자로 받으면 그래프마다 조절할 수 있겠죠?\n",
        "\n",
        "\n",
        "def plot_acc_variation(var1, var2, df, **kwargs):\n",
        "    list_v1 = df[var1].unique()\n",
        "    list_v2 = df[var2].unique()\n",
        "    list_data = []\n",
        "\n",
        "    for value1 in list_v1:\n",
        "        for value2 in list_v2:\n",
        "            row = df.loc[df[var1]==value1]\n",
        "            row = row.loc[df[var2]==value2]\n",
        "\n",
        "            train_accs = list(row.train_accs)[0]\n",
        "            val_accs = list(row.val_accs)[0]\n",
        "            test_acc = list(row.test_acc)[0]\n",
        "\n",
        "            for epoch, train_acc in enumerate(train_accs):\n",
        "                list_data.append({'type':'train', 'Acc':train_acc, 'test_acc':test_acc, 'epoch':epoch, var1:value1, var2:value2})\n",
        "            for epoch, val_acc in enumerate(val_accs):\n",
        "                list_data.append({'type':'val', 'Acc':val_acc, 'test_acc':test_acc, 'epoch':epoch, var1:value1, var2:value2})\n",
        "\n",
        "    df = pd.DataFrame(list_data)\n",
        "    g = sns.FacetGrid(df, row=var2, col=var1, hue='type', **kwargs)\n",
        "    g = g.map(plt.plot, 'epoch', 'Acc', marker='.')\n",
        "\n",
        "    def show_acc(x, y, metric, **kwargs):\n",
        "        plt.scatter(x, y, alpha=0.3, s=1)\n",
        "        metric = \"Test Acc: {:1.3f}\".format(list(metric.values)[0])\n",
        "        plt.text(0.05, 0.95, metric,  horizontalalignment='left', verticalalignment='center', transform=plt.gca().transAxes, bbox=dict(facecolor='yellow', alpha=0.5, boxstyle=\"round,pad=0.1\"))\n",
        "    g = g.map(show_acc, 'epoch', 'Acc', 'test_acc')\n",
        "\n",
        "    g.add_legend()\n",
        "    g.fig.suptitle('Train Accuracy vs Val Accuracy')\n",
        "    plt.subplots_adjust(top=0.89)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPMUo-jEL2ED",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f1f3da9f-b98b-4ad2-d43c-aa13ab5c609a"
      },
      "source": [
        "# ====== Random Seed Initialization ====== #\n",
        "seed = 666\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "args = parser.parse_args(\"\")\n",
        "args.exp_name = \"exp1_lr\"\n",
        "args.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# ====== Data Loading ====== #\n",
        "args.symbol = '028050.KS'\n",
        "args.batch_size = 128\n",
        "args.x_frames = 5\n",
        "args.y_frames = 5\n",
        "\n",
        "# ====== Model Capacity ===== #\n",
        "args.input_dim = 6\n",
        "args.hid_dim = 50\n",
        "args.n_layers = 2\n",
        "\n",
        "# ====== Regularization ======= #\n",
        "args.l2 = 0.00001\n",
        "args.dropout = 0.0\n",
        "args.use_bn = True\n",
        "\n",
        "# ====== Optimizer & Training ====== #\n",
        "args.optim = 'RMSprop' #'RMSprop' #SGD, RMSprop, ADAM...\n",
        "args.lr = 0.0001\n",
        "args.epoch = 2\n",
        "\n",
        "\n",
        "# ====== Experiment Variable ====== #\n",
        "name_var1 = 'lr'\n",
        "name_var2 = 'n_layers'\n",
        "list_var1 = [0.001, 0.0001, 0.00001]\n",
        "list_var2 = [1,2,3]\n",
        "\n",
        "trainset = StockDataset(args.symbol, args.x_frames, args.y_frames, (2000,1,1), (2012,1,1))\n",
        "valset = StockDataset(args.symbol, args.x_frames, args.y_frames, (2012,1,1), (2016,1,1))\n",
        "testset = StockDataset(args.symbol, args.x_frames, args.y_frames, (2016,1,1), (2019,2,1))\n",
        "partition = {'train': trainset, 'val':valset, 'test':testset}\n",
        "\n",
        "print(len(trainset.data))\n",
        "\n",
        "for var1 in list_var1:\n",
        "    cnt = 0\n",
        "    for var2 in list_var2:\n",
        "        setattr(args, name_var1, var1)\n",
        "        setattr(args, name_var2, var2)\n",
        "        print(args)\n",
        "                \n",
        "        setting, result = experiment(partition, deepcopy(args))\n",
        "        # save_exp_result(setting, result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "Open         0\n",
            "High         0\n",
            "Low          0\n",
            "Close        0\n",
            "Adj Close    0\n",
            "Volume       0\n",
            "dtype: int64\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Open         0\n",
            "High         0\n",
            "Low          0\n",
            "Close        0\n",
            "Adj Close    0\n",
            "Volume       0\n",
            "dtype: int64\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Open         0\n",
            "High         0\n",
            "Low          0\n",
            "Close        0\n",
            "Adj Close    0\n",
            "Volume       0\n",
            "dtype: int64\n",
            "3019\n",
            "Namespace(batch_size=128, device='cpu', dropout=0.0, epoch=2, exp_name='exp1_lr', hid_dim=50, input_dim=6, l2=1e-05, lr=0.001, n_layers=1, optim='RMSprop', symbol='028050.KS', use_bn=True, x_frames=5, y_frames=5)\n",
            "y_pred:  tensor([-0.1998,  0.1864,  0.2985, -0.1037, -0.0410], grad_fn=<SelectBackward>)\n",
            "y_true: tensor([0.0025, 0.0080, 0.0172, 0.0225, 0.0256])\n",
            "128\n",
            "y_pred:  tensor([ 0.0107,  0.0665,  0.0545, -0.1135, -0.0188], grad_fn=<SelectBackward>)\n",
            "y_true: tensor([ 0.0030, -0.0003, -0.0096, -0.0042,  0.0005])\n",
            "128\n",
            "y_pred:  tensor([ 0.0109,  0.1261,  0.1605, -0.0582,  0.0132], grad_fn=<SelectBackward>)\n",
            "y_true: tensor([0.0012, 0.0061, 0.0173, 0.0246, 0.0157])\n",
            "128\n",
            "y_pred:  tensor([0.0930, 0.0863, 0.0294, 0.1590, 0.2124], grad_fn=<SelectBackward>)\n",
            "y_true: tensor([-0.0069, -0.0221,  0.0114,  0.0258,  0.0200])\n",
            "128\n",
            "y_pred:  tensor([ 0.0866, -0.0352, -0.0010, -0.0636,  0.0895], grad_fn=<SelectBackward>)\n",
            "y_true: tensor([0.0201, 0.0292, 0.0006, 0.0216, 0.0203])\n",
            "128\n",
            "y_pred:  tensor([0.0947, 0.0869, 0.0650, 0.1209, 0.0434], grad_fn=<SelectBackward>)\n",
            "y_true: tensor([-0.0246,  0.0014, -0.0247, -0.0017, -0.0139])\n",
            "128\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-2f660cd72c0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0msetting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;31m# save_exp_result(setting, result)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-fb0be02f0292>\u001b[0m in \u001b[0;36mexperiment\u001b[0;34m(partition, args)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# loop over the dataset multiple times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mte\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-4c7416f28f3b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, partition, optimizer, loss_fn, args)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;31m# print('@@@@@@@@@@@@')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# print(X)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-efecab00183b>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_frames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_frames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'High'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Low'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Open'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Close'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Adj Close'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Volume'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_frames\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_frames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   7550\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7551\u001b[0m         )\n\u001b[0;32m-> 7552\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7554\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DataFrame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mResType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Index\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mwrap_results\u001b[0;34m(self, results, res_index)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;31m# see if we can infer the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_results_for_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;31m# dict of scalars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mwrap_results_for_axis\u001b[0;34m(self, results, res_index)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"arrays must all be same length\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m         \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_iterable_to_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;31m# GH#24096 need copy to be deep for datetime64tz case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data, dtype, copy, name, tupleize_cols, **kwargs)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;31m# other iterable of some kind\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray_tuplesafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     \"\"\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data, dtype, copy, name, tupleize_cols, **kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                     return cls(\n\u001b[0;32m--> 404\u001b[0;31m                         \u001b[0mnew_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m                     )\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data, dtype, copy, name, tupleize_cols, **kwargs)\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;31m# should not be coerced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;31m# GH 11836\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_cast_with_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m                 \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m  \u001b[0;31m# TODO: maybe not for object?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_maybe_cast_with_dtype\u001b[0;34m(data, dtype, copy)\u001b[0m\n\u001b[1;32m   5694\u001b[0m     \u001b[0;31m# GH 11836\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5695\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_integer_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5696\u001b[0;31m         \u001b[0minferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5697\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minferred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"integer\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5698\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_cast_to_integer_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.infer_dtype\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib._try_infer_map\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/_dtype.py\u001b[0m in \u001b[0;36m_name_get\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_name_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m     \u001b[0;31m# provides dtype.name.__get__, documented as returning a \"bit name\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSjEK5vbL2ED"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8dOPWYNL2ED"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}