{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gqlpt6bO5ZzD",
    "outputId": "04886b08-66a6-4076-c8a9-7d78da19622b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0+cu111\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['e', 'seed', 'partition', 'test']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import argparse\n",
    "from copy import deepcopy\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_absolute_error\n",
    "from sklearn.preprocessing import binarize\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score,f1_score ,roc_auc_score, explained_variance_score, mean_squared_error, r2_score, plot_roc_curve\n",
    "\n",
    "print(torch.__version__)\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (15, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTdQQjnK5ZzF"
   },
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = pd.read_csv('./sofa/sofa_total_ifz_v2.csv', index_col='starttime')\n",
    "train_df = pd.read_csv('./sofa/sofa_train_ifz_v2.csv', index_col='starttime')\n",
    "valid_df = pd.read_csv('./sofa/sofa_valid_ifz_v2.csv', index_col='starttime')\n",
    "test_df = pd.read_csv('./sofa/sofa_test_ifz_v2.csv', index_col='starttime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>stay_id</th>\n",
       "      <th>hr</th>\n",
       "      <th>sbp</th>\n",
       "      <th>dbp</th>\n",
       "      <th>gcs_min</th>\n",
       "      <th>respiratory_rate</th>\n",
       "      <th>abp_mean</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>temperature</th>\n",
       "      <th>hemoglobin</th>\n",
       "      <th>hematocrit</th>\n",
       "      <th>sao2</th>\n",
       "      <th>fio2</th>\n",
       "      <th>urine</th>\n",
       "      <th>wbc</th>\n",
       "      <th>bun</th>\n",
       "      <th>bilirubin_max</th>\n",
       "      <th>creatinine_max</th>\n",
       "      <th>pao2fio2ratio_vent</th>\n",
       "      <th>platelet_min</th>\n",
       "      <th>dobutamine</th>\n",
       "      <th>dopamine</th>\n",
       "      <th>epinephrine</th>\n",
       "      <th>norepinephrine</th>\n",
       "      <th>vasopressin</th>\n",
       "      <th>pH</th>\n",
       "      <th>potassium</th>\n",
       "      <th>bicarbonate</th>\n",
       "      <th>lactate</th>\n",
       "      <th>icd_event</th>\n",
       "      <th>age</th>\n",
       "      <th>is_infection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.405992e+06</td>\n",
       "      <td>1.405992e+06</td>\n",
       "      <td>1.405992e+06</td>\n",
       "      <td>1.405992e+06</td>\n",
       "      <td>1.405992e+06</td>\n",
       "      <td>1.405992e+06</td>\n",
       "      <td>1.405992e+06</td>\n",
       "      <td>1.405992e+06</td>\n",
       "      <td>1.405992e+06</td>\n",
       "      <td>1.405992e+06</td>\n",
       "      <td>1.405992e+06</td>\n",
       "      <td>1.405992e+06</td>\n",
       "      <td>1.405992e+06</td>\n",
       "      <td>1.405992e+06</td>\n",
       "      <td>1.405992e+06</td>\n",
       "      <td>1405992.0</td>\n",
       "      <td>1.405992e+06</td>\n",
       "      <td>1.405992e+06</td>\n",
       "      <td>1.405992e+06</td>\n",
       "      <td>1.405992e+06</td>\n",
       "      <td>1.405992e+06</td>\n",
       "      <td>1.405992e+06</td>\n",
       "      <td>1.405992e+06</td>\n",
       "      <td>1.405992e+06</td>\n",
       "      <td>1.405992e+06</td>\n",
       "      <td>1.405992e+06</td>\n",
       "      <td>1405992.0</td>\n",
       "      <td>1.405992e+06</td>\n",
       "      <td>1.405992e+06</td>\n",
       "      <td>1.405992e+06</td>\n",
       "      <td>1.405992e+06</td>\n",
       "      <td>1.405992e+06</td>\n",
       "      <td>1.405992e+06</td>\n",
       "      <td>1.405992e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.500207e+07</td>\n",
       "      <td>2.498522e+07</td>\n",
       "      <td>3.498904e+07</td>\n",
       "      <td>1.248151e+01</td>\n",
       "      <td>1.169085e+02</td>\n",
       "      <td>6.269719e+01</td>\n",
       "      <td>1.402981e+01</td>\n",
       "      <td>1.894550e+01</td>\n",
       "      <td>2.772064e+01</td>\n",
       "      <td>8.524457e+01</td>\n",
       "      <td>3.466858e+01</td>\n",
       "      <td>8.346573e+00</td>\n",
       "      <td>2.560511e+01</td>\n",
       "      <td>1.068130e+02</td>\n",
       "      <td>5.820530e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.337892e+01</td>\n",
       "      <td>9.132403e+01</td>\n",
       "      <td>6.417746e-01</td>\n",
       "      <td>1.143500e+00</td>\n",
       "      <td>7.044163e+01</td>\n",
       "      <td>1.522581e+02</td>\n",
       "      <td>6.184246e-03</td>\n",
       "      <td>1.024757e-02</td>\n",
       "      <td>1.982301e-02</td>\n",
       "      <td>9.811080e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.985607e+00</td>\n",
       "      <td>3.386056e+00</td>\n",
       "      <td>1.916074e+01</td>\n",
       "      <td>8.410696e-01</td>\n",
       "      <td>1.439837e-01</td>\n",
       "      <td>6.516724e+01</td>\n",
       "      <td>7.112416e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.888587e+06</td>\n",
       "      <td>2.884422e+06</td>\n",
       "      <td>2.888226e+06</td>\n",
       "      <td>3.822103e+01</td>\n",
       "      <td>2.358109e+01</td>\n",
       "      <td>1.612615e+01</td>\n",
       "      <td>2.876355e+00</td>\n",
       "      <td>5.557298e+00</td>\n",
       "      <td>9.067290e+01</td>\n",
       "      <td>1.826582e+01</td>\n",
       "      <td>8.751936e+00</td>\n",
       "      <td>4.506070e+00</td>\n",
       "      <td>1.332922e+01</td>\n",
       "      <td>8.364655e+03</td>\n",
       "      <td>1.841357e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.109875e+03</td>\n",
       "      <td>6.697755e+03</td>\n",
       "      <td>2.467048e+00</td>\n",
       "      <td>1.278898e+00</td>\n",
       "      <td>1.358318e+02</td>\n",
       "      <td>1.120071e+02</td>\n",
       "      <td>7.839646e-02</td>\n",
       "      <td>1.007103e-01</td>\n",
       "      <td>1.393918e-01</td>\n",
       "      <td>2.974645e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.677374e+00</td>\n",
       "      <td>1.721744e+00</td>\n",
       "      <td>9.829090e+00</td>\n",
       "      <td>1.126053e+00</td>\n",
       "      <td>3.510734e-01</td>\n",
       "      <td>1.650639e+01</td>\n",
       "      <td>2.665964e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000122e+07</td>\n",
       "      <td>2.000081e+07</td>\n",
       "      <td>3.000015e+07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.350000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.800000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.249584e+07</td>\n",
       "      <td>2.248994e+07</td>\n",
       "      <td>3.248486e+07</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>1.030000e+02</td>\n",
       "      <td>5.500000e+01</td>\n",
       "      <td>1.460000e+01</td>\n",
       "      <td>1.500000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.200000e+01</td>\n",
       "      <td>3.650000e+01</td>\n",
       "      <td>7.620000e+00</td>\n",
       "      <td>2.390000e+01</td>\n",
       "      <td>9.500000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.947826e+00</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.450000e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.300000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.444444e+00</td>\n",
       "      <td>1.790909e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.500000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.500225e+07</td>\n",
       "      <td>2.497620e+07</td>\n",
       "      <td>3.498331e+07</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>1.150000e+02</td>\n",
       "      <td>6.200000e+01</td>\n",
       "      <td>1.500000e+01</td>\n",
       "      <td>1.800000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.400000e+01</td>\n",
       "      <td>3.678000e+01</td>\n",
       "      <td>9.600000e+00</td>\n",
       "      <td>2.924615e+01</td>\n",
       "      <td>9.700000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.361538e+00</td>\n",
       "      <td>1.616667e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.440000e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.543913e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.274000e+00</td>\n",
       "      <td>3.971429e+00</td>\n",
       "      <td>2.233333e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.700000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.751798e+07</td>\n",
       "      <td>2.747728e+07</td>\n",
       "      <td>3.748522e+07</td>\n",
       "      <td>1.800000e+01</td>\n",
       "      <td>1.310000e+02</td>\n",
       "      <td>7.100000e+01</td>\n",
       "      <td>1.500000e+01</td>\n",
       "      <td>2.200000e+01</td>\n",
       "      <td>6.973855e+01</td>\n",
       "      <td>9.700000e+01</td>\n",
       "      <td>3.711000e+01</td>\n",
       "      <td>1.130000e+01</td>\n",
       "      <td>3.417826e+01</td>\n",
       "      <td>9.900000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.345000e+01</td>\n",
       "      <td>2.800000e+01</td>\n",
       "      <td>4.000000e-01</td>\n",
       "      <td>1.300000e+00</td>\n",
       "      <td>8.508852e+01</td>\n",
       "      <td>2.233466e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.390000e+00</td>\n",
       "      <td>4.392308e+00</td>\n",
       "      <td>2.500000e+01</td>\n",
       "      <td>1.500000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.800000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.999999e+07</td>\n",
       "      <td>2.999983e+07</td>\n",
       "      <td>3.999981e+07</td>\n",
       "      <td>8.768000e+03</td>\n",
       "      <td>2.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.500000e+01</td>\n",
       "      <td>5.000000e+01</td>\n",
       "      <td>8.810600e+04</td>\n",
       "      <td>2.000000e+02</td>\n",
       "      <td>4.230000e+01</td>\n",
       "      <td>2.070000e+01</td>\n",
       "      <td>5.970000e+01</td>\n",
       "      <td>9.765430e+06</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.999990e+05</td>\n",
       "      <td>9.999990e+05</td>\n",
       "      <td>4.000000e+01</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>1.990000e+03</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.760000e+00</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>4.000000e+01</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.020000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         subject_id       hadm_id       stay_id            hr           sbp  \\\n",
       "count  1.405992e+06  1.405992e+06  1.405992e+06  1.405992e+06  1.405992e+06   \n",
       "mean   1.500207e+07  2.498522e+07  3.498904e+07  1.248151e+01  1.169085e+02   \n",
       "std    2.888587e+06  2.884422e+06  2.888226e+06  3.822103e+01  2.358109e+01   \n",
       "min    1.000122e+07  2.000081e+07  3.000015e+07  0.000000e+00  0.000000e+00   \n",
       "25%    1.249584e+07  2.248994e+07  3.248486e+07  6.000000e+00  1.030000e+02   \n",
       "50%    1.500225e+07  2.497620e+07  3.498331e+07  1.200000e+01  1.150000e+02   \n",
       "75%    1.751798e+07  2.747728e+07  3.748522e+07  1.800000e+01  1.310000e+02   \n",
       "max    1.999999e+07  2.999983e+07  3.999981e+07  8.768000e+03  2.000000e+02   \n",
       "\n",
       "                dbp       gcs_min  respiratory_rate      abp_mean  \\\n",
       "count  1.405992e+06  1.405992e+06      1.405992e+06  1.405992e+06   \n",
       "mean   6.269719e+01  1.402981e+01      1.894550e+01  2.772064e+01   \n",
       "std    1.612615e+01  2.876355e+00      5.557298e+00  9.067290e+01   \n",
       "min    0.000000e+00  0.000000e+00      0.000000e+00 -1.350000e+02   \n",
       "25%    5.500000e+01  1.460000e+01      1.500000e+01  0.000000e+00   \n",
       "50%    6.200000e+01  1.500000e+01      1.800000e+01  0.000000e+00   \n",
       "75%    7.100000e+01  1.500000e+01      2.200000e+01  6.973855e+01   \n",
       "max    1.000000e+02  1.500000e+01      5.000000e+01  8.810600e+04   \n",
       "\n",
       "         heart_rate   temperature    hemoglobin    hematocrit          sao2  \\\n",
       "count  1.405992e+06  1.405992e+06  1.405992e+06  1.405992e+06  1.405992e+06   \n",
       "mean   8.524457e+01  3.466858e+01  8.346573e+00  2.560511e+01  1.068130e+02   \n",
       "std    1.826582e+01  8.751936e+00  4.506070e+00  1.332922e+01  8.364655e+03   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    7.200000e+01  3.650000e+01  7.620000e+00  2.390000e+01  9.500000e+01   \n",
       "50%    8.400000e+01  3.678000e+01  9.600000e+00  2.924615e+01  9.700000e+01   \n",
       "75%    9.700000e+01  3.711000e+01  1.130000e+01  3.417826e+01  9.900000e+01   \n",
       "max    2.000000e+02  4.230000e+01  2.070000e+01  5.970000e+01  9.765430e+06   \n",
       "\n",
       "               fio2      urine           wbc           bun  bilirubin_max  \\\n",
       "count  1.405992e+06  1405992.0  1.405992e+06  1.405992e+06   1.405992e+06   \n",
       "mean   5.820530e+00        0.0  8.337892e+01  9.132403e+01   6.417746e-01   \n",
       "std    1.841357e+01        0.0  7.109875e+03  6.697755e+03   2.467048e+00   \n",
       "min    0.000000e+00        0.0  0.000000e+00  0.000000e+00   0.000000e+00   \n",
       "25%    0.000000e+00        0.0  4.947826e+00  9.000000e+00   0.000000e+00   \n",
       "50%    0.000000e+00        0.0  9.361538e+00  1.616667e+01   0.000000e+00   \n",
       "75%    0.000000e+00        0.0  1.345000e+01  2.800000e+01   4.000000e-01   \n",
       "max    1.000000e+02        0.0  9.999990e+05  9.999990e+05   4.000000e+01   \n",
       "\n",
       "       creatinine_max  pao2fio2ratio_vent  platelet_min    dobutamine  \\\n",
       "count    1.405992e+06        1.405992e+06  1.405992e+06  1.405992e+06   \n",
       "mean     1.143500e+00        7.044163e+01  1.522581e+02  6.184246e-03   \n",
       "std      1.278898e+00        1.358318e+02  1.120071e+02  7.839646e-02   \n",
       "min      0.000000e+00        0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%      5.450000e-01        0.000000e+00  6.300000e+01  0.000000e+00   \n",
       "50%      8.440000e-01        0.000000e+00  1.543913e+02  0.000000e+00   \n",
       "75%      1.300000e+00        8.508852e+01  2.233466e+02  0.000000e+00   \n",
       "max      1.000000e+01        1.990000e+03  5.000000e+02  1.000000e+00   \n",
       "\n",
       "           dopamine   epinephrine  norepinephrine  vasopressin            pH  \\\n",
       "count  1.405992e+06  1.405992e+06    1.405992e+06    1405992.0  1.405992e+06   \n",
       "mean   1.024757e-02  1.982301e-02    9.811080e-02          0.0  3.985607e+00   \n",
       "std    1.007103e-01  1.393918e-01    2.974645e-01          0.0  3.677374e+00   \n",
       "min    0.000000e+00  0.000000e+00    0.000000e+00          0.0  0.000000e+00   \n",
       "25%    0.000000e+00  0.000000e+00    0.000000e+00          0.0  0.000000e+00   \n",
       "50%    0.000000e+00  0.000000e+00    0.000000e+00          0.0  7.274000e+00   \n",
       "75%    0.000000e+00  0.000000e+00    0.000000e+00          0.0  7.390000e+00   \n",
       "max    1.000000e+00  1.000000e+00    1.000000e+00          0.0  7.760000e+00   \n",
       "\n",
       "          potassium   bicarbonate       lactate     icd_event           age  \\\n",
       "count  1.405992e+06  1.405992e+06  1.405992e+06  1.405992e+06  1.405992e+06   \n",
       "mean   3.386056e+00  1.916074e+01  8.410696e-01  1.439837e-01  6.516724e+01   \n",
       "std    1.721744e+00  9.829090e+00  1.126053e+00  3.510734e-01  1.650639e+01   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  1.800000e+01   \n",
       "25%    3.444444e+00  1.790909e+01  0.000000e+00  0.000000e+00  5.500000e+01   \n",
       "50%    3.971429e+00  2.233333e+01  0.000000e+00  0.000000e+00  6.700000e+01   \n",
       "75%    4.392308e+00  2.500000e+01  1.500000e+00  0.000000e+00  7.800000e+01   \n",
       "max    1.000000e+01  4.000000e+01  6.000000e+00  1.000000e+00  1.020000e+02   \n",
       "\n",
       "       is_infection  \n",
       "count  1.405992e+06  \n",
       "mean   7.112416e-04  \n",
       "std    2.665964e-02  \n",
       "min    0.000000e+00  \n",
       "25%    0.000000e+00  \n",
       "50%    0.000000e+00  \n",
       "75%    0.000000e+00  \n",
       "max    1.000000e+00  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "total_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subject_id', 'hadm_id', 'stay_id', 'hr', 'endtime', 'sbp', 'dbp',\n",
       "       'gcs_min', 'respiratory_rate', 'abp_mean', 'heart_rate', 'temperature',\n",
       "       'hemoglobin', 'hematocrit', 'sao2', 'fio2', 'wbc', 'bun',\n",
       "       'bilirubin_max', 'creatinine_max', 'pao2fio2ratio_vent', 'platelet_min',\n",
       "       'dobutamine', 'dopamine', 'epinephrine', 'norepinephrine',\n",
       "       'vasopressin', 'pH', 'potassium', 'bicarbonate', 'lactate', 'icd_event',\n",
       "       'age', 'is_infection'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>stay_id</th>\n",
       "      <th>hr</th>\n",
       "      <th>endtime</th>\n",
       "      <th>sbp</th>\n",
       "      <th>dbp</th>\n",
       "      <th>gcs_min</th>\n",
       "      <th>respiratory_rate</th>\n",
       "      <th>abp_mean</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>temperature</th>\n",
       "      <th>hemoglobin</th>\n",
       "      <th>hematocrit</th>\n",
       "      <th>sao2</th>\n",
       "      <th>fio2</th>\n",
       "      <th>wbc</th>\n",
       "      <th>bun</th>\n",
       "      <th>bilirubin_max</th>\n",
       "      <th>creatinine_max</th>\n",
       "      <th>pao2fio2ratio_vent</th>\n",
       "      <th>platelet_min</th>\n",
       "      <th>dobutamine</th>\n",
       "      <th>dopamine</th>\n",
       "      <th>epinephrine</th>\n",
       "      <th>norepinephrine</th>\n",
       "      <th>vasopressin</th>\n",
       "      <th>pH</th>\n",
       "      <th>potassium</th>\n",
       "      <th>bicarbonate</th>\n",
       "      <th>lactate</th>\n",
       "      <th>icd_event</th>\n",
       "      <th>age</th>\n",
       "      <th>is_infection</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starttime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2174-09-29 12:00:00</th>\n",
       "      <td>12466550</td>\n",
       "      <td>23998182</td>\n",
       "      <td>30000153</td>\n",
       "      <td>0</td>\n",
       "      <td>2174-09-29 13:00:00</td>\n",
       "      <td>0.6225</td>\n",
       "      <td>0.7550</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.226667</td>\n",
       "      <td>0.000975</td>\n",
       "      <td>0.5100</td>\n",
       "      <td>0.864346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.589226</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2174-09-29 13:00:00</th>\n",
       "      <td>12466550</td>\n",
       "      <td>23998182</td>\n",
       "      <td>30000153</td>\n",
       "      <td>1</td>\n",
       "      <td>2174-09-29 14:00:00</td>\n",
       "      <td>0.7050</td>\n",
       "      <td>0.6650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.001882</td>\n",
       "      <td>0.4625</td>\n",
       "      <td>0.895078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.570707</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944373</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2174-09-29 14:00:00</th>\n",
       "      <td>12466550</td>\n",
       "      <td>23998182</td>\n",
       "      <td>30000153</td>\n",
       "      <td>2</td>\n",
       "      <td>2174-09-29 15:00:00</td>\n",
       "      <td>0.6425</td>\n",
       "      <td>0.6325</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.001868</td>\n",
       "      <td>0.4150</td>\n",
       "      <td>0.895078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.552189</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.264322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944373</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2174-09-29 15:00:00</th>\n",
       "      <td>12466550</td>\n",
       "      <td>23998182</td>\n",
       "      <td>30000153</td>\n",
       "      <td>3</td>\n",
       "      <td>2174-09-29 16:00:00</td>\n",
       "      <td>0.5800</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.001854</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.900360</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.533670</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.240201</td>\n",
       "      <td>0.346000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.945019</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2174-09-29 16:00:00</th>\n",
       "      <td>12466550</td>\n",
       "      <td>23998182</td>\n",
       "      <td>30000153</td>\n",
       "      <td>4</td>\n",
       "      <td>2174-09-29 17:00:00</td>\n",
       "      <td>0.5550</td>\n",
       "      <td>0.5600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.001780</td>\n",
       "      <td>0.5150</td>\n",
       "      <td>0.900360</td>\n",
       "      <td>0.517713</td>\n",
       "      <td>0.535915</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.091667</td>\n",
       "      <td>0.216080</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.945666</td>\n",
       "      <td>0.443333</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2174-09-29 17:00:00</th>\n",
       "      <td>12466550</td>\n",
       "      <td>23998182</td>\n",
       "      <td>30000153</td>\n",
       "      <td>5</td>\n",
       "      <td>2174-09-29 18:00:00</td>\n",
       "      <td>0.6650</td>\n",
       "      <td>0.6300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.001916</td>\n",
       "      <td>0.5550</td>\n",
       "      <td>0.900360</td>\n",
       "      <td>0.513688</td>\n",
       "      <td>0.538159</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>0.216080</td>\n",
       "      <td>0.342333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.945666</td>\n",
       "      <td>0.446667</td>\n",
       "      <td>0.491667</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2174-09-29 18:00:00</th>\n",
       "      <td>12466550</td>\n",
       "      <td>23998182</td>\n",
       "      <td>30000153</td>\n",
       "      <td>6</td>\n",
       "      <td>2174-09-29 19:00:00</td>\n",
       "      <td>0.7750</td>\n",
       "      <td>0.6800</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.002007</td>\n",
       "      <td>0.6150</td>\n",
       "      <td>0.900360</td>\n",
       "      <td>0.509662</td>\n",
       "      <td>0.540404</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.095000</td>\n",
       "      <td>0.216080</td>\n",
       "      <td>0.340500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.945666</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2174-09-29 19:00:00</th>\n",
       "      <td>12466550</td>\n",
       "      <td>23998182</td>\n",
       "      <td>30000153</td>\n",
       "      <td>7</td>\n",
       "      <td>2174-09-29 20:00:00</td>\n",
       "      <td>0.6100</td>\n",
       "      <td>0.6700</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.001916</td>\n",
       "      <td>0.6400</td>\n",
       "      <td>0.917647</td>\n",
       "      <td>0.505636</td>\n",
       "      <td>0.534792</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.096667</td>\n",
       "      <td>0.216080</td>\n",
       "      <td>0.338667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.945666</td>\n",
       "      <td>0.453333</td>\n",
       "      <td>0.508333</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2174-09-29 20:00:00</th>\n",
       "      <td>12466550</td>\n",
       "      <td>23998182</td>\n",
       "      <td>30000153</td>\n",
       "      <td>8</td>\n",
       "      <td>2174-09-29 21:00:00</td>\n",
       "      <td>0.6800</td>\n",
       "      <td>0.6700</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.001962</td>\n",
       "      <td>0.6150</td>\n",
       "      <td>0.917647</td>\n",
       "      <td>0.501610</td>\n",
       "      <td>0.529181</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.098333</td>\n",
       "      <td>0.216080</td>\n",
       "      <td>0.336833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.945666</td>\n",
       "      <td>0.456667</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2174-09-29 21:00:00</th>\n",
       "      <td>12466550</td>\n",
       "      <td>23998182</td>\n",
       "      <td>30000153</td>\n",
       "      <td>9</td>\n",
       "      <td>2174-09-29 22:00:00</td>\n",
       "      <td>0.5400</td>\n",
       "      <td>0.6100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.001848</td>\n",
       "      <td>0.6200</td>\n",
       "      <td>0.917647</td>\n",
       "      <td>0.497585</td>\n",
       "      <td>0.523569</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.216080</td>\n",
       "      <td>0.335000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.945666</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     subject_id   hadm_id   stay_id  hr              endtime  \\\n",
       "starttime                                                                      \n",
       "2174-09-29 12:00:00    12466550  23998182  30000153   0  2174-09-29 13:00:00   \n",
       "2174-09-29 13:00:00    12466550  23998182  30000153   1  2174-09-29 14:00:00   \n",
       "2174-09-29 14:00:00    12466550  23998182  30000153   2  2174-09-29 15:00:00   \n",
       "2174-09-29 15:00:00    12466550  23998182  30000153   3  2174-09-29 16:00:00   \n",
       "2174-09-29 16:00:00    12466550  23998182  30000153   4  2174-09-29 17:00:00   \n",
       "2174-09-29 17:00:00    12466550  23998182  30000153   5  2174-09-29 18:00:00   \n",
       "2174-09-29 18:00:00    12466550  23998182  30000153   6  2174-09-29 19:00:00   \n",
       "2174-09-29 19:00:00    12466550  23998182  30000153   7  2174-09-29 20:00:00   \n",
       "2174-09-29 20:00:00    12466550  23998182  30000153   8  2174-09-29 21:00:00   \n",
       "2174-09-29 21:00:00    12466550  23998182  30000153   9  2174-09-29 22:00:00   \n",
       "\n",
       "                        sbp     dbp  gcs_min  respiratory_rate  abp_mean  \\\n",
       "starttime                                                                  \n",
       "2174-09-29 12:00:00  0.6225  0.7550      1.0          0.226667  0.000975   \n",
       "2174-09-29 13:00:00  0.7050  0.6650      1.0          0.320000  0.001882   \n",
       "2174-09-29 14:00:00  0.6425  0.6325      1.0          0.270000  0.001868   \n",
       "2174-09-29 15:00:00  0.5800  0.6000      1.0          0.220000  0.001854   \n",
       "2174-09-29 16:00:00  0.5550  0.5600      1.0          0.400000  0.001780   \n",
       "2174-09-29 17:00:00  0.6650  0.6300      0.6          0.240000  0.001916   \n",
       "2174-09-29 18:00:00  0.7750  0.6800      0.6          0.420000  0.002007   \n",
       "2174-09-29 19:00:00  0.6100  0.6700      0.8          0.420000  0.001916   \n",
       "2174-09-29 20:00:00  0.6800  0.6700      0.8          0.440000  0.001962   \n",
       "2174-09-29 21:00:00  0.5400  0.6100      0.8          0.340000  0.001848   \n",
       "\n",
       "                     heart_rate  temperature  hemoglobin  hematocrit     sao2  \\\n",
       "starttime                                                                       \n",
       "2174-09-29 12:00:00      0.5100     0.864346    0.000000    0.589226  0.00001   \n",
       "2174-09-29 13:00:00      0.4625     0.895078    0.000000    0.570707  0.00001   \n",
       "2174-09-29 14:00:00      0.4150     0.895078    0.000000    0.552189  0.00001   \n",
       "2174-09-29 15:00:00      0.4375     0.900360    0.521739    0.533670  0.00001   \n",
       "2174-09-29 16:00:00      0.5150     0.900360    0.517713    0.535915  0.00001   \n",
       "2174-09-29 17:00:00      0.5550     0.900360    0.513688    0.538159  0.00001   \n",
       "2174-09-29 18:00:00      0.6150     0.900360    0.509662    0.540404  0.00001   \n",
       "2174-09-29 19:00:00      0.6400     0.917647    0.505636    0.534792  0.00001   \n",
       "2174-09-29 20:00:00      0.6150     0.917647    0.501610    0.529181  0.00001   \n",
       "2174-09-29 21:00:00      0.6200     0.917647    0.497585    0.523569  0.00001   \n",
       "\n",
       "                     fio2       wbc       bun  bilirubin_max  creatinine_max  \\\n",
       "starttime                                                                      \n",
       "2174-09-29 12:00:00   0.0  0.000000  0.000000            0.0        0.000000   \n",
       "2174-09-29 13:00:00   0.0  0.000000  0.000000            0.0        0.000000   \n",
       "2174-09-29 14:00:00   0.0  0.000000  0.000000            0.0        0.000000   \n",
       "2174-09-29 15:00:00   0.0  0.000017  0.000022            0.0        0.090000   \n",
       "2174-09-29 16:00:00   0.5  0.000017  0.000022            0.0        0.091667   \n",
       "2174-09-29 17:00:00   0.5  0.000017  0.000022            0.0        0.093333   \n",
       "2174-09-29 18:00:00   0.5  0.000017  0.000022            0.0        0.095000   \n",
       "2174-09-29 19:00:00   0.5  0.000016  0.000022            0.0        0.096667   \n",
       "2174-09-29 20:00:00   0.5  0.000016  0.000022            0.0        0.098333   \n",
       "2174-09-29 21:00:00   0.5  0.000016  0.000022            0.0        0.100000   \n",
       "\n",
       "                     pao2fio2ratio_vent  platelet_min  dobutamine  dopamine  \\\n",
       "starttime                                                                     \n",
       "2174-09-29 12:00:00            0.000000      0.000000         0.0       0.0   \n",
       "2174-09-29 13:00:00            0.222111      0.000000         0.0       0.0   \n",
       "2174-09-29 14:00:00            0.264322      0.000000         0.0       0.0   \n",
       "2174-09-29 15:00:00            0.240201      0.346000         0.0       0.0   \n",
       "2174-09-29 16:00:00            0.216080      0.344167         0.0       0.0   \n",
       "2174-09-29 17:00:00            0.216080      0.342333         0.0       0.0   \n",
       "2174-09-29 18:00:00            0.216080      0.340500         0.0       0.0   \n",
       "2174-09-29 19:00:00            0.216080      0.338667         0.0       0.0   \n",
       "2174-09-29 20:00:00            0.216080      0.336833         0.0       0.0   \n",
       "2174-09-29 21:00:00            0.216080      0.335000         0.0       0.0   \n",
       "\n",
       "                     epinephrine  norepinephrine  vasopressin        pH  \\\n",
       "starttime                                                                 \n",
       "2174-09-29 12:00:00          0.0             0.0          0.0  0.000000   \n",
       "2174-09-29 13:00:00          0.0             0.0          0.0  0.944373   \n",
       "2174-09-29 14:00:00          0.0             0.0          0.0  0.944373   \n",
       "2174-09-29 15:00:00          0.0             0.0          0.0  0.945019   \n",
       "2174-09-29 16:00:00          0.0             0.0          0.0  0.945666   \n",
       "2174-09-29 17:00:00          0.0             0.0          0.0  0.945666   \n",
       "2174-09-29 18:00:00          0.0             0.0          0.0  0.945666   \n",
       "2174-09-29 19:00:00          0.0             0.0          0.0  0.945666   \n",
       "2174-09-29 20:00:00          0.0             0.0          0.0  0.945666   \n",
       "2174-09-29 21:00:00          0.0             0.0          0.0  0.945666   \n",
       "\n",
       "                     potassium  bicarbonate   lactate  icd_event       age  \\\n",
       "starttime                                                                    \n",
       "2174-09-29 12:00:00   0.000000     0.000000  0.000000        0.0  0.511905   \n",
       "2174-09-29 13:00:00   0.000000     0.000000  0.216667        0.0  0.511905   \n",
       "2174-09-29 14:00:00   0.000000     0.000000  0.350000        0.0  0.511905   \n",
       "2174-09-29 15:00:00   0.440000     0.475000  0.350000        0.0  0.511905   \n",
       "2174-09-29 16:00:00   0.443333     0.483333  0.350000        0.0  0.511905   \n",
       "2174-09-29 17:00:00   0.446667     0.491667  0.350000        0.0  0.511905   \n",
       "2174-09-29 18:00:00   0.450000     0.500000  0.350000        0.0  0.511905   \n",
       "2174-09-29 19:00:00   0.453333     0.508333  0.350000        0.0  0.511905   \n",
       "2174-09-29 20:00:00   0.456667     0.516667  0.350000        0.0  0.511905   \n",
       "2174-09-29 21:00:00   0.460000     0.525000  0.350000        0.0  0.511905   \n",
       "\n",
       "                     is_infection  \n",
       "starttime                          \n",
       "2174-09-29 12:00:00             0  \n",
       "2174-09-29 13:00:00             0  \n",
       "2174-09-29 14:00:00             0  \n",
       "2174-09-29 15:00:00             0  \n",
       "2174-09-29 16:00:00             0  \n",
       "2174-09-29 17:00:00             0  \n",
       "2174-09-29 18:00:00             0  \n",
       "2174-09-29 19:00:00             0  \n",
       "2174-09-29 20:00:00             0  \n",
       "2174-09-29 21:00:00             0  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sbp</th>\n",
       "      <th>dbp</th>\n",
       "      <th>gcs_min</th>\n",
       "      <th>respiratory_rate</th>\n",
       "      <th>abp_mean</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>temperature</th>\n",
       "      <th>hemoglobin</th>\n",
       "      <th>hematocrit</th>\n",
       "      <th>sao2</th>\n",
       "      <th>wbc</th>\n",
       "      <th>bun</th>\n",
       "      <th>bilirubin_max</th>\n",
       "      <th>creatinine_max</th>\n",
       "      <th>platelet_min</th>\n",
       "      <th>pH</th>\n",
       "      <th>potassium</th>\n",
       "      <th>bicarbonate</th>\n",
       "      <th>lactate</th>\n",
       "      <th>age</th>\n",
       "      <th>is_infection</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starttime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2174-09-29 12:00:00</th>\n",
       "      <td>0.6225</td>\n",
       "      <td>0.7550</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.226667</td>\n",
       "      <td>0.000975</td>\n",
       "      <td>0.5100</td>\n",
       "      <td>0.864346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.589226</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2174-09-29 13:00:00</th>\n",
       "      <td>0.7050</td>\n",
       "      <td>0.6650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.001882</td>\n",
       "      <td>0.4625</td>\n",
       "      <td>0.895078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.570707</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.944373</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2174-09-29 14:00:00</th>\n",
       "      <td>0.6425</td>\n",
       "      <td>0.6325</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.001868</td>\n",
       "      <td>0.4150</td>\n",
       "      <td>0.895078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.552189</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.944373</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2174-09-29 15:00:00</th>\n",
       "      <td>0.5800</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.001854</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.900360</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.533670</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.346000</td>\n",
       "      <td>0.945019</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2174-09-29 16:00:00</th>\n",
       "      <td>0.5550</td>\n",
       "      <td>0.5600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.001780</td>\n",
       "      <td>0.5150</td>\n",
       "      <td>0.900360</td>\n",
       "      <td>0.517713</td>\n",
       "      <td>0.535915</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.091667</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.945666</td>\n",
       "      <td>0.443333</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2174-09-29 17:00:00</th>\n",
       "      <td>0.6650</td>\n",
       "      <td>0.6300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.001916</td>\n",
       "      <td>0.5550</td>\n",
       "      <td>0.900360</td>\n",
       "      <td>0.513688</td>\n",
       "      <td>0.538159</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>0.342333</td>\n",
       "      <td>0.945666</td>\n",
       "      <td>0.446667</td>\n",
       "      <td>0.491667</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2174-09-29 18:00:00</th>\n",
       "      <td>0.7750</td>\n",
       "      <td>0.6800</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.002007</td>\n",
       "      <td>0.6150</td>\n",
       "      <td>0.900360</td>\n",
       "      <td>0.509662</td>\n",
       "      <td>0.540404</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.095000</td>\n",
       "      <td>0.340500</td>\n",
       "      <td>0.945666</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2174-09-29 19:00:00</th>\n",
       "      <td>0.6100</td>\n",
       "      <td>0.6700</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.001916</td>\n",
       "      <td>0.6400</td>\n",
       "      <td>0.917647</td>\n",
       "      <td>0.505636</td>\n",
       "      <td>0.534792</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.096667</td>\n",
       "      <td>0.338667</td>\n",
       "      <td>0.945666</td>\n",
       "      <td>0.453333</td>\n",
       "      <td>0.508333</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2174-09-29 20:00:00</th>\n",
       "      <td>0.6800</td>\n",
       "      <td>0.6700</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.001962</td>\n",
       "      <td>0.6150</td>\n",
       "      <td>0.917647</td>\n",
       "      <td>0.501610</td>\n",
       "      <td>0.529181</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.098333</td>\n",
       "      <td>0.336833</td>\n",
       "      <td>0.945666</td>\n",
       "      <td>0.456667</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2174-09-29 21:00:00</th>\n",
       "      <td>0.5400</td>\n",
       "      <td>0.6100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.001848</td>\n",
       "      <td>0.6200</td>\n",
       "      <td>0.917647</td>\n",
       "      <td>0.497585</td>\n",
       "      <td>0.523569</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.335000</td>\n",
       "      <td>0.945666</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        sbp     dbp  gcs_min  respiratory_rate  abp_mean  \\\n",
       "starttime                                                                  \n",
       "2174-09-29 12:00:00  0.6225  0.7550      1.0          0.226667  0.000975   \n",
       "2174-09-29 13:00:00  0.7050  0.6650      1.0          0.320000  0.001882   \n",
       "2174-09-29 14:00:00  0.6425  0.6325      1.0          0.270000  0.001868   \n",
       "2174-09-29 15:00:00  0.5800  0.6000      1.0          0.220000  0.001854   \n",
       "2174-09-29 16:00:00  0.5550  0.5600      1.0          0.400000  0.001780   \n",
       "2174-09-29 17:00:00  0.6650  0.6300      0.6          0.240000  0.001916   \n",
       "2174-09-29 18:00:00  0.7750  0.6800      0.6          0.420000  0.002007   \n",
       "2174-09-29 19:00:00  0.6100  0.6700      0.8          0.420000  0.001916   \n",
       "2174-09-29 20:00:00  0.6800  0.6700      0.8          0.440000  0.001962   \n",
       "2174-09-29 21:00:00  0.5400  0.6100      0.8          0.340000  0.001848   \n",
       "\n",
       "                     heart_rate  temperature  hemoglobin  hematocrit     sao2  \\\n",
       "starttime                                                                       \n",
       "2174-09-29 12:00:00      0.5100     0.864346    0.000000    0.589226  0.00001   \n",
       "2174-09-29 13:00:00      0.4625     0.895078    0.000000    0.570707  0.00001   \n",
       "2174-09-29 14:00:00      0.4150     0.895078    0.000000    0.552189  0.00001   \n",
       "2174-09-29 15:00:00      0.4375     0.900360    0.521739    0.533670  0.00001   \n",
       "2174-09-29 16:00:00      0.5150     0.900360    0.517713    0.535915  0.00001   \n",
       "2174-09-29 17:00:00      0.5550     0.900360    0.513688    0.538159  0.00001   \n",
       "2174-09-29 18:00:00      0.6150     0.900360    0.509662    0.540404  0.00001   \n",
       "2174-09-29 19:00:00      0.6400     0.917647    0.505636    0.534792  0.00001   \n",
       "2174-09-29 20:00:00      0.6150     0.917647    0.501610    0.529181  0.00001   \n",
       "2174-09-29 21:00:00      0.6200     0.917647    0.497585    0.523569  0.00001   \n",
       "\n",
       "                          wbc       bun  bilirubin_max  creatinine_max  \\\n",
       "starttime                                                                \n",
       "2174-09-29 12:00:00  0.000000  0.000000            0.0        0.000000   \n",
       "2174-09-29 13:00:00  0.000000  0.000000            0.0        0.000000   \n",
       "2174-09-29 14:00:00  0.000000  0.000000            0.0        0.000000   \n",
       "2174-09-29 15:00:00  0.000017  0.000022            0.0        0.090000   \n",
       "2174-09-29 16:00:00  0.000017  0.000022            0.0        0.091667   \n",
       "2174-09-29 17:00:00  0.000017  0.000022            0.0        0.093333   \n",
       "2174-09-29 18:00:00  0.000017  0.000022            0.0        0.095000   \n",
       "2174-09-29 19:00:00  0.000016  0.000022            0.0        0.096667   \n",
       "2174-09-29 20:00:00  0.000016  0.000022            0.0        0.098333   \n",
       "2174-09-29 21:00:00  0.000016  0.000022            0.0        0.100000   \n",
       "\n",
       "                     platelet_min        pH  potassium  bicarbonate   lactate  \\\n",
       "starttime                                                                       \n",
       "2174-09-29 12:00:00      0.000000  0.000000   0.000000     0.000000  0.000000   \n",
       "2174-09-29 13:00:00      0.000000  0.944373   0.000000     0.000000  0.216667   \n",
       "2174-09-29 14:00:00      0.000000  0.944373   0.000000     0.000000  0.350000   \n",
       "2174-09-29 15:00:00      0.346000  0.945019   0.440000     0.475000  0.350000   \n",
       "2174-09-29 16:00:00      0.344167  0.945666   0.443333     0.483333  0.350000   \n",
       "2174-09-29 17:00:00      0.342333  0.945666   0.446667     0.491667  0.350000   \n",
       "2174-09-29 18:00:00      0.340500  0.945666   0.450000     0.500000  0.350000   \n",
       "2174-09-29 19:00:00      0.338667  0.945666   0.453333     0.508333  0.350000   \n",
       "2174-09-29 20:00:00      0.336833  0.945666   0.456667     0.516667  0.350000   \n",
       "2174-09-29 21:00:00      0.335000  0.945666   0.460000     0.525000  0.350000   \n",
       "\n",
       "                          age  is_infection  \n",
       "starttime                                    \n",
       "2174-09-29 12:00:00  0.511905             0  \n",
       "2174-09-29 13:00:00  0.511905             0  \n",
       "2174-09-29 14:00:00  0.511905             0  \n",
       "2174-09-29 15:00:00  0.511905             0  \n",
       "2174-09-29 16:00:00  0.511905             0  \n",
       "2174-09-29 17:00:00  0.511905             0  \n",
       "2174-09-29 18:00:00  0.511905             0  \n",
       "2174-09-29 19:00:00  0.511905             0  \n",
       "2174-09-29 20:00:00  0.511905             0  \n",
       "2174-09-29 21:00:00  0.511905             0  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_cols = ['subject_id', 'hadm_id', 'stay_id', 'hr', 'endtime', 'icd_event', 'dobutamine', 'dopamine', 'epinephrine', 'norepinephrine', 'vasopressin', 'fio2', 'pao2fio2ratio_vent']\n",
    "#drop_cols = ['subject_id', 'hadm_id', 'stay_id', 'hr', 'endtime', 'icd_event']\n",
    "\n",
    "total_dataset = total_df.drop(drop_cols, axis=1)\n",
    "train_dataset = train_df.drop(drop_cols, axis=1)\n",
    "valid_dataset = valid_df.drop(drop_cols, axis=1)\n",
    "test_dataset = test_df.drop(drop_cols, axis=1)\n",
    "train_dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sbp', 'dbp', 'gcs_min', 'respiratory_rate', 'abp_mean', 'heart_rate',\n",
       "       'temperature', 'hemoglobin', 'hematocrit', 'sao2', 'wbc', 'bun',\n",
       "       'bilirubin_max', 'creatinine_max', 'platelet_min', 'pH', 'potassium',\n",
       "       'bicarbonate', 'lactate', 'age', 'is_infection'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] 전체 환자: 37492\n",
      "[train] 패혈증 환자: 640\n",
      "[valid] 전체 환자: 9374\n",
      "[valid] 패혈증 환자: 184\n",
      "[test] 전체 환자: 11717\n",
      "[test] 패혈증 환자: 176\n"
     ]
    }
   ],
   "source": [
    "print('[train] 전체 환자:',len(train_dataset)//24)\n",
    "print('[train] 패혈증 환자:',len(train_dataset[train_dataset['is_infection'] == 1]))\n",
    "print('[valid] 전체 환자:',len(valid_dataset)//24)\n",
    "print('[valid] 패혈증 환자:',len(valid_dataset[valid_dataset['is_infection'] == 1]))\n",
    "print('[test] 전체 환자:',len(test_dataset)//24)\n",
    "print('[test] 패혈증 환자:',len(test_dataset[test_dataset['is_infection'] == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sbp</th>\n",
       "      <th>dbp</th>\n",
       "      <th>gcs_min</th>\n",
       "      <th>respiratory_rate</th>\n",
       "      <th>abp_mean</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>temperature</th>\n",
       "      <th>hemoglobin</th>\n",
       "      <th>hematocrit</th>\n",
       "      <th>sao2</th>\n",
       "      <th>urine</th>\n",
       "      <th>wbc</th>\n",
       "      <th>bun</th>\n",
       "      <th>bilirubin_max</th>\n",
       "      <th>creatinine_max</th>\n",
       "      <th>platelet_min</th>\n",
       "      <th>pH</th>\n",
       "      <th>potassium</th>\n",
       "      <th>bicarbonate</th>\n",
       "      <th>lactate</th>\n",
       "      <th>age</th>\n",
       "      <th>is_infection</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starttime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2134-10-20 10:00:00</th>\n",
       "      <td>134.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>14.75</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>37.00</td>\n",
       "      <td>8.866667</td>\n",
       "      <td>26.600000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>7.366667</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.866667</td>\n",
       "      <td>25.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191-05-07 11:00:00</th>\n",
       "      <td>101.208333</td>\n",
       "      <td>54.500000</td>\n",
       "      <td>15.00</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>70.583333</td>\n",
       "      <td>96.250000</td>\n",
       "      <td>36.17</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>99.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>14.600000</td>\n",
       "      <td>18.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>7.410000</td>\n",
       "      <td>3.540000</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150-12-16 13:00:00</th>\n",
       "      <td>105.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>14.00</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>37.50</td>\n",
       "      <td>9.020833</td>\n",
       "      <td>27.579167</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>17.158333</td>\n",
       "      <td>19.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>28.291667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2169-07-13 03:00:00</th>\n",
       "      <td>91.250000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>14.50</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>36.61</td>\n",
       "      <td>11.172727</td>\n",
       "      <td>35.218182</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>11.109091</td>\n",
       "      <td>10.727273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>345.272727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.481818</td>\n",
       "      <td>23.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2182-10-10 02:00:00</th>\n",
       "      <td>120.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>13.00</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>36.56</td>\n",
       "      <td>8.900000</td>\n",
       "      <td>28.300000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>20.100000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>193.000000</td>\n",
       "      <td>7.330000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127-07-25 07:00:00</th>\n",
       "      <td>157.666667</td>\n",
       "      <td>79.833333</td>\n",
       "      <td>11.00</td>\n",
       "      <td>21.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>68.333333</td>\n",
       "      <td>36.44</td>\n",
       "      <td>9.187500</td>\n",
       "      <td>27.262500</td>\n",
       "      <td>97.833333</td>\n",
       "      <td>0</td>\n",
       "      <td>9.033333</td>\n",
       "      <td>16.933333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.806667</td>\n",
       "      <td>164.958333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>19.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2148-09-23 09:00:00</th>\n",
       "      <td>94.777778</td>\n",
       "      <td>68.833333</td>\n",
       "      <td>15.00</td>\n",
       "      <td>17.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>80.777778</td>\n",
       "      <td>36.78</td>\n",
       "      <td>9.820000</td>\n",
       "      <td>29.580000</td>\n",
       "      <td>93.444444</td>\n",
       "      <td>0</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.340909</td>\n",
       "      <td>232.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.580000</td>\n",
       "      <td>22.181818</td>\n",
       "      <td>1.137662</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2117-05-26 21:00:00</th>\n",
       "      <td>160.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>15.00</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>36.61</td>\n",
       "      <td>12.272727</td>\n",
       "      <td>35.872727</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>9.554545</td>\n",
       "      <td>12.818182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.581818</td>\n",
       "      <td>204.181818</td>\n",
       "      <td>7.451304</td>\n",
       "      <td>3.536364</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2155-01-13 08:00:00</th>\n",
       "      <td>127.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>14.00</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>37.00</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>24.633333</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>5.366667</td>\n",
       "      <td>34.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>201.833333</td>\n",
       "      <td>7.327778</td>\n",
       "      <td>4.616667</td>\n",
       "      <td>36.833333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130-03-09 10:00:00</th>\n",
       "      <td>124.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>14.50</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>86.500000</td>\n",
       "      <td>36.44</td>\n",
       "      <td>14.881818</td>\n",
       "      <td>44.281818</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>9.563636</td>\n",
       "      <td>23.909091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>277.636364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>27.545455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            sbp        dbp  gcs_min  respiratory_rate  \\\n",
       "starttime                                                               \n",
       "2134-10-20 10:00:00  134.000000  80.000000    14.75         19.000000   \n",
       "2191-05-07 11:00:00  101.208333  54.500000    15.00         14.000000   \n",
       "2150-12-16 13:00:00  105.000000  64.000000    14.00         16.000000   \n",
       "2169-07-13 03:00:00   91.250000  61.000000    14.50         13.000000   \n",
       "2182-10-10 02:00:00  120.000000  52.000000    13.00         23.000000   \n",
       "...                         ...        ...      ...               ...   \n",
       "2127-07-25 07:00:00  157.666667  79.833333    11.00         21.333333   \n",
       "2148-09-23 09:00:00   94.777778  68.833333    15.00         17.333333   \n",
       "2117-05-26 21:00:00  160.000000  80.000000    15.00         15.000000   \n",
       "2155-01-13 08:00:00  127.000000  68.000000    14.00         28.000000   \n",
       "2130-03-09 10:00:00  124.000000  72.000000    14.50         22.000000   \n",
       "\n",
       "                       abp_mean  heart_rate  temperature  hemoglobin  \\\n",
       "starttime                                                              \n",
       "2134-10-20 10:00:00    0.000000  113.000000        37.00    8.866667   \n",
       "2191-05-07 11:00:00   70.583333   96.250000        36.17    9.200000   \n",
       "2150-12-16 13:00:00    0.000000  120.000000        37.50    9.020833   \n",
       "2169-07-13 03:00:00   71.000000   82.000000        36.61   11.172727   \n",
       "2182-10-10 02:00:00   73.000000   93.000000        36.56    8.900000   \n",
       "...                         ...         ...          ...         ...   \n",
       "2127-07-25 07:00:00    0.000000   68.333333        36.44    9.187500   \n",
       "2148-09-23 09:00:00    0.000000   80.777778        36.78    9.820000   \n",
       "2117-05-26 21:00:00  111.000000   78.000000        36.61   12.272727   \n",
       "2155-01-13 08:00:00    0.000000  102.000000        37.00    7.500000   \n",
       "2130-03-09 10:00:00    0.000000   86.500000        36.44   14.881818   \n",
       "\n",
       "                     hematocrit        sao2  urine        wbc        bun  \\\n",
       "starttime                                                                  \n",
       "2134-10-20 10:00:00   26.600000   95.000000      0   7.366667  22.000000   \n",
       "2191-05-07 11:00:00   27.000000   99.333333      0  14.600000  18.600000   \n",
       "2150-12-16 13:00:00   27.579167   98.000000      0  17.158333  19.666667   \n",
       "2169-07-13 03:00:00   35.218182   98.000000      0  11.109091  10.727273   \n",
       "2182-10-10 02:00:00   28.300000   91.000000      0  20.100000  27.000000   \n",
       "...                         ...         ...    ...        ...        ...   \n",
       "2127-07-25 07:00:00   27.262500   97.833333      0   9.033333  16.933333   \n",
       "2148-09-23 09:00:00   29.580000   93.444444      0   5.700000  28.500000   \n",
       "2117-05-26 21:00:00   35.872727  100.000000      0   9.554545  12.818182   \n",
       "2155-01-13 08:00:00   24.633333   96.000000      0   5.366667  34.833333   \n",
       "2130-03-09 10:00:00   44.281818   98.000000      0   9.563636  23.909091   \n",
       "\n",
       "                     bilirubin_max  creatinine_max  platelet_min        pH  \\\n",
       "starttime                                                                    \n",
       "2134-10-20 10:00:00            0.2        0.700000    114.000000  0.000000   \n",
       "2191-05-07 11:00:00            0.0        0.700000    154.000000  7.410000   \n",
       "2150-12-16 13:00:00            0.0        0.500000      0.000000  0.000000   \n",
       "2169-07-13 03:00:00            0.0        0.400000    345.272727  0.000000   \n",
       "2182-10-10 02:00:00            0.0        0.700000    193.000000  7.330000   \n",
       "...                            ...             ...           ...       ...   \n",
       "2127-07-25 07:00:00            0.5        0.806667    164.958333  0.000000   \n",
       "2148-09-23 09:00:00            0.0        1.340909    232.400000  0.000000   \n",
       "2117-05-26 21:00:00            0.0        0.581818    204.181818  7.451304   \n",
       "2155-01-13 08:00:00            0.0        1.000000    201.833333  7.327778   \n",
       "2130-03-09 10:00:00            0.0        0.727273    277.636364  0.000000   \n",
       "\n",
       "                     potassium  bicarbonate   lactate  age  is_infection  \n",
       "starttime                                                                 \n",
       "2134-10-20 10:00:00   3.866667    25.666667  0.000000   60             1  \n",
       "2191-05-07 11:00:00   3.540000    20.400000  3.600000   50             1  \n",
       "2150-12-16 13:00:00   4.833333    28.291667  0.000000   20             1  \n",
       "2169-07-13 03:00:00   4.481818    23.090909  0.000000   44             1  \n",
       "2182-10-10 02:00:00   4.400000    24.000000  0.950000   91             1  \n",
       "...                        ...          ...       ...  ...           ...  \n",
       "2127-07-25 07:00:00   3.600000    19.066667  0.000000   88             1  \n",
       "2148-09-23 09:00:00   4.580000    22.181818  1.137662   66             1  \n",
       "2117-05-26 21:00:00   3.536364    27.000000  0.709677   49             1  \n",
       "2155-01-13 08:00:00   4.616667    36.833333  0.000000   62             1  \n",
       "2130-03-09 10:00:00   3.700000    27.545455  0.000000   80             1  \n",
       "\n",
       "[1000 rows x 22 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_dataset[total_dataset['is_infection'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "d_zlRdiSTAgn"
   },
   "outputs": [],
   "source": [
    "class SepsisDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df_data, seq_len=24):\n",
    "        self.seq_len = seq_len\n",
    "        self.X = df_data.loc[:,df_data.columns!='is_infection'].values\n",
    "        self.y = df_data.loc[:, 'is_infection'].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)//self.seq_len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx *= self.seq_len \n",
    "        # lookback : prediction time (term) : sofa = 19 : 4 : 1 \n",
    "        X = self.X[idx:idx + self.seq_len-5]\n",
    "        y = self.y[idx + self.seq_len-1]\n",
    "        return X, y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24시간 단위\n",
    "trainset = SepsisDataset(train_dataset, seq_len=24)\n",
    "valset = SepsisDataset(valid_dataset, seq_len=24)\n",
    "testset = SepsisDataset(test_dataset, seq_len=24)\n",
    "\n",
    "partition = {'train': trainset, 'val':valset, 'test':testset}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '# of sepsis')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataloader = DataLoader(partition['train'],\n",
    "                             batch_size=128,\n",
    "                             shuffle=False, drop_last=False)\n",
    "\n",
    "y_num = []\n",
    "for X,y in dataloader :\n",
    "    y_num.append(y.numpy().sum())\n",
    "plt.plot(y_num)\n",
    "plt.xlabel('Batch Index')\n",
    "plt.ylabel('# of sepsis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Al40scAi5ZzG"
   },
   "source": [
    "# Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "Rr7F5kpl5ZzH"
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, batch_size, dropout, use_bn, device):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_dim = input_dim \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = 1\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.dropout = dropout\n",
    "        self.use_bn = use_bn \n",
    "        \n",
    "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers)\n",
    "        self.regressor = self.make_regressor()\n",
    "        \n",
    "        self.device = device\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        return (torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(self.device),\n",
    "                torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(self.device))\n",
    "    \n",
    "    def make_regressor(self):\n",
    "        layers = []\n",
    "        if self.use_bn:\n",
    "            layers.append(nn.BatchNorm1d(self.hidden_dim))\n",
    "        layers.append(nn.Dropout(self.dropout))\n",
    "        \n",
    "        layers.append(nn.Linear(self.hidden_dim, self.hidden_dim // 2))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.Linear(self.hidden_dim // 2, self.output_dim))\n",
    "        #layers.append(nn.Sigmoid()) # 지운 이유 : BCEwithLogitLoss에 Sigmoid가 붙어 있기 때문 (없으면 안돌아감)\n",
    "        regressor = nn.Sequential(*layers)\n",
    "        return regressor\n",
    "    \n",
    "    def forward(self, x):\n",
    "        hidden = self.init_hidden(x.size(1))\n",
    "        \n",
    "        lstm_out, self.hidden = self.lstm(x, hidden)\n",
    "        y_pred = self.regressor(lstm_out[-1].view(x.size(1), -1))\n",
    "#         t = Variable(torch.Tensor([0.5]))  # threshold\n",
    "#         out = (y_pred > t).float() * 1\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "pqir1JP_5ZzH"
   },
   "outputs": [],
   "source": [
    "def metric(y_pred, y_true):  \n",
    "    perc_y_pred = y_pred.cpu().detach().numpy()\n",
    "    perc_y_true = y_true.cpu().detach().numpy()\n",
    "    \n",
    "    try:\n",
    "        auc = roc_auc_score(perc_y_true, perc_y_pred)\n",
    "    except ValueError:\n",
    "        auc = -1\n",
    "    \n",
    "    return auc #acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0j20Sve95ZzH"
   },
   "source": [
    "# Train, Validate, Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "I7FqJ9EX5ZzI"
   },
   "outputs": [],
   "source": [
    "def train(model, partition, optimizer, loss_fn, args):\n",
    "    trainloader = DataLoader(partition['train'],\n",
    "                             batch_size=args.batch_size,\n",
    "                             shuffle=False, drop_last=False)\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    train_acc = 0.0\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    error_count = 0\n",
    "    for i, (X, y) in enumerate(trainloader):\n",
    "\n",
    "        X = X.transpose(0, 1).float().to(args.device)\n",
    "        y_true = y.float().to(args.device) \n",
    "\n",
    "        model.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred.view(-1), y_true.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        acc = metric(y_pred, y_true)\n",
    "        if acc < 0 :\n",
    "            error_count += 1\n",
    "        else :\n",
    "            train_acc += acc\n",
    "    \n",
    "    train_loss = train_loss / len(trainloader)\n",
    "    train_acc = train_acc / (len(trainloader) - error_count)\n",
    "    \n",
    "    return model, train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "JTX3hfCI5ZzI"
   },
   "outputs": [],
   "source": [
    "def validate(model, partition, loss_fn, args):\n",
    "    valloader = DataLoader(partition['val'], \n",
    "                           batch_size=args.batch_size, \n",
    "                           shuffle=False, drop_last=False)\n",
    "    model.eval()\n",
    "\n",
    "    val_acc = 0.0\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    error_count = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (X, y) in enumerate(valloader):\n",
    "\n",
    "            X = X.transpose(0, 1).float().to(args.device)\n",
    "            y_true = y.float().to(args.device)\n",
    "\n",
    "            y_pred = model(X)\n",
    "            loss = loss_fn(y_pred.view(-1), y_true.view(-1))\n",
    "            val_loss += loss.item()\n",
    "            acc = metric(y_pred, y_true)\n",
    "            \n",
    "            if acc < 0 :\n",
    "                error_count += 1\n",
    "            else :\n",
    "                val_acc += acc\n",
    "    \n",
    "    val_loss = val_loss / len(valloader)\n",
    "    val_acc = val_acc / (len(valloader) - error_count)\n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "kAmbRVca5ZzI"
   },
   "outputs": [],
   "source": [
    "def test(model, partition, args):\n",
    "    testloader = DataLoader(partition['test'], \n",
    "                           batch_size=args.batch_size, \n",
    "                           shuffle=False, drop_last=False)\n",
    "    model.eval()\n",
    "\n",
    "    test_acc = 0.0\n",
    "    \n",
    "    y_true = torch.zeros(1).to(args.device)\n",
    "    prediction = torch.zeros(1, 1).to(args.device)\n",
    "    \n",
    "    error_count = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (X, y) in enumerate(testloader):\n",
    "            X = X.transpose(0, 1).float().to(args.device)\n",
    "            y = y.float().to(args.device)\n",
    "\n",
    "            y_pred = model(X)\n",
    "            \n",
    "            acc = metric(y_pred, y)\n",
    "            if acc < 0 :\n",
    "                error_count += 1\n",
    "            else :\n",
    "                test_acc += acc\n",
    "            \n",
    "            y_true = torch.cat((y_true, y), 0)\n",
    "            prediction = torch.cat((prediction, y_pred), 0)\n",
    "    \n",
    "    test_acc = test_acc / (len(testloader) - error_count)\n",
    "    return y_true[1:], prediction[1:], test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "RgQSze2O5ZzJ"
   },
   "outputs": [],
   "source": [
    "def experiment(partition, args):\n",
    "\n",
    "    model = LSTM(args.input_dim, args.hid_dim, args.n_layers, args.batch_size, args.dropout, args.use_bn, args.device)\n",
    "    model.to(args.device)\n",
    "    \n",
    "    loss_fn = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([50]).to(args.device))\n",
    "    #loss_fn = nn.BCELoss()\n",
    "    \n",
    "    if args.optim == 'SGD':\n",
    "        optimizer = optim.RMSprop(model.parameters(), lr=args.lr, weight_decay=args.l2)\n",
    "    elif args.optim == 'RMSprop':\n",
    "        optimizer = optim.RMSprop(model.parameters(), lr=args.lr, weight_decay=args.l2)\n",
    "    elif args.optim == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.l2)\n",
    "    else:\n",
    "        raise ValueError('In-valid optimizer choice')\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience = 20, verbose=False, tolerance=0, path='results/checkpoint.pt')\n",
    "    \n",
    "    # ===== List for epoch-wise data ====== #\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    # ===================================== #\n",
    "    \n",
    "    e = 0\n",
    "    for epoch in range(args.epoch):\n",
    "        ts = time.time()\n",
    "        model, train_loss, train_acc = train(model, partition, optimizer, loss_fn, args)\n",
    "        val_loss, val_acc = validate(model, partition, loss_fn, args)\n",
    "        te = time.time()\n",
    "        \n",
    "        # ====== Add Epoch Data ====== #\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "        # ============================ #\n",
    "        \n",
    "        if (epoch+1) % 1 == 0 :\n",
    "            print('Epoch {}, Acc(train/val): {:2.2f}/{:2.2f}, Loss(train/val) {:2.5f}/{:2.5f}. Took {:2.2f} sec'.format(epoch+1, train_acc, val_acc, train_loss, val_loss, te-ts))\n",
    "        \n",
    "        # ====== Early Stopping ====== #\n",
    "        early_stopping(val_loss, model)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            e = epoch\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "        # ============================ #\n",
    "    \n",
    "    # ========== Load best model & Test =========== #\n",
    "    model = torch.load(\"./results/checkpoint.pt\")\n",
    "    y_true, prediction, test_acc = test(model, partition, args)\n",
    "    # ============================================= #\n",
    "    \n",
    "    # ======= Add Result to Dictionary ======= #\n",
    "    result = {}\n",
    "    result['train_losses'] = train_losses\n",
    "    result['val_losses'] = val_losses\n",
    "    result['train_accs'] = train_accs\n",
    "    result['val_accs'] = val_accs\n",
    "    result['train_acc'] = train_acc\n",
    "    result['val_acc'] = val_acc\n",
    "    result['test_acc'] = test_acc\n",
    "    return vars(args), result, y_true, prediction, e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7OUVge945ZzJ",
    "tags": []
   },
   "source": [
    "# Manage Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "6Ved9MOK5ZzJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import json\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "\n",
    "def save_exp_result(setting, result):\n",
    "    exp_name = setting['exp_name']\n",
    "    del setting['epoch']\n",
    "\n",
    "    hash_key = hashlib.sha1(str(setting).encode()).hexdigest()[:6]\n",
    "    filename = './results/{}-{}.json'.format(exp_name, hash_key)\n",
    "    result.update(setting)\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(result, f)\n",
    "\n",
    "    \n",
    "def load_exp_result(exp_name):\n",
    "    dir_path = './results'\n",
    "    filenames = [f for f in listdir(dir_path) if isfile(join(dir_path, f)) if '.json' in f]\n",
    "    list_result = []\n",
    "    for filename in filenames:\n",
    "        if exp_name in filename:\n",
    "            with open(join(dir_path, filename), 'r') as infile:\n",
    "                results = json.load(infile)\n",
    "                list_result.append(results)\n",
    "        break\n",
    "    df = pd.DataFrame(list_result) # .drop(columns=[])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "kfLW-ZBo5ZzJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_acc(var1, var2, df):\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3)\n",
    "    fig.set_size_inches(15, 6)\n",
    "    sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "\n",
    "    sns.barplot(x=var1, y='train_acc', hue=var2, data=df, ax=ax[0])\n",
    "    sns.barplot(x=var1, y='val_acc', hue=var2, data=df, ax=ax[1])\n",
    "    sns.barplot(x=var1, y='test_acc', hue=var2, data=df, ax=ax[2])\n",
    "    \n",
    "    ax[0].set_title('Train Accuracy')\n",
    "    ax[1].set_title('Validation Accuracy')\n",
    "    ax[2].set_title('Test Accuracy')\n",
    "\n",
    "    \n",
    "def plot_loss_variation(var1, var2, df, **kwargs):\n",
    "\n",
    "    list_v1 = df[var1].unique()\n",
    "    list_v2 = df[var2].unique()\n",
    "    list_data = []\n",
    "\n",
    "    for value1 in list_v1:\n",
    "        for value2 in list_v2:\n",
    "            row = df.loc[df[var1]==value1]\n",
    "            row = row.loc[df[var2]==value2]\n",
    "\n",
    "            train_losses = list(row.train_losses)[0]\n",
    "            val_losses = list(row.val_losses)[0]\n",
    "\n",
    "            for epoch, train_loss in enumerate(train_losses):\n",
    "                list_data.append({'type':'train', 'loss':train_loss, 'epoch':epoch, var1:value1, var2:value2})\n",
    "            for epoch, val_loss in enumerate(val_losses):\n",
    "                list_data.append({'type':'val', 'loss':val_loss, 'epoch':epoch, var1:value1, var2:value2})\n",
    "\n",
    "    df = pd.DataFrame(list_data)\n",
    "    g = sns.FacetGrid(df, row=var2, col=var1, hue='type', **kwargs)\n",
    "    g = g.map(plt.plot, 'epoch', 'loss', marker='.')\n",
    "    g.add_legend()\n",
    "    g.fig.suptitle('Train loss vs Val loss')\n",
    "    plt.subplots_adjust(top=0.89) \n",
    "\n",
    "\n",
    "def plot_acc_variation(var1, var2, df, **kwargs):\n",
    "    list_v1 = df[var1].unique()\n",
    "    list_v2 = df[var2].unique()\n",
    "    list_data = []\n",
    "\n",
    "    for value1 in list_v1:\n",
    "        for value2 in list_v2:\n",
    "            row = df.loc[df[var1]==value1]\n",
    "            row = row.loc[df[var2]==value2]\n",
    "\n",
    "            train_accs = list(row.train_accs)[0]\n",
    "            val_accs = list(row.val_accs)[0]\n",
    "            test_acc = list(row.test_acc)[0]\n",
    "\n",
    "            for epoch, train_acc in enumerate(train_accs):\n",
    "                list_data.append({'type':'train', 'Acc':train_acc, 'test_acc':test_acc, 'epoch':epoch, var1:value1, var2:value2})\n",
    "            for epoch, val_acc in enumerate(val_accs):\n",
    "                list_data.append({'type':'val', 'Acc':val_acc, 'test_acc':test_acc, 'epoch':epoch, var1:value1, var2:value2})\n",
    "\n",
    "    df = pd.DataFrame(list_data)\n",
    "    g = sns.FacetGrid(df, row=var2, col=var1, hue='type', **kwargs)\n",
    "    g = g.map(plt.plot, 'epoch', 'Acc', marker='.')\n",
    "\n",
    "    def show_acc(x, y, metric, **kwargs):\n",
    "        plt.scatter(x, y, alpha=0.3, s=1)\n",
    "        metric = \"Test Acc: {:1.3f}\".format(list(metric.values)[0])\n",
    "        plt.text(0.05, 0.95, metric,  horizontalalignment='left', verticalalignment='center', transform=plt.gca().transAxes, bbox=dict(facecolor='yellow', alpha=0.5, boxstyle=\"round,pad=0.1\"))\n",
    "    g = g.map(show_acc, 'epoch', 'Acc', 'test_acc')\n",
    "\n",
    "    g.add_legend()\n",
    "    g.fig.suptitle('Train Accuracy vs Val Accuracy')\n",
    "    plt.subplots_adjust(top=0.89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience = 15, verbose=False, tolerance=0, path='checkpoint.pt'):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        # If tolereance is large value, then early stopping criterion is more strict.\n",
    "        self.tolerance = tolerance\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.val_loss_last = np.Inf\n",
    "        self.path = path\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        if self.val_loss_min is np.Inf:\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.val_loss_last = val_loss\n",
    "\n",
    "        elif self.val_loss_last < val_loss + self.tolerance :    \n",
    "            self.counter += 1\n",
    "            print('EarlyStopping counter: {} out of {}'.format(self.counter, self.patience))\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.val_loss_last = val_loss\n",
    "            if(self.val_loss_min > val_loss):\n",
    "                self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            print('Least validation loss decreased (%.6f --> %.6f).  Saving model ...'%(self.val_loss_min, val_loss))\n",
    "\n",
    "        torch.save(model, self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clf_eval(y_test, y_pred):\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    tt = confusion[0,0]\n",
    "    tf = confusion[0,1]\n",
    "    ft = confusion[1,0]\n",
    "    ff = confusion[1,1]\n",
    "\n",
    "#     print('오차행렬:\\n', confusion)\n",
    "#     print('\\n정확도: {:.4f}'.format(accuracy))\n",
    "#     print('정밀도: {:.4f}'.format(precision))\n",
    "#     print('재현율: {:.4f}'.format(recall))    \n",
    "#     print('양성예측율: {:.4f}'.format(tt/(tt+tf)))\n",
    "#     print('음성예측율: {:.4f}'.format(ff/(ft+ff)))    \n",
    "#     print('F1: {:.4f}'.format(F1))\n",
    "    return tt, tf, ft, ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "id": "D2umJYQT5ZzK",
    "outputId": "96e326e4-74a7-4428-b5f5-213e83ae931c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=128, device='cuda:0', dropout=0.0, epoch=1000, exp_name='exp1_lr', hid_dim=50, input_dim=20, l2=1e-05, lr=0.001, n_layers=1, optim='Adam', use_bn=True)\n",
      "Epoch 1, Acc(train/val): 0.71/0.84, Loss(train/val) 1.14667/0.98894. Took 1.33 sec\n",
      "Epoch 2, Acc(train/val): 0.87/0.88, Loss(train/val) 0.85860/0.93551. Took 1.28 sec\n",
      "Epoch 3, Acc(train/val): 0.90/0.89, Loss(train/val) 0.74992/0.73762. Took 1.31 sec\n",
      "Epoch 4, Acc(train/val): 0.91/0.90, Loss(train/val) 0.70642/0.77045. Took 1.30 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 5, Acc(train/val): 0.91/0.89, Loss(train/val) 0.69060/1.69424. Took 1.30 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 6, Acc(train/val): 0.93/0.88, Loss(train/val) 0.66739/1.29794. Took 1.31 sec\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 7, Acc(train/val): 0.93/0.90, Loss(train/val) 0.63446/0.74726. Took 1.31 sec\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 8, Acc(train/val): 0.93/0.91, Loss(train/val) 0.61737/0.74239. Took 1.34 sec\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 9, Acc(train/val): 0.94/0.91, Loss(train/val) 0.60328/0.74715. Took 1.29 sec\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 10, Acc(train/val): 0.94/0.91, Loss(train/val) 0.59659/0.77981. Took 1.29 sec\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 11, Acc(train/val): 0.94/0.92, Loss(train/val) 0.60436/0.89353. Took 1.35 sec\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Epoch 12, Acc(train/val): 0.94/0.92, Loss(train/val) 0.57759/0.77429. Took 1.34 sec\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Epoch 13, Acc(train/val): 0.94/0.93, Loss(train/val) 0.57630/0.68813. Took 1.37 sec\n",
      "Epoch 14, Acc(train/val): 0.94/0.93, Loss(train/val) 0.56435/0.70309. Took 1.29 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 15, Acc(train/val): 0.94/0.93, Loss(train/val) 0.55770/0.73135. Took 1.33 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 16, Acc(train/val): 0.95/0.93, Loss(train/val) 0.55244/0.69049. Took 1.32 sec\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 17, Acc(train/val): 0.95/0.93, Loss(train/val) 0.54773/0.95959. Took 1.29 sec\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 18, Acc(train/val): 0.94/0.92, Loss(train/val) 0.55818/0.77427. Took 1.33 sec\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 19, Acc(train/val): 0.95/0.90, Loss(train/val) 0.54882/1.53746. Took 1.36 sec\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 20, Acc(train/val): 0.95/0.92, Loss(train/val) 0.53593/1.03301. Took 1.32 sec\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 21, Acc(train/val): 0.95/0.91, Loss(train/val) 0.52519/1.30460. Took 1.31 sec\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Epoch 22, Acc(train/val): 0.95/0.90, Loss(train/val) 0.51838/1.42821. Took 1.30 sec\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Epoch 23, Acc(train/val): 0.95/0.81, Loss(train/val) 0.51201/2.17024. Took 1.32 sec\n",
      "EarlyStopping counter: 10 out of 20\n",
      "Epoch 24, Acc(train/val): 0.96/0.84, Loss(train/val) 0.50506/1.97860. Took 1.31 sec\n",
      "EarlyStopping counter: 11 out of 20\n",
      "Epoch 25, Acc(train/val): 0.96/0.85, Loss(train/val) 0.50281/1.96254. Took 1.31 sec\n",
      "EarlyStopping counter: 12 out of 20\n",
      "Epoch 26, Acc(train/val): 0.96/0.82, Loss(train/val) 0.49163/2.11721. Took 1.30 sec\n",
      "EarlyStopping counter: 13 out of 20\n",
      "Epoch 27, Acc(train/val): 0.96/0.83, Loss(train/val) 0.48512/2.02705. Took 1.33 sec\n",
      "EarlyStopping counter: 14 out of 20\n",
      "Epoch 28, Acc(train/val): 0.96/0.88, Loss(train/val) 0.49027/1.61825. Took 1.31 sec\n",
      "EarlyStopping counter: 15 out of 20\n",
      "Epoch 29, Acc(train/val): 0.96/0.90, Loss(train/val) 0.47727/1.42413. Took 1.35 sec\n",
      "EarlyStopping counter: 16 out of 20\n",
      "Epoch 30, Acc(train/val): 0.96/0.91, Loss(train/val) 0.48391/1.30475. Took 1.30 sec\n",
      "EarlyStopping counter: 17 out of 20\n",
      "Epoch 31, Acc(train/val): 0.96/0.92, Loss(train/val) 0.47066/0.78325. Took 1.33 sec\n",
      "EarlyStopping counter: 18 out of 20\n",
      "Epoch 32, Acc(train/val): 0.96/0.93, Loss(train/val) 0.45953/0.68871. Took 1.33 sec\n",
      "EarlyStopping counter: 19 out of 20\n",
      "Epoch 33, Acc(train/val): 0.97/0.93, Loss(train/val) 0.44871/0.67937. Took 1.34 sec\n",
      "Epoch 34, Acc(train/val): 0.97/0.92, Loss(train/val) 0.44144/0.83957. Took 1.32 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 35, Acc(train/val): 0.97/0.92, Loss(train/val) 0.44065/0.92543. Took 1.34 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 36, Acc(train/val): 0.97/0.91, Loss(train/val) 0.42429/0.93186. Took 1.29 sec\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 37, Acc(train/val): 0.97/0.92, Loss(train/val) 0.44759/0.76473. Took 1.33 sec\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 38, Acc(train/val): 0.97/0.93, Loss(train/val) 0.45628/0.70075. Took 1.31 sec\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 39, Acc(train/val): 0.97/0.92, Loss(train/val) 0.41991/0.71512. Took 1.31 sec\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 40, Acc(train/val): 0.97/0.92, Loss(train/val) 0.40749/0.84184. Took 1.30 sec\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 41, Acc(train/val): 0.97/0.90, Loss(train/val) 0.40182/1.28595. Took 1.32 sec\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Epoch 42, Acc(train/val): 0.97/0.92, Loss(train/val) 0.38622/0.91714. Took 1.30 sec\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Epoch 43, Acc(train/val): 0.97/0.92, Loss(train/val) 0.38312/0.89836. Took 1.31 sec\n",
      "EarlyStopping counter: 10 out of 20\n",
      "Epoch 44, Acc(train/val): 0.97/0.92, Loss(train/val) 0.38307/0.85057. Took 1.30 sec\n",
      "EarlyStopping counter: 11 out of 20\n",
      "Epoch 45, Acc(train/val): 0.97/0.92, Loss(train/val) 0.37831/0.94017. Took 1.33 sec\n",
      "EarlyStopping counter: 12 out of 20\n",
      "Epoch 46, Acc(train/val): 0.97/0.92, Loss(train/val) 0.38356/0.85050. Took 1.29 sec\n",
      "EarlyStopping counter: 13 out of 20\n",
      "Epoch 47, Acc(train/val): 0.98/0.92, Loss(train/val) 0.37358/0.89448. Took 1.33 sec\n",
      "EarlyStopping counter: 14 out of 20\n",
      "Epoch 48, Acc(train/val): 0.98/0.91, Loss(train/val) 0.35234/1.28575. Took 1.29 sec\n",
      "EarlyStopping counter: 15 out of 20\n",
      "Epoch 49, Acc(train/val): 0.98/0.92, Loss(train/val) 0.34868/1.10614. Took 1.34 sec\n",
      "EarlyStopping counter: 16 out of 20\n",
      "Epoch 50, Acc(train/val): 0.98/0.93, Loss(train/val) 0.34821/0.94044. Took 1.30 sec\n",
      "EarlyStopping counter: 17 out of 20\n",
      "Epoch 51, Acc(train/val): 0.98/0.92, Loss(train/val) 0.36305/0.94302. Took 1.31 sec\n",
      "EarlyStopping counter: 18 out of 20\n",
      "Epoch 52, Acc(train/val): 0.98/0.93, Loss(train/val) 0.36820/0.82456. Took 1.30 sec\n",
      "EarlyStopping counter: 19 out of 20\n",
      "Epoch 53, Acc(train/val): 0.98/0.93, Loss(train/val) 0.34884/0.89894. Took 1.29 sec\n",
      "EarlyStopping counter: 20 out of 20\n",
      "Early stopping\n",
      "*** auc score : 0.94349 ***\n",
      "0.943487054060228,0.9430741657420841,0.9849757683949727,0.9430741657420841,0.9603018445666883,10905,636,31,145\n",
      "Namespace(batch_size=128, device='cuda:0', dropout=0.0, epoch=1000, exp_name='exp1_lr', hid_dim=50, input_dim=20, l2=1e-05, lr=0.001, n_layers=2, optim='Adam', use_bn=True)\n",
      "Epoch 1, Acc(train/val): 0.77/0.90, Loss(train/val) 1.06366/1.08854. Took 1.68 sec\n",
      "Epoch 2, Acc(train/val): 0.91/0.76, Loss(train/val) 0.72564/2.14966. Took 1.67 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 3, Acc(train/val): 0.92/0.86, Loss(train/val) 0.66979/1.74207. Took 1.66 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 4, Acc(train/val): 0.93/0.92, Loss(train/val) 0.64867/0.71576. Took 1.68 sec\n",
      "Epoch 5, Acc(train/val): 0.93/0.92, Loss(train/val) 0.61917/0.69298. Took 1.66 sec\n",
      "Epoch 6, Acc(train/val): 0.93/0.93, Loss(train/val) 0.60622/0.69417. Took 1.75 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 7, Acc(train/val): 0.93/0.93, Loss(train/val) 0.60227/0.67890. Took 1.65 sec\n",
      "Epoch 8, Acc(train/val): 0.94/0.93, Loss(train/val) 0.59435/0.68051. Took 1.73 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 9, Acc(train/val): 0.94/0.93, Loss(train/val) 0.58528/1.39189. Took 1.66 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 10, Acc(train/val): 0.94/0.93, Loss(train/val) 0.58213/0.67530. Took 2.36 sec\n",
      "Epoch 11, Acc(train/val): 0.94/0.92, Loss(train/val) 0.57609/0.95216. Took 2.38 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 12, Acc(train/val): 0.94/0.90, Loss(train/val) 0.57148/1.86807. Took 1.64 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 13, Acc(train/val): 0.94/0.85, Loss(train/val) 0.57110/2.49887. Took 1.68 sec\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 14, Acc(train/val): 0.94/0.91, Loss(train/val) 0.56641/1.68128. Took 1.74 sec\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 15, Acc(train/val): 0.94/0.90, Loss(train/val) 0.56136/1.85976. Took 1.69 sec\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 16, Acc(train/val): 0.94/0.91, Loss(train/val) 0.55565/1.37254. Took 1.69 sec\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 17, Acc(train/val): 0.94/0.91, Loss(train/val) 0.55259/1.30350. Took 1.68 sec\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 18, Acc(train/val): 0.95/0.93, Loss(train/val) 0.54928/0.90949. Took 1.66 sec\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Epoch 19, Acc(train/val): 0.95/0.93, Loss(train/val) 0.54273/0.66191. Took 1.68 sec\n",
      "Epoch 20, Acc(train/val): 0.95/0.93, Loss(train/val) 0.53685/0.69001. Took 1.65 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 21, Acc(train/val): 0.95/0.92, Loss(train/val) 0.53271/0.82659. Took 1.68 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 22, Acc(train/val): 0.95/0.91, Loss(train/val) 0.52842/0.79480. Took 1.70 sec\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 23, Acc(train/val): 0.95/0.90, Loss(train/val) 0.52322/1.16673. Took 1.76 sec\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 24, Acc(train/val): 0.95/0.92, Loss(train/val) 0.51724/0.71906. Took 1.66 sec\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 25, Acc(train/val): 0.95/0.92, Loss(train/val) 0.51116/0.77088. Took 1.70 sec\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 26, Acc(train/val): 0.96/0.91, Loss(train/val) 0.50339/0.75475. Took 1.66 sec\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 27, Acc(train/val): 0.96/0.92, Loss(train/val) 0.50092/0.70973. Took 1.69 sec\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Epoch 28, Acc(train/val): 0.96/0.93, Loss(train/val) 0.49722/0.66527. Took 1.67 sec\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Epoch 29, Acc(train/val): 0.96/0.91, Loss(train/val) 0.49314/0.73286. Took 1.65 sec\n",
      "EarlyStopping counter: 10 out of 20\n",
      "Epoch 30, Acc(train/val): 0.96/0.91, Loss(train/val) 0.48546/0.73093. Took 1.72 sec\n",
      "EarlyStopping counter: 11 out of 20\n",
      "Epoch 31, Acc(train/val): 0.96/0.91, Loss(train/val) 0.47848/0.76625. Took 1.72 sec\n",
      "EarlyStopping counter: 12 out of 20\n",
      "Epoch 32, Acc(train/val): 0.96/0.91, Loss(train/val) 0.47606/0.75476. Took 1.67 sec\n",
      "EarlyStopping counter: 13 out of 20\n",
      "Epoch 33, Acc(train/val): 0.96/0.92, Loss(train/val) 0.47404/0.73176. Took 1.75 sec\n",
      "EarlyStopping counter: 14 out of 20\n",
      "Epoch 34, Acc(train/val): 0.96/0.92, Loss(train/val) 0.46254/0.78496. Took 1.72 sec\n",
      "EarlyStopping counter: 15 out of 20\n",
      "Epoch 35, Acc(train/val): 0.96/0.92, Loss(train/val) 0.46064/0.73125. Took 1.67 sec\n",
      "EarlyStopping counter: 16 out of 20\n",
      "Epoch 36, Acc(train/val): 0.96/0.93, Loss(train/val) 0.45985/0.70047. Took 1.70 sec\n",
      "EarlyStopping counter: 17 out of 20\n",
      "Epoch 37, Acc(train/val): 0.97/0.92, Loss(train/val) 0.44600/0.74200. Took 1.72 sec\n",
      "EarlyStopping counter: 18 out of 20\n",
      "Epoch 38, Acc(train/val): 0.97/0.92, Loss(train/val) 0.43423/0.73834. Took 1.67 sec\n",
      "EarlyStopping counter: 19 out of 20\n",
      "Epoch 39, Acc(train/val): 0.97/0.93, Loss(train/val) 0.43053/0.73010. Took 1.66 sec\n",
      "EarlyStopping counter: 20 out of 20\n",
      "Early stopping\n",
      "*** auc score : 0.95098 ***\n",
      "0.9509810871911208,0.9427327814286933,0.9849605364625574,0.9427327814286933,0.9601023782156601,10901,640,31,145\n",
      "Namespace(batch_size=128, device='cuda:0', dropout=0.0, epoch=1000, exp_name='exp1_lr', hid_dim=50, input_dim=20, l2=1e-05, lr=0.001, n_layers=3, optim='Adam', use_bn=True)\n",
      "Epoch 1, Acc(train/val): 0.78/0.88, Loss(train/val) 1.08108/0.87121. Took 2.05 sec\n",
      "Epoch 2, Acc(train/val): 0.90/0.90, Loss(train/val) 0.75543/0.86247. Took 2.07 sec\n",
      "Epoch 3, Acc(train/val): 0.92/0.91, Loss(train/val) 0.67638/0.85653. Took 1.97 sec\n",
      "Epoch 4, Acc(train/val): 0.93/0.92, Loss(train/val) 0.63962/0.86812. Took 2.17 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 5, Acc(train/val): 0.93/0.91, Loss(train/val) 0.62384/0.85129. Took 2.03 sec\n",
      "Epoch 6, Acc(train/val): 0.93/0.92, Loss(train/val) 0.61006/0.69066. Took 2.04 sec\n",
      "Epoch 7, Acc(train/val): 0.94/0.92, Loss(train/val) 0.59929/0.72818. Took 2.11 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 8, Acc(train/val): 0.94/0.92, Loss(train/val) 0.59279/0.70950. Took 2.01 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 9, Acc(train/val): 0.94/0.93, Loss(train/val) 0.58542/0.69608. Took 2.08 sec\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 10, Acc(train/val): 0.94/0.94, Loss(train/val) 0.58270/1.80032. Took 2.10 sec\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 11, Acc(train/val): 0.94/0.93, Loss(train/val) 0.57690/0.82208. Took 2.02 sec\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 12, Acc(train/val): 0.94/0.80, Loss(train/val) 0.56996/2.36897. Took 2.04 sec\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 13, Acc(train/val): 0.94/0.90, Loss(train/val) 0.56740/1.33774. Took 1.99 sec\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 14, Acc(train/val): 0.94/0.92, Loss(train/val) 0.56165/0.83017. Took 2.03 sec\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Epoch 15, Acc(train/val): 0.94/0.90, Loss(train/val) 0.55368/1.18606. Took 2.04 sec\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Epoch 16, Acc(train/val): 0.95/0.89, Loss(train/val) 0.55291/1.09284. Took 1.98 sec\n",
      "EarlyStopping counter: 10 out of 20\n",
      "Epoch 17, Acc(train/val): 0.95/0.89, Loss(train/val) 0.54645/1.48475. Took 2.04 sec\n",
      "EarlyStopping counter: 11 out of 20\n",
      "Epoch 18, Acc(train/val): 0.95/0.69, Loss(train/val) 0.54183/2.43958. Took 2.05 sec\n",
      "EarlyStopping counter: 12 out of 20\n",
      "Epoch 19, Acc(train/val): 0.95/0.90, Loss(train/val) 0.54039/1.07989. Took 2.24 sec\n",
      "EarlyStopping counter: 13 out of 20\n",
      "Epoch 20, Acc(train/val): 0.95/0.90, Loss(train/val) 0.53727/1.14670. Took 2.05 sec\n",
      "EarlyStopping counter: 14 out of 20\n",
      "Epoch 21, Acc(train/val): 0.95/0.89, Loss(train/val) 0.53014/1.02615. Took 2.01 sec\n",
      "EarlyStopping counter: 15 out of 20\n",
      "Epoch 22, Acc(train/val): 0.95/0.90, Loss(train/val) 0.53319/0.95668. Took 2.04 sec\n",
      "EarlyStopping counter: 16 out of 20\n",
      "Epoch 23, Acc(train/val): 0.95/0.90, Loss(train/val) 0.52594/0.92566. Took 2.02 sec\n",
      "EarlyStopping counter: 17 out of 20\n",
      "Epoch 24, Acc(train/val): 0.95/0.90, Loss(train/val) 0.52164/1.06763. Took 2.07 sec\n",
      "EarlyStopping counter: 18 out of 20\n",
      "Epoch 25, Acc(train/val): 0.95/0.90, Loss(train/val) 0.51687/0.84174. Took 2.12 sec\n",
      "EarlyStopping counter: 19 out of 20\n",
      "Epoch 26, Acc(train/val): 0.95/0.90, Loss(train/val) 0.51894/0.94387. Took 2.00 sec\n",
      "EarlyStopping counter: 20 out of 20\n",
      "Early stopping\n",
      "*** auc score : 0.94114 ***\n",
      "0.9411416609558019,0.9221643765468976,0.9847562676912621,0.9221643765468976,0.9482731910866158,10655,886,26,150\n",
      "Namespace(batch_size=128, device='cuda:0', dropout=0.0, epoch=1000, exp_name='exp1_lr', hid_dim=50, input_dim=20, l2=1e-05, lr=0.0001, n_layers=1, optim='Adam', use_bn=True)\n",
      "Epoch 1, Acc(train/val): 0.57/0.65, Loss(train/val) 1.25632/1.29635. Took 1.31 sec\n",
      "Epoch 2, Acc(train/val): 0.66/0.68, Loss(train/val) 1.21114/1.26457. Took 1.33 sec\n",
      "Epoch 3, Acc(train/val): 0.70/0.72, Loss(train/val) 1.17403/1.21835. Took 1.33 sec\n",
      "Epoch 4, Acc(train/val): 0.74/0.78, Loss(train/val) 1.11171/1.13424. Took 1.33 sec\n",
      "Epoch 5, Acc(train/val): 0.80/0.83, Loss(train/val) 1.01961/1.01612. Took 1.31 sec\n",
      "Epoch 6, Acc(train/val): 0.85/0.87, Loss(train/val) 0.90945/0.91768. Took 1.33 sec\n",
      "Epoch 7, Acc(train/val): 0.88/0.88, Loss(train/val) 0.82459/0.86052. Took 1.36 sec\n",
      "Epoch 8, Acc(train/val): 0.89/0.89, Loss(train/val) 0.77467/0.81594. Took 1.34 sec\n",
      "Epoch 9, Acc(train/val): 0.90/0.90, Loss(train/val) 0.74425/0.78363. Took 1.32 sec\n",
      "Epoch 10, Acc(train/val): 0.91/0.91, Loss(train/val) 0.72226/0.76372. Took 1.30 sec\n",
      "Epoch 11, Acc(train/val): 0.91/0.91, Loss(train/val) 0.70378/0.76712. Took 1.32 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 12, Acc(train/val): 0.91/0.91, Loss(train/val) 0.68852/0.77063. Took 1.32 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 13, Acc(train/val): 0.92/0.91, Loss(train/val) 0.67647/0.78287. Took 1.31 sec\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 14, Acc(train/val): 0.92/0.91, Loss(train/val) 0.66605/0.79226. Took 1.31 sec\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 15, Acc(train/val): 0.92/0.91, Loss(train/val) 0.65871/0.84238. Took 1.30 sec\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 16, Acc(train/val): 0.92/0.91, Loss(train/val) 0.65155/0.88416. Took 1.30 sec\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 17, Acc(train/val): 0.92/0.92, Loss(train/val) 0.64652/0.88985. Took 1.32 sec\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 18, Acc(train/val): 0.93/0.91, Loss(train/val) 0.64135/0.94302. Took 1.36 sec\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Epoch 19, Acc(train/val): 0.93/0.91, Loss(train/val) 0.63628/1.01415. Took 1.31 sec\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Epoch 20, Acc(train/val): 0.93/0.91, Loss(train/val) 0.63224/1.01493. Took 1.32 sec\n",
      "EarlyStopping counter: 10 out of 20\n",
      "Epoch 21, Acc(train/val): 0.93/0.91, Loss(train/val) 0.62800/1.04890. Took 1.38 sec\n",
      "EarlyStopping counter: 11 out of 20\n",
      "Epoch 22, Acc(train/val): 0.93/0.91, Loss(train/val) 0.62448/1.07020. Took 1.33 sec\n",
      "EarlyStopping counter: 12 out of 20\n",
      "Epoch 23, Acc(train/val): 0.93/0.91, Loss(train/val) 0.62081/1.05437. Took 1.33 sec\n",
      "EarlyStopping counter: 13 out of 20\n",
      "Epoch 24, Acc(train/val): 0.93/0.92, Loss(train/val) 0.61713/1.01844. Took 1.34 sec\n",
      "EarlyStopping counter: 14 out of 20\n",
      "Epoch 25, Acc(train/val): 0.93/0.92, Loss(train/val) 0.61281/1.04643. Took 1.30 sec\n",
      "EarlyStopping counter: 15 out of 20\n",
      "Epoch 26, Acc(train/val): 0.93/0.92, Loss(train/val) 0.61007/1.02885. Took 1.29 sec\n",
      "EarlyStopping counter: 16 out of 20\n",
      "Epoch 27, Acc(train/val): 0.93/0.92, Loss(train/val) 0.60658/1.05140. Took 1.31 sec\n",
      "EarlyStopping counter: 17 out of 20\n",
      "Epoch 28, Acc(train/val): 0.93/0.91, Loss(train/val) 0.60388/1.11418. Took 1.30 sec\n",
      "EarlyStopping counter: 18 out of 20\n",
      "Epoch 29, Acc(train/val): 0.94/0.91, Loss(train/val) 0.60091/1.13215. Took 1.37 sec\n",
      "EarlyStopping counter: 19 out of 20\n",
      "Epoch 30, Acc(train/val): 0.94/0.92, Loss(train/val) 0.59771/1.03822. Took 1.32 sec\n",
      "EarlyStopping counter: 20 out of 20\n",
      "Early stopping\n",
      "*** auc score : 0.89182 ***\n",
      "0.8918170199525801,0.9353076726124434,0.9820067278181925,0.9353076726124434,0.9552938831018637,10840,701,57,119\n",
      "Namespace(batch_size=128, device='cuda:0', dropout=0.0, epoch=1000, exp_name='exp1_lr', hid_dim=50, input_dim=20, l2=1e-05, lr=0.0001, n_layers=2, optim='Adam', use_bn=True)\n",
      "Epoch 1, Acc(train/val): 0.59/0.69, Loss(train/val) 1.25365/1.27362. Took 1.67 sec\n",
      "Epoch 2, Acc(train/val): 0.71/0.72, Loss(train/val) 1.17072/1.21620. Took 1.66 sec\n",
      "Epoch 3, Acc(train/val): 0.77/0.80, Loss(train/val) 1.07950/1.10922. Took 1.68 sec\n",
      "Epoch 4, Acc(train/val): 0.84/0.85, Loss(train/val) 0.96452/0.99307. Took 1.70 sec\n",
      "Epoch 5, Acc(train/val): 0.87/0.87, Loss(train/val) 0.85664/0.95881. Took 1.76 sec\n",
      "Epoch 6, Acc(train/val): 0.89/0.88, Loss(train/val) 0.78400/0.97890. Took 1.67 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 7, Acc(train/val): 0.90/0.89, Loss(train/val) 0.74407/1.00916. Took 1.67 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 8, Acc(train/val): 0.91/0.90, Loss(train/val) 0.72021/0.99358. Took 1.78 sec\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 9, Acc(train/val): 0.91/0.90, Loss(train/val) 0.70325/1.03199. Took 1.75 sec\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 10, Acc(train/val): 0.92/0.90, Loss(train/val) 0.68973/1.12923. Took 1.70 sec\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 11, Acc(train/val): 0.92/0.90, Loss(train/val) 0.67824/1.20706. Took 1.73 sec\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 12, Acc(train/val): 0.92/0.91, Loss(train/val) 0.66999/1.25007. Took 1.71 sec\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 13, Acc(train/val): 0.92/0.90, Loss(train/val) 0.66334/1.50349. Took 1.79 sec\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Epoch 14, Acc(train/val): 0.93/0.90, Loss(train/val) 0.65751/1.65741. Took 1.69 sec\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Epoch 15, Acc(train/val): 0.93/0.89, Loss(train/val) 0.65136/1.81437. Took 1.69 sec\n",
      "EarlyStopping counter: 10 out of 20\n",
      "Epoch 16, Acc(train/val): 0.93/0.89, Loss(train/val) 0.64538/1.84666. Took 1.80 sec\n",
      "EarlyStopping counter: 11 out of 20\n",
      "Epoch 17, Acc(train/val): 0.93/0.88, Loss(train/val) 0.64127/1.94411. Took 1.70 sec\n",
      "EarlyStopping counter: 12 out of 20\n",
      "Epoch 18, Acc(train/val): 0.93/0.87, Loss(train/val) 0.63685/2.02796. Took 1.69 sec\n",
      "EarlyStopping counter: 13 out of 20\n",
      "Epoch 19, Acc(train/val): 0.93/0.86, Loss(train/val) 0.63293/2.05027. Took 1.66 sec\n",
      "EarlyStopping counter: 14 out of 20\n",
      "Epoch 20, Acc(train/val): 0.93/0.85, Loss(train/val) 0.62948/2.12130. Took 1.66 sec\n",
      "EarlyStopping counter: 15 out of 20\n",
      "Epoch 21, Acc(train/val): 0.93/0.85, Loss(train/val) 0.62634/2.11545. Took 1.73 sec\n",
      "EarlyStopping counter: 16 out of 20\n",
      "Epoch 22, Acc(train/val): 0.93/0.85, Loss(train/val) 0.62322/2.08547. Took 1.69 sec\n",
      "EarlyStopping counter: 17 out of 20\n",
      "Epoch 23, Acc(train/val): 0.93/0.86, Loss(train/val) 0.62026/1.99908. Took 1.72 sec\n",
      "EarlyStopping counter: 18 out of 20\n",
      "Epoch 24, Acc(train/val): 0.93/0.86, Loss(train/val) 0.61752/1.96493. Took 1.72 sec\n",
      "EarlyStopping counter: 19 out of 20\n",
      "Epoch 25, Acc(train/val): 0.93/0.87, Loss(train/val) 0.61472/1.92546. Took 1.67 sec\n",
      "EarlyStopping counter: 20 out of 20\n",
      "Early stopping\n",
      "*** auc score : 0.87264 ***\n",
      "0.8726403297335192,0.9657762225825723,0.9783298275649628,0.9657762225825723,0.9714926964335666,11249,292,109,67\n",
      "Namespace(batch_size=128, device='cuda:0', dropout=0.0, epoch=1000, exp_name='exp1_lr', hid_dim=50, input_dim=20, l2=1e-05, lr=0.0001, n_layers=3, optim='Adam', use_bn=True)\n",
      "Epoch 1, Acc(train/val): 0.64/0.71, Loss(train/val) 1.22726/1.25139. Took 2.07 sec\n",
      "Epoch 2, Acc(train/val): 0.71/0.76, Loss(train/val) 1.15801/1.18807. Took 1.96 sec\n",
      "Epoch 3, Acc(train/val): 0.80/0.85, Loss(train/val) 1.05330/1.05945. Took 2.06 sec\n",
      "Epoch 4, Acc(train/val): 0.87/0.89, Loss(train/val) 0.88869/0.84680. Took 2.02 sec\n",
      "Epoch 5, Acc(train/val): 0.90/0.90, Loss(train/val) 0.78696/0.78480. Took 2.14 sec\n",
      "Epoch 6, Acc(train/val): 0.91/0.91, Loss(train/val) 0.73176/0.76204. Took 2.05 sec\n",
      "Epoch 7, Acc(train/val): 0.91/0.91, Loss(train/val) 0.69763/0.73846. Took 2.07 sec\n",
      "Epoch 8, Acc(train/val): 0.92/0.91, Loss(train/val) 0.67738/0.87462. Took 2.16 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 9, Acc(train/val): 0.92/0.91, Loss(train/val) 0.66799/0.76119. Took 2.06 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 10, Acc(train/val): 0.92/0.91, Loss(train/val) 0.65432/0.81140. Took 2.20 sec\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 11, Acc(train/val): 0.93/0.92, Loss(train/val) 0.64403/0.86680. Took 2.05 sec\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 12, Acc(train/val): 0.93/0.92, Loss(train/val) 0.63665/0.88762. Took 2.05 sec\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 13, Acc(train/val): 0.93/0.92, Loss(train/val) 0.63149/0.83704. Took 2.03 sec\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 14, Acc(train/val): 0.93/0.92, Loss(train/val) 0.62665/0.84266. Took 2.03 sec\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 15, Acc(train/val): 0.93/0.92, Loss(train/val) 0.62275/0.92482. Took 1.97 sec\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Epoch 16, Acc(train/val): 0.93/0.92, Loss(train/val) 0.61927/1.05774. Took 1.98 sec\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Epoch 17, Acc(train/val): 0.93/0.92, Loss(train/val) 0.61674/1.27715. Took 2.05 sec\n",
      "EarlyStopping counter: 10 out of 20\n",
      "Epoch 18, Acc(train/val): 0.93/0.92, Loss(train/val) 0.61443/1.29635. Took 2.02 sec\n",
      "EarlyStopping counter: 11 out of 20\n",
      "Epoch 19, Acc(train/val): 0.93/0.92, Loss(train/val) 0.61133/1.27301. Took 2.01 sec\n",
      "EarlyStopping counter: 12 out of 20\n",
      "Epoch 20, Acc(train/val): 0.93/0.92, Loss(train/val) 0.60952/1.20381. Took 2.05 sec\n",
      "EarlyStopping counter: 13 out of 20\n",
      "Epoch 21, Acc(train/val): 0.94/0.92, Loss(train/val) 0.60758/1.16214. Took 2.03 sec\n",
      "EarlyStopping counter: 14 out of 20\n",
      "Epoch 22, Acc(train/val): 0.94/0.92, Loss(train/val) 0.60540/1.11866. Took 2.08 sec\n",
      "EarlyStopping counter: 15 out of 20\n",
      "Epoch 23, Acc(train/val): 0.94/0.92, Loss(train/val) 0.60378/1.02879. Took 2.21 sec\n",
      "EarlyStopping counter: 16 out of 20\n",
      "Epoch 24, Acc(train/val): 0.94/0.92, Loss(train/val) 0.60093/0.96106. Took 2.04 sec\n",
      "EarlyStopping counter: 17 out of 20\n",
      "Epoch 25, Acc(train/val): 0.94/0.92, Loss(train/val) 0.59973/0.92134. Took 1.97 sec\n",
      "EarlyStopping counter: 18 out of 20\n",
      "Epoch 26, Acc(train/val): 0.94/0.92, Loss(train/val) 0.59887/1.06186. Took 2.04 sec\n",
      "EarlyStopping counter: 19 out of 20\n",
      "Epoch 27, Acc(train/val): 0.94/0.93, Loss(train/val) 0.59793/0.93816. Took 2.05 sec\n",
      "EarlyStopping counter: 20 out of 20\n",
      "Early stopping\n",
      "*** auc score : 0.91246 ***\n",
      "0.9124553961764775,0.9424767431936503,0.9834208221341216,0.9424767431936503,0.9596549039302263,10913,628,46,130\n",
      "Namespace(batch_size=128, device='cuda:0', dropout=0.0, epoch=1000, exp_name='exp1_lr', hid_dim=50, input_dim=20, l2=1e-05, lr=1e-05, n_layers=1, optim='Adam', use_bn=True)\n",
      "Epoch 1, Acc(train/val): 0.55/0.54, Loss(train/val) 1.26774/1.35042. Took 1.33 sec\n",
      "Epoch 2, Acc(train/val): 0.58/0.56, Loss(train/val) 1.26181/1.34531. Took 1.33 sec\n",
      "Epoch 3, Acc(train/val): 0.59/0.58, Loss(train/val) 1.25676/1.34079. Took 1.30 sec\n",
      "Epoch 4, Acc(train/val): 0.60/0.59, Loss(train/val) 1.25224/1.33677. Took 1.38 sec\n",
      "Epoch 5, Acc(train/val): 0.62/0.60, Loss(train/val) 1.24807/1.33302. Took 1.32 sec\n",
      "Epoch 6, Acc(train/val): 0.63/0.61, Loss(train/val) 1.24412/1.32952. Took 1.30 sec\n",
      "Epoch 7, Acc(train/val): 0.64/0.62, Loss(train/val) 1.24042/1.32617. Took 1.35 sec\n",
      "Epoch 8, Acc(train/val): 0.64/0.63, Loss(train/val) 1.23690/1.32292. Took 1.30 sec\n",
      "Epoch 9, Acc(train/val): 0.65/0.64, Loss(train/val) 1.23351/1.31968. Took 1.35 sec\n",
      "Epoch 10, Acc(train/val): 0.65/0.65, Loss(train/val) 1.23020/1.31631. Took 1.32 sec\n",
      "Epoch 11, Acc(train/val): 0.66/0.65, Loss(train/val) 1.22693/1.31296. Took 1.37 sec\n",
      "Epoch 12, Acc(train/val): 0.66/0.66, Loss(train/val) 1.22367/1.30957. Took 1.27 sec\n",
      "Epoch 13, Acc(train/val): 0.67/0.66, Loss(train/val) 1.22030/1.30599. Took 1.33 sec\n",
      "Epoch 14, Acc(train/val): 0.67/0.67, Loss(train/val) 1.21681/1.30225. Took 1.34 sec\n",
      "Epoch 15, Acc(train/val): 0.67/0.67, Loss(train/val) 1.21317/1.29831. Took 1.29 sec\n",
      "Epoch 16, Acc(train/val): 0.68/0.68, Loss(train/val) 1.20938/1.29416. Took 1.31 sec\n",
      "Epoch 17, Acc(train/val): 0.68/0.68, Loss(train/val) 1.20541/1.28969. Took 1.36 sec\n",
      "Epoch 18, Acc(train/val): 0.68/0.68, Loss(train/val) 1.20118/1.28473. Took 1.33 sec\n",
      "Epoch 19, Acc(train/val): 0.69/0.69, Loss(train/val) 1.19652/1.27928. Took 1.41 sec\n",
      "Epoch 20, Acc(train/val): 0.69/0.69, Loss(train/val) 1.19142/1.27320. Took 1.32 sec\n",
      "Epoch 21, Acc(train/val): 0.69/0.70, Loss(train/val) 1.18581/1.26621. Took 1.37 sec\n",
      "Epoch 22, Acc(train/val): 0.70/0.71, Loss(train/val) 1.17954/1.25846. Took 1.33 sec\n",
      "Epoch 23, Acc(train/val): 0.70/0.71, Loss(train/val) 1.17265/1.24996. Took 1.32 sec\n",
      "Epoch 24, Acc(train/val): 0.71/0.72, Loss(train/val) 1.16503/1.24056. Took 1.32 sec\n",
      "Epoch 25, Acc(train/val): 0.72/0.73, Loss(train/val) 1.15665/1.23035. Took 1.33 sec\n",
      "Epoch 26, Acc(train/val): 0.72/0.74, Loss(train/val) 1.14773/1.21963. Took 1.33 sec\n",
      "Epoch 27, Acc(train/val): 0.73/0.74, Loss(train/val) 1.13847/1.20882. Took 1.33 sec\n",
      "Epoch 28, Acc(train/val): 0.74/0.75, Loss(train/val) 1.12897/1.19751. Took 1.32 sec\n",
      "Epoch 29, Acc(train/val): 0.74/0.76, Loss(train/val) 1.11915/1.18611. Took 1.31 sec\n",
      "Epoch 30, Acc(train/val): 0.75/0.76, Loss(train/val) 1.10937/1.17494. Took 1.34 sec\n",
      "Epoch 31, Acc(train/val): 0.76/0.77, Loss(train/val) 1.09971/1.16419. Took 1.33 sec\n",
      "Epoch 32, Acc(train/val): 0.76/0.77, Loss(train/val) 1.09021/1.15397. Took 1.31 sec\n",
      "Epoch 33, Acc(train/val): 0.77/0.78, Loss(train/val) 1.08090/1.14384. Took 1.37 sec\n",
      "Epoch 34, Acc(train/val): 0.78/0.78, Loss(train/val) 1.07178/1.13381. Took 1.32 sec\n",
      "Epoch 35, Acc(train/val): 0.78/0.79, Loss(train/val) 1.06274/1.12405. Took 1.34 sec\n",
      "Epoch 36, Acc(train/val): 0.79/0.79, Loss(train/val) 1.05387/1.11452. Took 1.38 sec\n",
      "Epoch 37, Acc(train/val): 0.79/0.79, Loss(train/val) 1.04510/1.10510. Took 1.31 sec\n",
      "Epoch 38, Acc(train/val): 0.80/0.80, Loss(train/val) 1.03629/1.09576. Took 1.29 sec\n",
      "Epoch 39, Acc(train/val): 0.80/0.80, Loss(train/val) 1.02750/1.08647. Took 1.30 sec\n",
      "Epoch 40, Acc(train/val): 0.81/0.80, Loss(train/val) 1.01890/1.07753. Took 1.33 sec\n",
      "Epoch 41, Acc(train/val): 0.81/0.81, Loss(train/val) 1.01044/1.06878. Took 1.32 sec\n",
      "Epoch 42, Acc(train/val): 0.81/0.81, Loss(train/val) 1.00193/1.05995. Took 1.35 sec\n",
      "Epoch 43, Acc(train/val): 0.82/0.81, Loss(train/val) 0.99343/1.05123. Took 1.29 sec\n",
      "Epoch 44, Acc(train/val): 0.82/0.81, Loss(train/val) 0.98508/1.04256. Took 1.31 sec\n",
      "Epoch 45, Acc(train/val): 0.83/0.82, Loss(train/val) 0.97675/1.03398. Took 2.71 sec\n",
      "Epoch 46, Acc(train/val): 0.83/0.82, Loss(train/val) 0.96845/1.02563. Took 1.34 sec\n",
      "Epoch 47, Acc(train/val): 0.83/0.82, Loss(train/val) 0.96030/1.01752. Took 1.39 sec\n",
      "Epoch 48, Acc(train/val): 0.84/0.82, Loss(train/val) 0.95235/1.00928. Took 1.31 sec\n",
      "Epoch 49, Acc(train/val): 0.84/0.83, Loss(train/val) 0.94452/1.00104. Took 1.30 sec\n",
      "Epoch 50, Acc(train/val): 0.84/0.83, Loss(train/val) 0.93675/0.99293. Took 1.33 sec\n",
      "Epoch 51, Acc(train/val): 0.85/0.83, Loss(train/val) 0.92906/0.98493. Took 1.34 sec\n",
      "Epoch 52, Acc(train/val): 0.85/0.83, Loss(train/val) 0.92155/0.97722. Took 1.36 sec\n",
      "Epoch 53, Acc(train/val): 0.85/0.84, Loss(train/val) 0.91424/0.96968. Took 1.30 sec\n",
      "Epoch 54, Acc(train/val): 0.85/0.84, Loss(train/val) 0.90719/0.96245. Took 1.32 sec\n",
      "Epoch 55, Acc(train/val): 0.85/0.84, Loss(train/val) 0.90029/0.95521. Took 1.31 sec\n",
      "Epoch 56, Acc(train/val): 0.86/0.84, Loss(train/val) 0.89348/0.94823. Took 1.44 sec\n",
      "Epoch 57, Acc(train/val): 0.86/0.84, Loss(train/val) 0.88680/0.94145. Took 1.35 sec\n",
      "Epoch 58, Acc(train/val): 0.86/0.85, Loss(train/val) 0.88034/0.93462. Took 1.32 sec\n",
      "Epoch 59, Acc(train/val): 0.86/0.85, Loss(train/val) 0.87397/0.92813. Took 1.38 sec\n",
      "Epoch 60, Acc(train/val): 0.87/0.85, Loss(train/val) 0.86774/0.92198. Took 1.29 sec\n",
      "Epoch 61, Acc(train/val): 0.87/0.85, Loss(train/val) 0.86171/0.91610. Took 1.30 sec\n",
      "Epoch 62, Acc(train/val): 0.87/0.85, Loss(train/val) 0.85601/0.90997. Took 1.31 sec\n",
      "Epoch 63, Acc(train/val): 0.87/0.86, Loss(train/val) 0.85031/0.90422. Took 1.29 sec\n",
      "Epoch 64, Acc(train/val): 0.87/0.86, Loss(train/val) 0.84480/0.89855. Took 1.32 sec\n",
      "Epoch 65, Acc(train/val): 0.87/0.86, Loss(train/val) 0.83941/0.89316. Took 1.30 sec\n",
      "Epoch 66, Acc(train/val): 0.88/0.86, Loss(train/val) 0.83417/0.88831. Took 1.32 sec\n",
      "Epoch 67, Acc(train/val): 0.88/0.86, Loss(train/val) 0.82934/0.88323. Took 1.31 sec\n",
      "Epoch 68, Acc(train/val): 0.88/0.86, Loss(train/val) 0.82455/0.87821. Took 1.34 sec\n",
      "Epoch 69, Acc(train/val): 0.88/0.86, Loss(train/val) 0.81985/0.87335. Took 1.31 sec\n",
      "Epoch 70, Acc(train/val): 0.88/0.86, Loss(train/val) 0.81529/0.86862. Took 1.29 sec\n",
      "Epoch 71, Acc(train/val): 0.88/0.87, Loss(train/val) 0.81082/0.86420. Took 1.30 sec\n",
      "Epoch 72, Acc(train/val): 0.88/0.87, Loss(train/val) 0.80654/0.85995. Took 1.31 sec\n",
      "Epoch 73, Acc(train/val): 0.88/0.87, Loss(train/val) 0.80253/0.85595. Took 1.29 sec\n",
      "Epoch 74, Acc(train/val): 0.89/0.87, Loss(train/val) 0.79854/0.85222. Took 1.31 sec\n",
      "Epoch 75, Acc(train/val): 0.89/0.87, Loss(train/val) 0.79476/0.84840. Took 1.29 sec\n",
      "Epoch 76, Acc(train/val): 0.89/0.87, Loss(train/val) 0.79097/0.84492. Took 1.32 sec\n",
      "Epoch 77, Acc(train/val): 0.89/0.87, Loss(train/val) 0.78749/0.84168. Took 1.31 sec\n",
      "Epoch 78, Acc(train/val): 0.89/0.87, Loss(train/val) 0.78398/0.83912. Took 1.30 sec\n",
      "Epoch 79, Acc(train/val): 0.89/0.87, Loss(train/val) 0.78073/0.83596. Took 1.30 sec\n",
      "Epoch 80, Acc(train/val): 0.89/0.88, Loss(train/val) 0.77752/0.83287. Took 1.31 sec\n",
      "Epoch 81, Acc(train/val): 0.89/0.88, Loss(train/val) 0.77450/0.83031. Took 1.36 sec\n",
      "Epoch 82, Acc(train/val): 0.89/0.88, Loss(train/val) 0.77171/0.82751. Took 1.32 sec\n",
      "Epoch 83, Acc(train/val): 0.89/0.88, Loss(train/val) 0.76897/0.82467. Took 1.34 sec\n",
      "Epoch 84, Acc(train/val): 0.89/0.88, Loss(train/val) 0.76634/0.82209. Took 1.34 sec\n",
      "Epoch 85, Acc(train/val): 0.89/0.88, Loss(train/val) 0.76371/0.81977. Took 1.34 sec\n",
      "Epoch 86, Acc(train/val): 0.90/0.88, Loss(train/val) 0.76117/0.81749. Took 1.30 sec\n",
      "Epoch 87, Acc(train/val): 0.90/0.88, Loss(train/val) 0.75863/0.81520. Took 1.34 sec\n",
      "Epoch 88, Acc(train/val): 0.90/0.88, Loss(train/val) 0.75629/0.81276. Took 1.31 sec\n",
      "Epoch 89, Acc(train/val): 0.90/0.88, Loss(train/val) 0.75384/0.81059. Took 1.33 sec\n",
      "Epoch 90, Acc(train/val): 0.90/0.88, Loss(train/val) 0.75137/0.80856. Took 1.36 sec\n",
      "Epoch 91, Acc(train/val): 0.90/0.88, Loss(train/val) 0.74927/0.80631. Took 1.30 sec\n",
      "Epoch 92, Acc(train/val): 0.90/0.88, Loss(train/val) 0.74711/0.80393. Took 1.36 sec\n",
      "Epoch 93, Acc(train/val): 0.90/0.89, Loss(train/val) 0.74499/0.80223. Took 1.40 sec\n",
      "Epoch 94, Acc(train/val): 0.90/0.89, Loss(train/val) 0.74296/0.79967. Took 1.30 sec\n",
      "Epoch 95, Acc(train/val): 0.90/0.89, Loss(train/val) 0.74096/0.79797. Took 1.36 sec\n",
      "Epoch 96, Acc(train/val): 0.90/0.89, Loss(train/val) 0.73908/0.79601. Took 1.32 sec\n",
      "Epoch 97, Acc(train/val): 0.90/0.89, Loss(train/val) 0.73728/0.79406. Took 1.34 sec\n",
      "Epoch 98, Acc(train/val): 0.90/0.89, Loss(train/val) 0.73564/0.79263. Took 1.35 sec\n",
      "Epoch 99, Acc(train/val): 0.90/0.89, Loss(train/val) 0.73440/0.79096. Took 1.31 sec\n",
      "Epoch 100, Acc(train/val): 0.90/0.89, Loss(train/val) 0.73216/0.78903. Took 1.31 sec\n",
      "Epoch 101, Acc(train/val): 0.90/0.89, Loss(train/val) 0.73114/0.78762. Took 1.35 sec\n",
      "Epoch 102, Acc(train/val): 0.90/0.89, Loss(train/val) 0.72883/0.78605. Took 1.32 sec\n",
      "Epoch 103, Acc(train/val): 0.90/0.89, Loss(train/val) 0.72790/0.78475. Took 1.29 sec\n",
      "Epoch 104, Acc(train/val): 0.90/0.89, Loss(train/val) 0.72595/0.78345. Took 1.31 sec\n",
      "Epoch 105, Acc(train/val): 0.90/0.89, Loss(train/val) 0.72515/0.78205. Took 1.30 sec\n",
      "Epoch 106, Acc(train/val): 0.90/0.89, Loss(train/val) 0.72311/0.78066. Took 1.32 sec\n",
      "Epoch 107, Acc(train/val): 0.90/0.89, Loss(train/val) 0.72228/0.77934. Took 1.35 sec\n",
      "Epoch 108, Acc(train/val): 0.91/0.89, Loss(train/val) 0.72033/0.77725. Took 1.33 sec\n",
      "Epoch 109, Acc(train/val): 0.91/0.89, Loss(train/val) 0.71934/0.77585. Took 1.37 sec\n",
      "Epoch 110, Acc(train/val): 0.91/0.89, Loss(train/val) 0.71799/0.77465. Took 1.29 sec\n",
      "Epoch 111, Acc(train/val): 0.91/0.89, Loss(train/val) 0.71603/0.77312. Took 1.33 sec\n",
      "Epoch 112, Acc(train/val): 0.91/0.90, Loss(train/val) 0.71551/0.77195. Took 1.30 sec\n",
      "Epoch 113, Acc(train/val): 0.91/0.90, Loss(train/val) 0.71387/0.77061. Took 1.33 sec\n",
      "Epoch 114, Acc(train/val): 0.91/0.90, Loss(train/val) 0.71210/0.76910. Took 1.31 sec\n",
      "Epoch 115, Acc(train/val): 0.91/0.90, Loss(train/val) 0.71176/0.76798. Took 1.30 sec\n",
      "Epoch 116, Acc(train/val): 0.91/0.90, Loss(train/val) 0.71054/0.76693. Took 1.31 sec\n",
      "Epoch 117, Acc(train/val): 0.91/0.90, Loss(train/val) 0.70910/0.76595. Took 1.28 sec\n",
      "Epoch 118, Acc(train/val): 0.91/0.90, Loss(train/val) 0.70752/0.76460. Took 1.30 sec\n",
      "Epoch 119, Acc(train/val): 0.91/0.90, Loss(train/val) 0.70691/0.76357. Took 1.32 sec\n",
      "Epoch 120, Acc(train/val): 0.91/0.90, Loss(train/val) 0.70556/0.76221. Took 1.32 sec\n",
      "Epoch 121, Acc(train/val): 0.91/0.90, Loss(train/val) 0.70483/0.76170. Took 1.35 sec\n",
      "Epoch 122, Acc(train/val): 0.91/0.90, Loss(train/val) 0.70340/0.76032. Took 1.36 sec\n",
      "Epoch 123, Acc(train/val): 0.91/0.90, Loss(train/val) 0.70267/0.75950. Took 1.29 sec\n",
      "Epoch 124, Acc(train/val): 0.91/0.90, Loss(train/val) 0.70133/0.75834. Took 1.38 sec\n",
      "Epoch 125, Acc(train/val): 0.91/0.90, Loss(train/val) 0.70070/0.75780. Took 1.32 sec\n",
      "Epoch 126, Acc(train/val): 0.91/0.90, Loss(train/val) 0.69943/0.75653. Took 1.36 sec\n",
      "Epoch 127, Acc(train/val): 0.91/0.90, Loss(train/val) 0.69863/0.75594. Took 1.32 sec\n",
      "Epoch 128, Acc(train/val): 0.91/0.90, Loss(train/val) 0.69747/0.75497. Took 1.31 sec\n",
      "Epoch 129, Acc(train/val): 0.91/0.90, Loss(train/val) 0.69655/0.75409. Took 1.30 sec\n",
      "Epoch 130, Acc(train/val): 0.91/0.90, Loss(train/val) 0.69542/0.75268. Took 1.35 sec\n",
      "Epoch 131, Acc(train/val): 0.91/0.90, Loss(train/val) 0.69449/0.75235. Took 1.29 sec\n",
      "Epoch 132, Acc(train/val): 0.91/0.90, Loss(train/val) 0.69347/0.75114. Took 1.32 sec\n",
      "Epoch 133, Acc(train/val): 0.91/0.90, Loss(train/val) 0.69261/0.75045. Took 1.31 sec\n",
      "Epoch 134, Acc(train/val): 0.91/0.90, Loss(train/val) 0.69144/0.74975. Took 1.35 sec\n",
      "Epoch 135, Acc(train/val): 0.91/0.90, Loss(train/val) 0.69048/0.74897. Took 1.33 sec\n",
      "Epoch 136, Acc(train/val): 0.91/0.91, Loss(train/val) 0.68968/0.74732. Took 1.32 sec\n",
      "Epoch 137, Acc(train/val): 0.91/0.91, Loss(train/val) 0.68881/0.74692. Took 1.31 sec\n",
      "Epoch 138, Acc(train/val): 0.91/0.91, Loss(train/val) 0.68770/0.74550. Took 1.33 sec\n",
      "Epoch 139, Acc(train/val): 0.91/0.91, Loss(train/val) 0.68677/0.74497. Took 1.35 sec\n",
      "Epoch 140, Acc(train/val): 0.91/0.91, Loss(train/val) 0.68583/0.74374. Took 1.33 sec\n",
      "Epoch 141, Acc(train/val): 0.91/0.91, Loss(train/val) 0.68490/0.74323. Took 1.30 sec\n",
      "Epoch 142, Acc(train/val): 0.91/0.91, Loss(train/val) 0.68400/0.74180. Took 1.31 sec\n",
      "Epoch 143, Acc(train/val): 0.92/0.91, Loss(train/val) 0.68284/0.74118. Took 1.36 sec\n",
      "Epoch 144, Acc(train/val): 0.92/0.91, Loss(train/val) 0.68197/0.74021. Took 1.32 sec\n",
      "Epoch 145, Acc(train/val): 0.92/0.91, Loss(train/val) 0.68082/0.73974. Took 1.29 sec\n",
      "Epoch 146, Acc(train/val): 0.92/0.91, Loss(train/val) 0.68007/0.73863. Took 1.33 sec\n",
      "Epoch 147, Acc(train/val): 0.92/0.91, Loss(train/val) 0.67922/0.73753. Took 1.34 sec\n",
      "Epoch 148, Acc(train/val): 0.92/0.91, Loss(train/val) 0.67782/0.73729. Took 1.35 sec\n",
      "Epoch 149, Acc(train/val): 0.92/0.91, Loss(train/val) 0.67703/0.73615. Took 1.37 sec\n",
      "Epoch 150, Acc(train/val): 0.92/0.91, Loss(train/val) 0.67630/0.73506. Took 1.43 sec\n",
      "Epoch 151, Acc(train/val): 0.92/0.91, Loss(train/val) 0.67485/0.73511. Took 1.28 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 152, Acc(train/val): 0.92/0.91, Loss(train/val) 0.67389/0.73418. Took 1.29 sec\n",
      "Epoch 153, Acc(train/val): 0.92/0.91, Loss(train/val) 0.67296/0.73366. Took 1.30 sec\n",
      "Epoch 154, Acc(train/val): 0.92/0.91, Loss(train/val) 0.67212/0.73221. Took 1.30 sec\n",
      "Epoch 155, Acc(train/val): 0.92/0.91, Loss(train/val) 0.67105/0.73127. Took 1.35 sec\n",
      "Epoch 156, Acc(train/val): 0.92/0.91, Loss(train/val) 0.67010/0.73027. Took 1.30 sec\n",
      "Epoch 157, Acc(train/val): 0.92/0.91, Loss(train/val) 0.66933/0.72992. Took 1.42 sec\n",
      "Epoch 158, Acc(train/val): 0.92/0.91, Loss(train/val) 0.66797/0.72892. Took 1.34 sec\n",
      "Epoch 159, Acc(train/val): 0.92/0.91, Loss(train/val) 0.66705/0.72840. Took 1.29 sec\n",
      "Epoch 160, Acc(train/val): 0.92/0.91, Loss(train/val) 0.66615/0.72738. Took 1.31 sec\n",
      "Epoch 161, Acc(train/val): 0.92/0.91, Loss(train/val) 0.66509/0.72639. Took 1.33 sec\n",
      "Epoch 162, Acc(train/val): 0.92/0.91, Loss(train/val) 0.66412/0.72538. Took 1.31 sec\n",
      "Epoch 163, Acc(train/val): 0.92/0.91, Loss(train/val) 0.66360/0.72568. Took 1.31 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 164, Acc(train/val): 0.92/0.91, Loss(train/val) 0.66226/0.72428. Took 1.34 sec\n",
      "Epoch 165, Acc(train/val): 0.92/0.91, Loss(train/val) 0.66144/0.72314. Took 1.35 sec\n",
      "Epoch 166, Acc(train/val): 0.92/0.91, Loss(train/val) 0.66046/0.72238. Took 1.30 sec\n",
      "Epoch 167, Acc(train/val): 0.92/0.91, Loss(train/val) 0.66002/0.72259. Took 1.34 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 168, Acc(train/val): 0.92/0.91, Loss(train/val) 0.65874/0.72088. Took 1.28 sec\n",
      "Epoch 169, Acc(train/val): 0.92/0.91, Loss(train/val) 0.65773/0.72018. Took 1.31 sec\n",
      "Epoch 170, Acc(train/val): 0.92/0.91, Loss(train/val) 0.65727/0.72025. Took 1.31 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 171, Acc(train/val): 0.92/0.91, Loss(train/val) 0.65606/0.71903. Took 1.33 sec\n",
      "Epoch 172, Acc(train/val): 0.92/0.91, Loss(train/val) 0.65528/0.71801. Took 1.33 sec\n",
      "Epoch 173, Acc(train/val): 0.92/0.91, Loss(train/val) 0.65472/0.71814. Took 1.32 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 174, Acc(train/val): 0.92/0.91, Loss(train/val) 0.65352/0.71702. Took 1.31 sec\n",
      "Epoch 175, Acc(train/val): 0.92/0.91, Loss(train/val) 0.65259/0.71608. Took 1.34 sec\n",
      "Epoch 176, Acc(train/val): 0.92/0.91, Loss(train/val) 0.65170/0.71520. Took 1.30 sec\n",
      "Epoch 177, Acc(train/val): 0.92/0.91, Loss(train/val) 0.65122/0.71562. Took 1.34 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 178, Acc(train/val): 0.92/0.91, Loss(train/val) 0.65004/0.71386. Took 1.29 sec\n",
      "Epoch 179, Acc(train/val): 0.92/0.91, Loss(train/val) 0.64926/0.71410. Took 1.30 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 180, Acc(train/val): 0.92/0.92, Loss(train/val) 0.64839/0.71255. Took 1.33 sec\n",
      "Epoch 181, Acc(train/val): 0.92/0.92, Loss(train/val) 0.64751/0.71210. Took 1.33 sec\n",
      "Epoch 182, Acc(train/val): 0.92/0.92, Loss(train/val) 0.64677/0.71212. Took 1.36 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 183, Acc(train/val): 0.92/0.92, Loss(train/val) 0.64581/0.71054. Took 1.31 sec\n",
      "Epoch 184, Acc(train/val): 0.92/0.92, Loss(train/val) 0.64506/0.71048. Took 1.36 sec\n",
      "Epoch 185, Acc(train/val): 0.93/0.92, Loss(train/val) 0.64414/0.70921. Took 1.36 sec\n",
      "Epoch 186, Acc(train/val): 0.93/0.92, Loss(train/val) 0.64334/0.70865. Took 1.33 sec\n",
      "Epoch 187, Acc(train/val): 0.93/0.92, Loss(train/val) 0.64313/0.70855. Took 1.31 sec\n",
      "Epoch 188, Acc(train/val): 0.93/0.92, Loss(train/val) 0.64179/0.70723. Took 1.29 sec\n",
      "Epoch 189, Acc(train/val): 0.93/0.92, Loss(train/val) 0.64103/0.70604. Took 1.31 sec\n",
      "Epoch 190, Acc(train/val): 0.93/0.92, Loss(train/val) 0.64055/0.70627. Took 1.31 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 191, Acc(train/val): 0.93/0.92, Loss(train/val) 0.63951/0.70494. Took 1.34 sec\n",
      "Epoch 192, Acc(train/val): 0.93/0.92, Loss(train/val) 0.63963/0.70531. Took 1.32 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 193, Acc(train/val): 0.93/0.92, Loss(train/val) 0.63837/0.70380. Took 1.34 sec\n",
      "Epoch 194, Acc(train/val): 0.93/0.92, Loss(train/val) 0.63763/0.70381. Took 1.30 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 195, Acc(train/val): 0.93/0.92, Loss(train/val) 0.63697/0.70213. Took 1.36 sec\n",
      "Epoch 196, Acc(train/val): 0.93/0.92, Loss(train/val) 0.63667/0.70274. Took 1.32 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 197, Acc(train/val): 0.93/0.92, Loss(train/val) 0.63567/0.70122. Took 1.28 sec\n",
      "Epoch 198, Acc(train/val): 0.93/0.92, Loss(train/val) 0.63472/0.70085. Took 1.36 sec\n",
      "Epoch 199, Acc(train/val): 0.93/0.92, Loss(train/val) 0.63417/0.69990. Took 1.30 sec\n",
      "Epoch 200, Acc(train/val): 0.93/0.92, Loss(train/val) 0.63370/0.69981. Took 1.33 sec\n",
      "Epoch 201, Acc(train/val): 0.93/0.92, Loss(train/val) 0.63295/0.69913. Took 1.31 sec\n",
      "Epoch 202, Acc(train/val): 0.93/0.92, Loss(train/val) 0.63275/0.69841. Took 1.36 sec\n",
      "Epoch 203, Acc(train/val): 0.93/0.92, Loss(train/val) 0.63173/0.69825. Took 1.32 sec\n",
      "Epoch 204, Acc(train/val): 0.93/0.92, Loss(train/val) 0.63133/0.69705. Took 1.31 sec\n",
      "Epoch 205, Acc(train/val): 0.93/0.92, Loss(train/val) 0.63048/0.69694. Took 1.37 sec\n",
      "Epoch 206, Acc(train/val): 0.93/0.92, Loss(train/val) 0.63007/0.69553. Took 1.29 sec\n",
      "Epoch 207, Acc(train/val): 0.93/0.92, Loss(train/val) 0.62929/0.69575. Took 1.37 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 208, Acc(train/val): 0.93/0.92, Loss(train/val) 0.62849/0.69477. Took 1.32 sec\n",
      "Epoch 209, Acc(train/val): 0.93/0.92, Loss(train/val) 0.62783/0.69419. Took 1.32 sec\n",
      "Epoch 210, Acc(train/val): 0.93/0.92, Loss(train/val) 0.62743/0.69444. Took 1.33 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 211, Acc(train/val): 0.93/0.92, Loss(train/val) 0.62669/0.69344. Took 1.29 sec\n",
      "Epoch 212, Acc(train/val): 0.93/0.92, Loss(train/val) 0.62618/0.69308. Took 1.29 sec\n",
      "Epoch 213, Acc(train/val): 0.93/0.92, Loss(train/val) 0.62582/0.69263. Took 1.35 sec\n",
      "Epoch 214, Acc(train/val): 0.93/0.92, Loss(train/val) 0.62541/0.69205. Took 1.32 sec\n",
      "Epoch 215, Acc(train/val): 0.93/0.92, Loss(train/val) 0.62477/0.69196. Took 1.31 sec\n",
      "Epoch 216, Acc(train/val): 0.93/0.92, Loss(train/val) 0.62368/0.69101. Took 1.33 sec\n",
      "Epoch 217, Acc(train/val): 0.93/0.92, Loss(train/val) 0.62342/0.69056. Took 1.30 sec\n",
      "Epoch 218, Acc(train/val): 0.93/0.92, Loss(train/val) 0.62318/0.69090. Took 1.36 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 219, Acc(train/val): 0.93/0.92, Loss(train/val) 0.62228/0.68969. Took 1.38 sec\n",
      "Epoch 220, Acc(train/val): 0.93/0.92, Loss(train/val) 0.62189/0.68890. Took 1.29 sec\n",
      "Epoch 221, Acc(train/val): 0.93/0.92, Loss(train/val) 0.62148/0.68921. Took 1.30 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 222, Acc(train/val): 0.93/0.92, Loss(train/val) 0.62072/0.68785. Took 1.30 sec\n",
      "Epoch 223, Acc(train/val): 0.93/0.92, Loss(train/val) 0.61975/0.68780. Took 1.32 sec\n",
      "Epoch 224, Acc(train/val): 0.93/0.92, Loss(train/val) 0.61928/0.68738. Took 1.30 sec\n",
      "Epoch 225, Acc(train/val): 0.93/0.92, Loss(train/val) 0.61914/0.68750. Took 1.29 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 226, Acc(train/val): 0.93/0.92, Loss(train/val) 0.61831/0.68662. Took 1.29 sec\n",
      "Epoch 227, Acc(train/val): 0.93/0.92, Loss(train/val) 0.61786/0.68601. Took 1.29 sec\n",
      "Epoch 228, Acc(train/val): 0.93/0.92, Loss(train/val) 0.61731/0.68541. Took 1.31 sec\n",
      "Epoch 229, Acc(train/val): 0.93/0.92, Loss(train/val) 0.61694/0.68537. Took 1.29 sec\n",
      "Epoch 230, Acc(train/val): 0.93/0.92, Loss(train/val) 0.61649/0.68509. Took 1.32 sec\n",
      "Epoch 231, Acc(train/val): 0.93/0.92, Loss(train/val) 0.61577/0.68358. Took 1.34 sec\n",
      "Epoch 232, Acc(train/val): 0.93/0.92, Loss(train/val) 0.61531/0.68372. Took 1.28 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 233, Acc(train/val): 0.93/0.92, Loss(train/val) 0.61515/0.68376. Took 1.35 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 234, Acc(train/val): 0.93/0.92, Loss(train/val) 0.61497/0.68392. Took 1.31 sec\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 235, Acc(train/val): 0.93/0.92, Loss(train/val) 0.61479/0.68383. Took 1.32 sec\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 236, Acc(train/val): 0.93/0.92, Loss(train/val) 0.61342/0.68187. Took 1.31 sec\n",
      "Epoch 237, Acc(train/val): 0.93/0.92, Loss(train/val) 0.61359/0.68268. Took 1.30 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 238, Acc(train/val): 0.93/0.92, Loss(train/val) 0.61311/0.68229. Took 1.30 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 239, Acc(train/val): 0.93/0.92, Loss(train/val) 0.61272/0.68207. Took 1.32 sec\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 240, Acc(train/val): 0.93/0.92, Loss(train/val) 0.61215/0.68177. Took 1.35 sec\n",
      "Epoch 241, Acc(train/val): 0.93/0.92, Loss(train/val) 0.61165/0.68104. Took 1.32 sec\n",
      "Epoch 242, Acc(train/val): 0.93/0.93, Loss(train/val) 0.61122/0.68184. Took 1.32 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 243, Acc(train/val): 0.93/0.93, Loss(train/val) 0.61076/0.68154. Took 1.33 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 244, Acc(train/val): 0.93/0.93, Loss(train/val) 0.61023/0.68083. Took 1.30 sec\n",
      "Epoch 245, Acc(train/val): 0.93/0.93, Loss(train/val) 0.60973/0.67999. Took 1.31 sec\n",
      "Epoch 246, Acc(train/val): 0.93/0.93, Loss(train/val) 0.60966/0.68047. Took 1.35 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 247, Acc(train/val): 0.93/0.93, Loss(train/val) 0.60884/0.67988. Took 1.33 sec\n",
      "Epoch 248, Acc(train/val): 0.93/0.93, Loss(train/val) 0.60825/0.67969. Took 1.33 sec\n",
      "Epoch 249, Acc(train/val): 0.93/0.93, Loss(train/val) 0.60785/0.67953. Took 1.32 sec\n",
      "Epoch 250, Acc(train/val): 0.93/0.93, Loss(train/val) 0.60765/0.67972. Took 1.30 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 251, Acc(train/val): 0.93/0.93, Loss(train/val) 0.60713/0.67890. Took 1.35 sec\n",
      "Epoch 252, Acc(train/val): 0.93/0.93, Loss(train/val) 0.60670/0.67909. Took 1.31 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 253, Acc(train/val): 0.93/0.93, Loss(train/val) 0.60630/0.67904. Took 1.32 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 254, Acc(train/val): 0.93/0.93, Loss(train/val) 0.60554/0.67807. Took 1.30 sec\n",
      "Epoch 255, Acc(train/val): 0.93/0.93, Loss(train/val) 0.60553/0.67819. Took 1.31 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 256, Acc(train/val): 0.93/0.93, Loss(train/val) 0.60482/0.67782. Took 1.30 sec\n",
      "Epoch 257, Acc(train/val): 0.93/0.93, Loss(train/val) 0.60466/0.67795. Took 1.32 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 258, Acc(train/val): 0.93/0.93, Loss(train/val) 0.60392/0.67693. Took 1.31 sec\n",
      "Epoch 259, Acc(train/val): 0.93/0.93, Loss(train/val) 0.60363/0.67696. Took 1.29 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 260, Acc(train/val): 0.93/0.93, Loss(train/val) 0.60334/0.67630. Took 1.34 sec\n",
      "Epoch 261, Acc(train/val): 0.94/0.93, Loss(train/val) 0.60292/0.67625. Took 1.33 sec\n",
      "Epoch 262, Acc(train/val): 0.94/0.93, Loss(train/val) 0.60250/0.67624. Took 1.30 sec\n",
      "Epoch 263, Acc(train/val): 0.94/0.93, Loss(train/val) 0.60177/0.67496. Took 1.32 sec\n",
      "Epoch 264, Acc(train/val): 0.94/0.93, Loss(train/val) 0.60157/0.67506. Took 1.36 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 265, Acc(train/val): 0.94/0.93, Loss(train/val) 0.60091/0.67450. Took 1.33 sec\n",
      "Epoch 266, Acc(train/val): 0.94/0.93, Loss(train/val) 0.60065/0.67421. Took 1.33 sec\n",
      "Epoch 267, Acc(train/val): 0.94/0.93, Loss(train/val) 0.60026/0.67443. Took 1.33 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 268, Acc(train/val): 0.94/0.93, Loss(train/val) 0.59993/0.67409. Took 1.32 sec\n",
      "Epoch 269, Acc(train/val): 0.94/0.93, Loss(train/val) 0.59951/0.67426. Took 1.32 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 270, Acc(train/val): 0.94/0.93, Loss(train/val) 0.59926/0.67390. Took 1.30 sec\n",
      "Epoch 271, Acc(train/val): 0.94/0.93, Loss(train/val) 0.59875/0.67360. Took 1.30 sec\n",
      "Epoch 272, Acc(train/val): 0.94/0.93, Loss(train/val) 0.59849/0.67340. Took 2.66 sec\n",
      "Epoch 273, Acc(train/val): 0.94/0.93, Loss(train/val) 0.59810/0.67387. Took 1.30 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 274, Acc(train/val): 0.94/0.93, Loss(train/val) 0.59766/0.67394. Took 1.32 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 275, Acc(train/val): 0.94/0.93, Loss(train/val) 0.59723/0.67342. Took 1.32 sec\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 276, Acc(train/val): 0.94/0.93, Loss(train/val) 0.59683/0.67291. Took 1.40 sec\n",
      "Epoch 277, Acc(train/val): 0.94/0.93, Loss(train/val) 0.59635/0.67229. Took 1.31 sec\n",
      "Epoch 278, Acc(train/val): 0.94/0.93, Loss(train/val) 0.59589/0.67158. Took 1.32 sec\n",
      "Epoch 279, Acc(train/val): 0.94/0.93, Loss(train/val) 0.59515/0.66984. Took 1.30 sec\n",
      "Epoch 280, Acc(train/val): 0.94/0.93, Loss(train/val) 0.59474/0.67002. Took 1.31 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 281, Acc(train/val): 0.94/0.93, Loss(train/val) 0.59468/0.67041. Took 1.33 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 282, Acc(train/val): 0.94/0.93, Loss(train/val) 0.59398/0.66967. Took 1.31 sec\n",
      "Epoch 283, Acc(train/val): 0.94/0.93, Loss(train/val) 0.59357/0.66921. Took 1.29 sec\n",
      "Epoch 284, Acc(train/val): 0.94/0.93, Loss(train/val) 0.59284/0.66813. Took 1.29 sec\n",
      "Epoch 285, Acc(train/val): 0.94/0.93, Loss(train/val) 0.59240/0.66799. Took 1.30 sec\n",
      "Epoch 286, Acc(train/val): 0.94/0.93, Loss(train/val) 0.59204/0.66793. Took 1.29 sec\n",
      "Epoch 287, Acc(train/val): 0.94/0.93, Loss(train/val) 0.59158/0.66678. Took 1.33 sec\n",
      "Epoch 288, Acc(train/val): 0.94/0.93, Loss(train/val) 0.59138/0.66733. Took 1.32 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 289, Acc(train/val): 0.94/0.93, Loss(train/val) 0.59076/0.66627. Took 1.29 sec\n",
      "Epoch 290, Acc(train/val): 0.94/0.93, Loss(train/val) 0.59031/0.66562. Took 1.33 sec\n",
      "Epoch 291, Acc(train/val): 0.94/0.93, Loss(train/val) 0.59027/0.66541. Took 1.31 sec\n",
      "Epoch 292, Acc(train/val): 0.94/0.93, Loss(train/val) 0.58992/0.66545. Took 1.30 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 293, Acc(train/val): 0.94/0.93, Loss(train/val) 0.58912/0.66456. Took 1.34 sec\n",
      "Epoch 294, Acc(train/val): 0.94/0.93, Loss(train/val) 0.58861/0.66408. Took 1.29 sec\n",
      "Epoch 295, Acc(train/val): 0.94/0.93, Loss(train/val) 0.58821/0.66360. Took 1.28 sec\n",
      "Epoch 296, Acc(train/val): 0.94/0.93, Loss(train/val) 0.58780/0.66346. Took 1.29 sec\n",
      "Epoch 297, Acc(train/val): 0.94/0.93, Loss(train/val) 0.58751/0.66337. Took 1.36 sec\n",
      "Epoch 298, Acc(train/val): 0.94/0.93, Loss(train/val) 0.58736/0.66314. Took 1.35 sec\n",
      "Epoch 299, Acc(train/val): 0.94/0.93, Loss(train/val) 0.58693/0.66318. Took 1.33 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 300, Acc(train/val): 0.94/0.93, Loss(train/val) 0.58621/0.66202. Took 1.30 sec\n",
      "Epoch 301, Acc(train/val): 0.94/0.93, Loss(train/val) 0.58598/0.66265. Took 1.30 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 302, Acc(train/val): 0.94/0.93, Loss(train/val) 0.58553/0.66134. Took 1.31 sec\n",
      "Epoch 303, Acc(train/val): 0.94/0.93, Loss(train/val) 0.58519/0.66237. Took 1.33 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 304, Acc(train/val): 0.94/0.93, Loss(train/val) 0.58483/0.66129. Took 1.30 sec\n",
      "Epoch 305, Acc(train/val): 0.94/0.93, Loss(train/val) 0.58437/0.66105. Took 1.35 sec\n",
      "Epoch 306, Acc(train/val): 0.94/0.93, Loss(train/val) 0.58383/0.66088. Took 1.29 sec\n",
      "Epoch 307, Acc(train/val): 0.94/0.93, Loss(train/val) 0.58360/0.66016. Took 1.33 sec\n",
      "Epoch 308, Acc(train/val): 0.94/0.93, Loss(train/val) 0.58342/0.66099. Took 1.30 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 309, Acc(train/val): 0.94/0.93, Loss(train/val) 0.58270/0.65913. Took 1.33 sec\n",
      "Epoch 310, Acc(train/val): 0.94/0.93, Loss(train/val) 0.58241/0.65899. Took 1.31 sec\n",
      "Epoch 311, Acc(train/val): 0.94/0.93, Loss(train/val) 0.58188/0.65908. Took 1.33 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 312, Acc(train/val): 0.94/0.93, Loss(train/val) 0.58155/0.65899. Took 1.29 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 313, Acc(train/val): 0.94/0.93, Loss(train/val) 0.58104/0.65833. Took 1.34 sec\n",
      "Epoch 314, Acc(train/val): 0.94/0.93, Loss(train/val) 0.58093/0.65821. Took 1.37 sec\n",
      "Epoch 315, Acc(train/val): 0.94/0.93, Loss(train/val) 0.58055/0.65821. Took 1.29 sec\n",
      "Epoch 316, Acc(train/val): 0.94/0.93, Loss(train/val) 0.58023/0.65803. Took 1.32 sec\n",
      "Epoch 317, Acc(train/val): 0.94/0.93, Loss(train/val) 0.57986/0.65792. Took 1.31 sec\n",
      "Epoch 318, Acc(train/val): 0.94/0.93, Loss(train/val) 0.57963/0.65761. Took 1.37 sec\n",
      "Epoch 319, Acc(train/val): 0.94/0.93, Loss(train/val) 0.57921/0.65730. Took 1.31 sec\n",
      "Epoch 320, Acc(train/val): 0.94/0.93, Loss(train/val) 0.57888/0.65721. Took 1.31 sec\n",
      "Epoch 321, Acc(train/val): 0.94/0.93, Loss(train/val) 0.57844/0.65682. Took 1.32 sec\n",
      "Epoch 322, Acc(train/val): 0.94/0.93, Loss(train/val) 0.57826/0.65751. Took 1.32 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 323, Acc(train/val): 0.94/0.93, Loss(train/val) 0.57752/0.65627. Took 1.32 sec\n",
      "Epoch 324, Acc(train/val): 0.94/0.93, Loss(train/val) 0.57736/0.65595. Took 1.31 sec\n",
      "Epoch 325, Acc(train/val): 0.94/0.93, Loss(train/val) 0.57692/0.65572. Took 1.30 sec\n",
      "Epoch 326, Acc(train/val): 0.94/0.93, Loss(train/val) 0.57679/0.65668. Took 1.36 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 327, Acc(train/val): 0.94/0.93, Loss(train/val) 0.57643/0.65557. Took 1.33 sec\n",
      "Epoch 328, Acc(train/val): 0.94/0.93, Loss(train/val) 0.57612/0.65608. Took 1.32 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 329, Acc(train/val): 0.94/0.93, Loss(train/val) 0.57593/0.65529. Took 1.32 sec\n",
      "Epoch 330, Acc(train/val): 0.94/0.93, Loss(train/val) 0.57547/0.65511. Took 1.29 sec\n",
      "Epoch 331, Acc(train/val): 0.94/0.93, Loss(train/val) 0.57524/0.65513. Took 1.30 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 332, Acc(train/val): 0.94/0.93, Loss(train/val) 0.57469/0.65438. Took 1.29 sec\n",
      "Epoch 333, Acc(train/val): 0.94/0.93, Loss(train/val) 0.57457/0.65470. Took 1.36 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 334, Acc(train/val): 0.94/0.93, Loss(train/val) 0.57423/0.65483. Took 1.29 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 335, Acc(train/val): 0.94/0.93, Loss(train/val) 0.57389/0.65444. Took 1.35 sec\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 336, Acc(train/val): 0.94/0.93, Loss(train/val) 0.57361/0.65452. Took 1.29 sec\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 337, Acc(train/val): 0.94/0.93, Loss(train/val) 0.57330/0.65452. Took 1.31 sec\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 338, Acc(train/val): 0.94/0.93, Loss(train/val) 0.57309/0.65443. Took 1.30 sec\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 339, Acc(train/val): 0.94/0.93, Loss(train/val) 0.57292/0.65478. Took 1.33 sec\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 340, Acc(train/val): 0.94/0.93, Loss(train/val) 0.57244/0.65346. Took 1.30 sec\n",
      "Epoch 341, Acc(train/val): 0.94/0.93, Loss(train/val) 0.57207/0.65409. Took 1.44 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 342, Acc(train/val): 0.94/0.93, Loss(train/val) 0.57169/0.65344. Took 1.34 sec\n",
      "Epoch 343, Acc(train/val): 0.94/0.93, Loss(train/val) 0.57143/0.65360. Took 1.33 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 344, Acc(train/val): 0.94/0.93, Loss(train/val) 0.57129/0.65341. Took 1.33 sec\n",
      "Epoch 345, Acc(train/val): 0.94/0.93, Loss(train/val) 0.57124/0.65440. Took 1.33 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 346, Acc(train/val): 0.94/0.93, Loss(train/val) 0.57063/0.65296. Took 1.32 sec\n",
      "Epoch 347, Acc(train/val): 0.94/0.93, Loss(train/val) 0.57050/0.65374. Took 1.32 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 348, Acc(train/val): 0.94/0.93, Loss(train/val) 0.57021/0.65377. Took 1.30 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 349, Acc(train/val): 0.94/0.93, Loss(train/val) 0.57002/0.65437. Took 1.33 sec\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 350, Acc(train/val): 0.94/0.93, Loss(train/val) 0.56974/0.65402. Took 1.35 sec\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 351, Acc(train/val): 0.94/0.93, Loss(train/val) 0.56954/0.65381. Took 1.31 sec\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 352, Acc(train/val): 0.94/0.93, Loss(train/val) 0.56931/0.65437. Took 1.30 sec\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 353, Acc(train/val): 0.94/0.93, Loss(train/val) 0.56888/0.65283. Took 1.38 sec\n",
      "Epoch 354, Acc(train/val): 0.94/0.93, Loss(train/val) 0.56870/0.65328. Took 1.30 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 355, Acc(train/val): 0.94/0.93, Loss(train/val) 0.56848/0.65367. Took 1.35 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 356, Acc(train/val): 0.94/0.93, Loss(train/val) 0.56819/0.65314. Took 1.29 sec\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 357, Acc(train/val): 0.94/0.93, Loss(train/val) 0.56785/0.65187. Took 1.33 sec\n",
      "Epoch 358, Acc(train/val): 0.94/0.93, Loss(train/val) 0.56757/0.65259. Took 1.32 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 359, Acc(train/val): 0.94/0.93, Loss(train/val) 0.56728/0.65235. Took 1.30 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 360, Acc(train/val): 0.94/0.93, Loss(train/val) 0.56687/0.65204. Took 1.40 sec\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 361, Acc(train/val): 0.94/0.93, Loss(train/val) 0.56670/0.65234. Took 1.30 sec\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 362, Acc(train/val): 0.94/0.93, Loss(train/val) 0.56631/0.65213. Took 1.34 sec\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 363, Acc(train/val): 0.94/0.93, Loss(train/val) 0.56623/0.65264. Took 1.38 sec\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 364, Acc(train/val): 0.94/0.93, Loss(train/val) 0.56571/0.65148. Took 1.30 sec\n",
      "Epoch 365, Acc(train/val): 0.94/0.93, Loss(train/val) 0.56553/0.65145. Took 1.29 sec\n",
      "Epoch 366, Acc(train/val): 0.94/0.93, Loss(train/val) 0.56529/0.65243. Took 1.27 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 367, Acc(train/val): 0.94/0.93, Loss(train/val) 0.56501/0.65209. Took 1.32 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 368, Acc(train/val): 0.94/0.93, Loss(train/val) 0.56471/0.65227. Took 1.30 sec\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 369, Acc(train/val): 0.94/0.93, Loss(train/val) 0.56444/0.65190. Took 1.32 sec\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 370, Acc(train/val): 0.94/0.93, Loss(train/val) 0.56393/0.65101. Took 1.37 sec\n",
      "Epoch 371, Acc(train/val): 0.94/0.93, Loss(train/val) 0.56376/0.65155. Took 1.31 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 372, Acc(train/val): 0.94/0.93, Loss(train/val) 0.56350/0.65210. Took 1.32 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 373, Acc(train/val): 0.94/0.93, Loss(train/val) 0.56336/0.65246. Took 1.32 sec\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 374, Acc(train/val): 0.94/0.93, Loss(train/val) 0.56286/0.65213. Took 1.32 sec\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 375, Acc(train/val): 0.94/0.93, Loss(train/val) 0.56278/0.65268. Took 1.30 sec\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 376, Acc(train/val): 0.94/0.93, Loss(train/val) 0.56258/0.65256. Took 1.31 sec\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 377, Acc(train/val): 0.94/0.93, Loss(train/val) 0.56234/0.65297. Took 1.35 sec\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 378, Acc(train/val): 0.94/0.93, Loss(train/val) 0.56195/0.65224. Took 1.32 sec\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Epoch 379, Acc(train/val): 0.94/0.93, Loss(train/val) 0.56175/0.65254. Took 1.32 sec\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Epoch 380, Acc(train/val): 0.94/0.93, Loss(train/val) 0.56129/0.65196. Took 1.32 sec\n",
      "EarlyStopping counter: 10 out of 20\n",
      "Epoch 381, Acc(train/val): 0.94/0.93, Loss(train/val) 0.56117/0.65219. Took 1.39 sec\n",
      "EarlyStopping counter: 11 out of 20\n",
      "Epoch 382, Acc(train/val): 0.94/0.93, Loss(train/val) 0.56113/0.65256. Took 1.37 sec\n",
      "EarlyStopping counter: 12 out of 20\n",
      "Epoch 383, Acc(train/val): 0.94/0.93, Loss(train/val) 0.56067/0.65204. Took 1.30 sec\n",
      "EarlyStopping counter: 13 out of 20\n",
      "Epoch 384, Acc(train/val): 0.94/0.93, Loss(train/val) 0.56059/0.65231. Took 1.31 sec\n",
      "EarlyStopping counter: 14 out of 20\n",
      "Epoch 385, Acc(train/val): 0.94/0.93, Loss(train/val) 0.56028/0.65214. Took 1.31 sec\n",
      "EarlyStopping counter: 15 out of 20\n",
      "Epoch 386, Acc(train/val): 0.94/0.93, Loss(train/val) 0.56009/0.65244. Took 1.29 sec\n",
      "EarlyStopping counter: 16 out of 20\n",
      "Epoch 387, Acc(train/val): 0.94/0.93, Loss(train/val) 0.55980/0.65199. Took 1.34 sec\n",
      "EarlyStopping counter: 17 out of 20\n",
      "Epoch 388, Acc(train/val): 0.94/0.93, Loss(train/val) 0.55954/0.65243. Took 1.34 sec\n",
      "EarlyStopping counter: 18 out of 20\n",
      "Epoch 389, Acc(train/val): 0.94/0.93, Loss(train/val) 0.55933/0.65140. Took 1.30 sec\n",
      "EarlyStopping counter: 19 out of 20\n",
      "Epoch 390, Acc(train/val): 0.94/0.93, Loss(train/val) 0.55885/0.65032. Took 1.32 sec\n",
      "Epoch 391, Acc(train/val): 0.94/0.93, Loss(train/val) 0.55859/0.65147. Took 1.32 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 392, Acc(train/val): 0.94/0.93, Loss(train/val) 0.55845/0.65111. Took 1.30 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 393, Acc(train/val): 0.94/0.93, Loss(train/val) 0.55832/0.65077. Took 1.30 sec\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 394, Acc(train/val): 0.94/0.93, Loss(train/val) 0.55795/0.65052. Took 1.32 sec\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 395, Acc(train/val): 0.94/0.93, Loss(train/val) 0.55776/0.65075. Took 1.37 sec\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 396, Acc(train/val): 0.94/0.93, Loss(train/val) 0.55751/0.65216. Took 1.28 sec\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 397, Acc(train/val): 0.94/0.93, Loss(train/val) 0.55730/0.65144. Took 1.30 sec\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 398, Acc(train/val): 0.94/0.93, Loss(train/val) 0.55712/0.65166. Took 1.31 sec\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Epoch 399, Acc(train/val): 0.94/0.93, Loss(train/val) 0.55672/0.65096. Took 1.30 sec\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Epoch 400, Acc(train/val): 0.94/0.93, Loss(train/val) 0.55659/0.65121. Took 1.30 sec\n",
      "EarlyStopping counter: 10 out of 20\n",
      "Epoch 401, Acc(train/val): 0.94/0.93, Loss(train/val) 0.55633/0.65192. Took 1.37 sec\n",
      "EarlyStopping counter: 11 out of 20\n",
      "Epoch 402, Acc(train/val): 0.94/0.93, Loss(train/val) 0.55617/0.65131. Took 1.30 sec\n",
      "EarlyStopping counter: 12 out of 20\n",
      "Epoch 403, Acc(train/val): 0.94/0.93, Loss(train/val) 0.55592/0.65123. Took 1.29 sec\n",
      "EarlyStopping counter: 13 out of 20\n",
      "Epoch 404, Acc(train/val): 0.94/0.93, Loss(train/val) 0.55549/0.65130. Took 1.32 sec\n",
      "EarlyStopping counter: 14 out of 20\n",
      "Epoch 405, Acc(train/val): 0.94/0.93, Loss(train/val) 0.55515/0.65078. Took 1.29 sec\n",
      "EarlyStopping counter: 15 out of 20\n",
      "Epoch 406, Acc(train/val): 0.94/0.93, Loss(train/val) 0.55511/0.65131. Took 1.33 sec\n",
      "EarlyStopping counter: 16 out of 20\n",
      "Epoch 407, Acc(train/val): 0.94/0.93, Loss(train/val) 0.55471/0.65120. Took 1.32 sec\n",
      "EarlyStopping counter: 17 out of 20\n",
      "Epoch 408, Acc(train/val): 0.94/0.93, Loss(train/val) 0.55424/0.64949. Took 1.32 sec\n",
      "Epoch 409, Acc(train/val): 0.94/0.93, Loss(train/val) 0.55410/0.65015. Took 1.30 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 410, Acc(train/val): 0.94/0.93, Loss(train/val) 0.55407/0.65053. Took 1.30 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 411, Acc(train/val): 0.94/0.93, Loss(train/val) 0.55366/0.64922. Took 1.30 sec\n",
      "Epoch 412, Acc(train/val): 0.94/0.93, Loss(train/val) 0.55343/0.64874. Took 1.37 sec\n",
      "Epoch 413, Acc(train/val): 0.94/0.93, Loss(train/val) 0.55316/0.64976. Took 1.35 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 414, Acc(train/val): 0.94/0.93, Loss(train/val) 0.55314/0.65025. Took 1.29 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 415, Acc(train/val): 0.94/0.93, Loss(train/val) 0.55259/0.64947. Took 1.34 sec\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 416, Acc(train/val): 0.94/0.93, Loss(train/val) 0.55251/0.64826. Took 1.30 sec\n",
      "Epoch 417, Acc(train/val): 0.94/0.93, Loss(train/val) 0.55222/0.64911. Took 1.32 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 418, Acc(train/val): 0.94/0.93, Loss(train/val) 0.55193/0.64774. Took 1.30 sec\n",
      "Epoch 419, Acc(train/val): 0.94/0.93, Loss(train/val) 0.55158/0.64835. Took 1.29 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 420, Acc(train/val): 0.94/0.93, Loss(train/val) 0.55133/0.64760. Took 1.28 sec\n",
      "Epoch 421, Acc(train/val): 0.94/0.93, Loss(train/val) 0.55107/0.64912. Took 1.31 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 422, Acc(train/val): 0.94/0.93, Loss(train/val) 0.55090/0.64755. Took 1.34 sec\n",
      "Epoch 423, Acc(train/val): 0.94/0.93, Loss(train/val) 0.55061/0.64833. Took 1.28 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 424, Acc(train/val): 0.95/0.93, Loss(train/val) 0.55046/0.64764. Took 1.35 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 425, Acc(train/val): 0.94/0.93, Loss(train/val) 0.55003/0.64832. Took 1.32 sec\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 426, Acc(train/val): 0.94/0.93, Loss(train/val) 0.54976/0.64575. Took 1.33 sec\n",
      "Epoch 427, Acc(train/val): 0.94/0.93, Loss(train/val) 0.54940/0.64610. Took 1.33 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 428, Acc(train/val): 0.95/0.93, Loss(train/val) 0.54907/0.64574. Took 1.32 sec\n",
      "Epoch 429, Acc(train/val): 0.95/0.93, Loss(train/val) 0.54887/0.64700. Took 1.31 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 430, Acc(train/val): 0.95/0.93, Loss(train/val) 0.54875/0.64796. Took 1.34 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 431, Acc(train/val): 0.95/0.93, Loss(train/val) 0.54839/0.64603. Took 1.41 sec\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 432, Acc(train/val): 0.95/0.93, Loss(train/val) 0.54840/0.64868. Took 1.29 sec\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 433, Acc(train/val): 0.95/0.93, Loss(train/val) 0.54771/0.64543. Took 1.31 sec\n",
      "Epoch 434, Acc(train/val): 0.95/0.93, Loss(train/val) 0.54765/0.64603. Took 1.27 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 435, Acc(train/val): 0.95/0.93, Loss(train/val) 0.54769/0.64829. Took 1.30 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 436, Acc(train/val): 0.95/0.93, Loss(train/val) 0.54707/0.64657. Took 1.32 sec\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 437, Acc(train/val): 0.95/0.93, Loss(train/val) 0.54677/0.64695. Took 1.32 sec\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 438, Acc(train/val): 0.95/0.93, Loss(train/val) 0.54676/0.64771. Took 1.29 sec\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 439, Acc(train/val): 0.95/0.93, Loss(train/val) 0.54650/0.64617. Took 1.31 sec\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 440, Acc(train/val): 0.95/0.93, Loss(train/val) 0.54657/0.64755. Took 1.32 sec\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 441, Acc(train/val): 0.95/0.93, Loss(train/val) 0.54604/0.64513. Took 1.29 sec\n",
      "Epoch 442, Acc(train/val): 0.95/0.93, Loss(train/val) 0.54564/0.64636. Took 1.33 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 443, Acc(train/val): 0.95/0.93, Loss(train/val) 0.54570/0.64851. Took 1.31 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 444, Acc(train/val): 0.95/0.93, Loss(train/val) 0.54558/0.64714. Took 1.30 sec\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 445, Acc(train/val): 0.95/0.93, Loss(train/val) 0.54498/0.64587. Took 1.29 sec\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 446, Acc(train/val): 0.95/0.93, Loss(train/val) 0.54465/0.64576. Took 1.29 sec\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 447, Acc(train/val): 0.95/0.93, Loss(train/val) 0.54451/0.64676. Took 1.28 sec\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 448, Acc(train/val): 0.95/0.93, Loss(train/val) 0.54469/0.64831. Took 1.30 sec\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 449, Acc(train/val): 0.95/0.93, Loss(train/val) 0.54411/0.64577. Took 1.29 sec\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Epoch 450, Acc(train/val): 0.95/0.93, Loss(train/val) 0.54371/0.64591. Took 1.37 sec\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Epoch 451, Acc(train/val): 0.95/0.93, Loss(train/val) 0.54400/0.64718. Took 1.29 sec\n",
      "EarlyStopping counter: 10 out of 20\n",
      "Epoch 452, Acc(train/val): 0.95/0.93, Loss(train/val) 0.54356/0.64684. Took 1.33 sec\n",
      "EarlyStopping counter: 11 out of 20\n",
      "Epoch 453, Acc(train/val): 0.95/0.93, Loss(train/val) 0.54325/0.64587. Took 1.33 sec\n",
      "EarlyStopping counter: 12 out of 20\n",
      "Epoch 454, Acc(train/val): 0.95/0.93, Loss(train/val) 0.54289/0.64576. Took 1.34 sec\n",
      "EarlyStopping counter: 13 out of 20\n",
      "Epoch 455, Acc(train/val): 0.95/0.93, Loss(train/val) 0.54287/0.64577. Took 1.28 sec\n",
      "EarlyStopping counter: 14 out of 20\n",
      "Epoch 456, Acc(train/val): 0.95/0.93, Loss(train/val) 0.54259/0.64534. Took 1.29 sec\n",
      "EarlyStopping counter: 15 out of 20\n",
      "Epoch 457, Acc(train/val): 0.95/0.93, Loss(train/val) 0.54242/0.64671. Took 1.31 sec\n",
      "EarlyStopping counter: 16 out of 20\n",
      "Epoch 458, Acc(train/val): 0.95/0.93, Loss(train/val) 0.54228/0.64619. Took 1.31 sec\n",
      "EarlyStopping counter: 17 out of 20\n",
      "Epoch 459, Acc(train/val): 0.95/0.93, Loss(train/val) 0.54174/0.64576. Took 1.36 sec\n",
      "EarlyStopping counter: 18 out of 20\n",
      "Epoch 460, Acc(train/val): 0.95/0.93, Loss(train/val) 0.54181/0.64696. Took 1.30 sec\n",
      "EarlyStopping counter: 19 out of 20\n",
      "Epoch 461, Acc(train/val): 0.95/0.93, Loss(train/val) 0.54156/0.64577. Took 1.34 sec\n",
      "EarlyStopping counter: 20 out of 20\n",
      "Early stopping\n",
      "*** auc score : 0.93479 ***\n",
      "0.9347932470008112,0.941964666723564,0.9842143805609503,0.941964666723564,0.9595182786847427,10899,642,38,138\n",
      "Namespace(batch_size=128, device='cuda:0', dropout=0.0, epoch=1000, exp_name='exp1_lr', hid_dim=50, input_dim=20, l2=1e-05, lr=1e-05, n_layers=2, optim='Adam', use_bn=True)\n",
      "Epoch 1, Acc(train/val): 0.53/0.61, Loss(train/val) 1.27236/1.35005. Took 1.67 sec\n",
      "Epoch 2, Acc(train/val): 0.59/0.64, Loss(train/val) 1.26042/1.34009. Took 1.66 sec\n",
      "Epoch 3, Acc(train/val): 0.61/0.65, Loss(train/val) 1.25125/1.33207. Took 1.65 sec\n",
      "Epoch 4, Acc(train/val): 0.63/0.66, Loss(train/val) 1.24354/1.32516. Took 1.67 sec\n",
      "Epoch 5, Acc(train/val): 0.64/0.66, Loss(train/val) 1.23696/1.31906. Took 1.65 sec\n",
      "Epoch 6, Acc(train/val): 0.64/0.67, Loss(train/val) 1.23109/1.31358. Took 1.71 sec\n",
      "Epoch 7, Acc(train/val): 0.65/0.67, Loss(train/val) 1.22583/1.30864. Took 1.79 sec\n",
      "Epoch 8, Acc(train/val): 0.65/0.68, Loss(train/val) 1.22090/1.30381. Took 1.74 sec\n",
      "Epoch 9, Acc(train/val): 0.66/0.68, Loss(train/val) 1.21613/1.29910. Took 1.67 sec\n",
      "Epoch 10, Acc(train/val): 0.66/0.68, Loss(train/val) 1.21141/1.29439. Took 1.73 sec\n",
      "Epoch 11, Acc(train/val): 0.67/0.69, Loss(train/val) 1.20670/1.28963. Took 1.65 sec\n",
      "Epoch 12, Acc(train/val): 0.67/0.69, Loss(train/val) 1.20189/1.28466. Took 1.70 sec\n",
      "Epoch 13, Acc(train/val): 0.68/0.69, Loss(train/val) 1.19698/1.27939. Took 1.70 sec\n",
      "Epoch 14, Acc(train/val): 0.68/0.70, Loss(train/val) 1.19192/1.27407. Took 1.66 sec\n",
      "Epoch 15, Acc(train/val): 0.69/0.70, Loss(train/val) 1.18670/1.26862. Took 1.73 sec\n",
      "Epoch 16, Acc(train/val): 0.69/0.71, Loss(train/val) 1.18135/1.26281. Took 1.73 sec\n",
      "Epoch 17, Acc(train/val): 0.70/0.71, Loss(train/val) 1.17575/1.25666. Took 1.76 sec\n",
      "Epoch 18, Acc(train/val): 0.70/0.72, Loss(train/val) 1.16992/1.25032. Took 1.69 sec\n",
      "Epoch 19, Acc(train/val): 0.71/0.72, Loss(train/val) 1.16388/1.24364. Took 1.69 sec\n",
      "Epoch 20, Acc(train/val): 0.71/0.73, Loss(train/val) 1.15753/1.23637. Took 1.76 sec\n",
      "Epoch 21, Acc(train/val): 0.72/0.74, Loss(train/val) 1.15088/1.22887. Took 1.65 sec\n",
      "Epoch 22, Acc(train/val): 0.72/0.74, Loss(train/val) 1.14405/1.22117. Took 1.79 sec\n",
      "Epoch 23, Acc(train/val): 0.73/0.75, Loss(train/val) 1.13688/1.21278. Took 1.71 sec\n",
      "Epoch 24, Acc(train/val): 0.73/0.75, Loss(train/val) 1.12931/1.20429. Took 1.69 sec\n",
      "Epoch 25, Acc(train/val): 0.74/0.76, Loss(train/val) 1.12150/1.19553. Took 1.72 sec\n",
      "Epoch 26, Acc(train/val): 0.74/0.76, Loss(train/val) 1.11338/1.18668. Took 1.66 sec\n",
      "Epoch 27, Acc(train/val): 0.75/0.77, Loss(train/val) 1.10512/1.17779. Took 1.65 sec\n",
      "Epoch 28, Acc(train/val): 0.75/0.77, Loss(train/val) 1.09689/1.16913. Took 1.70 sec\n",
      "Epoch 29, Acc(train/val): 0.76/0.78, Loss(train/val) 1.08883/1.16067. Took 1.66 sec\n",
      "Epoch 30, Acc(train/val): 0.77/0.78, Loss(train/val) 1.08081/1.15238. Took 3.05 sec\n",
      "Epoch 31, Acc(train/val): 0.77/0.79, Loss(train/val) 1.07297/1.14449. Took 1.68 sec\n",
      "Epoch 32, Acc(train/val): 0.78/0.79, Loss(train/val) 1.06543/1.13695. Took 1.67 sec\n",
      "Epoch 33, Acc(train/val): 0.78/0.80, Loss(train/val) 1.05806/1.12966. Took 1.67 sec\n",
      "Epoch 34, Acc(train/val): 0.79/0.80, Loss(train/val) 1.05079/1.12259. Took 1.68 sec\n",
      "Epoch 35, Acc(train/val): 0.79/0.80, Loss(train/val) 1.04364/1.11575. Took 1.72 sec\n",
      "Epoch 36, Acc(train/val): 0.80/0.81, Loss(train/val) 1.03662/1.10892. Took 1.65 sec\n",
      "Epoch 37, Acc(train/val): 0.80/0.81, Loss(train/val) 1.02966/1.10198. Took 1.67 sec\n",
      "Epoch 38, Acc(train/val): 0.80/0.81, Loss(train/val) 1.02270/1.09494. Took 1.69 sec\n",
      "Epoch 39, Acc(train/val): 0.81/0.82, Loss(train/val) 1.01568/1.08762. Took 1.71 sec\n",
      "Epoch 40, Acc(train/val): 0.81/0.82, Loss(train/val) 1.00860/1.08025. Took 1.67 sec\n",
      "Epoch 41, Acc(train/val): 0.82/0.82, Loss(train/val) 1.00143/1.07265. Took 1.73 sec\n",
      "Epoch 42, Acc(train/val): 0.82/0.83, Loss(train/val) 0.99408/1.06492. Took 1.66 sec\n",
      "Epoch 43, Acc(train/val): 0.82/0.83, Loss(train/val) 0.98659/1.05686. Took 1.68 sec\n",
      "Epoch 44, Acc(train/val): 0.83/0.83, Loss(train/val) 0.97898/1.04885. Took 1.72 sec\n",
      "Epoch 45, Acc(train/val): 0.83/0.84, Loss(train/val) 0.97125/1.04031. Took 1.69 sec\n",
      "Epoch 46, Acc(train/val): 0.83/0.84, Loss(train/val) 0.96334/1.03157. Took 1.67 sec\n",
      "Epoch 47, Acc(train/val): 0.84/0.84, Loss(train/val) 0.95522/1.02256. Took 1.73 sec\n",
      "Epoch 48, Acc(train/val): 0.84/0.85, Loss(train/val) 0.94695/1.01365. Took 1.68 sec\n",
      "Epoch 49, Acc(train/val): 0.84/0.85, Loss(train/val) 0.93860/1.00445. Took 1.71 sec\n",
      "Epoch 50, Acc(train/val): 0.85/0.85, Loss(train/val) 0.93007/0.99525. Took 2.00 sec\n",
      "Epoch 51, Acc(train/val): 0.85/0.86, Loss(train/val) 0.92142/0.98573. Took 1.68 sec\n",
      "Epoch 52, Acc(train/val): 0.85/0.86, Loss(train/val) 0.91263/0.97602. Took 1.68 sec\n",
      "Epoch 53, Acc(train/val): 0.86/0.86, Loss(train/val) 0.90372/0.96651. Took 1.65 sec\n",
      "Epoch 54, Acc(train/val): 0.86/0.86, Loss(train/val) 0.89480/0.95670. Took 1.74 sec\n",
      "Epoch 55, Acc(train/val): 0.86/0.87, Loss(train/val) 0.88584/0.94671. Took 1.78 sec\n",
      "Epoch 56, Acc(train/val): 0.87/0.87, Loss(train/val) 0.87678/0.93721. Took 1.69 sec\n",
      "Epoch 57, Acc(train/val): 0.87/0.87, Loss(train/val) 0.86784/0.92746. Took 1.68 sec\n",
      "Epoch 58, Acc(train/val): 0.87/0.87, Loss(train/val) 0.85899/0.91850. Took 1.67 sec\n",
      "Epoch 59, Acc(train/val): 0.87/0.88, Loss(train/val) 0.85029/0.90979. Took 1.70 sec\n",
      "Epoch 60, Acc(train/val): 0.88/0.88, Loss(train/val) 0.84173/0.90053. Took 1.71 sec\n",
      "Epoch 61, Acc(train/val): 0.88/0.88, Loss(train/val) 0.83330/0.89172. Took 1.69 sec\n",
      "Epoch 62, Acc(train/val): 0.88/0.88, Loss(train/val) 0.82504/0.88311. Took 1.77 sec\n",
      "Epoch 63, Acc(train/val): 0.88/0.88, Loss(train/val) 0.81700/0.87529. Took 1.66 sec\n",
      "Epoch 64, Acc(train/val): 0.89/0.89, Loss(train/val) 0.80928/0.86715. Took 1.65 sec\n",
      "Epoch 65, Acc(train/val): 0.89/0.89, Loss(train/val) 0.80181/0.85893. Took 1.65 sec\n",
      "Epoch 66, Acc(train/val): 0.89/0.89, Loss(train/val) 0.79480/0.85193. Took 1.67 sec\n",
      "Epoch 67, Acc(train/val): 0.89/0.89, Loss(train/val) 0.78806/0.84607. Took 1.73 sec\n",
      "Epoch 68, Acc(train/val): 0.89/0.89, Loss(train/val) 0.78169/0.84010. Took 1.66 sec\n",
      "Epoch 69, Acc(train/val): 0.89/0.89, Loss(train/val) 0.77541/0.83320. Took 1.76 sec\n",
      "Epoch 70, Acc(train/val): 0.89/0.89, Loss(train/val) 0.76946/0.82728. Took 1.81 sec\n",
      "Epoch 71, Acc(train/val): 0.90/0.89, Loss(train/val) 0.76390/0.82242. Took 1.69 sec\n",
      "Epoch 72, Acc(train/val): 0.90/0.89, Loss(train/val) 0.75845/0.81747. Took 1.68 sec\n",
      "Epoch 73, Acc(train/val): 0.90/0.90, Loss(train/val) 0.75330/0.81263. Took 1.64 sec\n",
      "Epoch 74, Acc(train/val): 0.90/0.90, Loss(train/val) 0.74842/0.80804. Took 1.68 sec\n",
      "Epoch 75, Acc(train/val): 0.90/0.90, Loss(train/val) 0.74371/0.80417. Took 1.84 sec\n",
      "Epoch 76, Acc(train/val): 0.90/0.90, Loss(train/val) 0.73922/0.79959. Took 1.69 sec\n",
      "Epoch 77, Acc(train/val): 0.90/0.90, Loss(train/val) 0.73488/0.79696. Took 1.67 sec\n",
      "Epoch 78, Acc(train/val): 0.90/0.90, Loss(train/val) 0.73081/0.79304. Took 1.89 sec\n",
      "Epoch 79, Acc(train/val): 0.90/0.90, Loss(train/val) 0.72695/0.78992. Took 1.71 sec\n",
      "Epoch 80, Acc(train/val): 0.91/0.90, Loss(train/val) 0.72320/0.78762. Took 1.76 sec\n",
      "Epoch 81, Acc(train/val): 0.91/0.90, Loss(train/val) 0.71968/0.78455. Took 1.78 sec\n",
      "Epoch 82, Acc(train/val): 0.91/0.90, Loss(train/val) 0.71629/0.78000. Took 1.70 sec\n",
      "Epoch 83, Acc(train/val): 0.91/0.90, Loss(train/val) 0.71291/0.77736. Took 1.67 sec\n",
      "Epoch 84, Acc(train/val): 0.91/0.91, Loss(train/val) 0.70977/0.77510. Took 1.78 sec\n",
      "Epoch 85, Acc(train/val): 0.91/0.91, Loss(train/val) 0.70682/0.77230. Took 1.80 sec\n",
      "Epoch 86, Acc(train/val): 0.91/0.91, Loss(train/val) 0.70399/0.76920. Took 1.66 sec\n",
      "Epoch 87, Acc(train/val): 0.91/0.91, Loss(train/val) 0.70112/0.76672. Took 1.72 sec\n",
      "Epoch 88, Acc(train/val): 0.91/0.91, Loss(train/val) 0.69850/0.76601. Took 1.72 sec\n",
      "Epoch 89, Acc(train/val): 0.91/0.91, Loss(train/val) 0.69587/0.76422. Took 1.80 sec\n",
      "Epoch 90, Acc(train/val): 0.91/0.91, Loss(train/val) 0.69336/0.76319. Took 1.69 sec\n",
      "Epoch 91, Acc(train/val): 0.91/0.91, Loss(train/val) 0.69102/0.76195. Took 1.66 sec\n",
      "Epoch 92, Acc(train/val): 0.91/0.91, Loss(train/val) 0.68869/0.76022. Took 1.72 sec\n",
      "Epoch 93, Acc(train/val): 0.91/0.91, Loss(train/val) 0.68644/0.75694. Took 1.67 sec\n",
      "Epoch 94, Acc(train/val): 0.92/0.91, Loss(train/val) 0.68429/0.75525. Took 1.80 sec\n",
      "Epoch 95, Acc(train/val): 0.92/0.91, Loss(train/val) 0.68228/0.75436. Took 1.71 sec\n",
      "Epoch 96, Acc(train/val): 0.92/0.91, Loss(train/val) 0.68022/0.75251. Took 1.67 sec\n",
      "Epoch 97, Acc(train/val): 0.92/0.91, Loss(train/val) 0.67825/0.75117. Took 1.66 sec\n",
      "Epoch 98, Acc(train/val): 0.92/0.91, Loss(train/val) 0.67650/0.74962. Took 1.71 sec\n",
      "Epoch 99, Acc(train/val): 0.92/0.91, Loss(train/val) 0.67476/0.74780. Took 1.74 sec\n",
      "Epoch 100, Acc(train/val): 0.92/0.91, Loss(train/val) 0.67298/0.74737. Took 1.65 sec\n",
      "Epoch 101, Acc(train/val): 0.92/0.92, Loss(train/val) 0.67122/0.74693. Took 1.72 sec\n",
      "Epoch 102, Acc(train/val): 0.92/0.92, Loss(train/val) 0.66956/0.74480. Took 1.67 sec\n",
      "Epoch 103, Acc(train/val): 0.92/0.92, Loss(train/val) 0.66812/0.74402. Took 1.72 sec\n",
      "Epoch 104, Acc(train/val): 0.92/0.92, Loss(train/val) 0.66661/0.74286. Took 1.71 sec\n",
      "Epoch 105, Acc(train/val): 0.92/0.92, Loss(train/val) 0.66508/0.74190. Took 1.66 sec\n",
      "Epoch 106, Acc(train/val): 0.92/0.92, Loss(train/val) 0.66357/0.74025. Took 1.70 sec\n",
      "Epoch 107, Acc(train/val): 0.92/0.92, Loss(train/val) 0.66217/0.73947. Took 1.73 sec\n",
      "Epoch 108, Acc(train/val): 0.92/0.92, Loss(train/val) 0.66074/0.74033. Took 1.69 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 109, Acc(train/val): 0.92/0.92, Loss(train/val) 0.65935/0.73733. Took 1.67 sec\n",
      "Epoch 110, Acc(train/val): 0.92/0.92, Loss(train/val) 0.65804/0.73688. Took 1.73 sec\n",
      "Epoch 111, Acc(train/val): 0.92/0.92, Loss(train/val) 0.65662/0.73529. Took 1.67 sec\n",
      "Epoch 112, Acc(train/val): 0.92/0.92, Loss(train/val) 0.65533/0.73450. Took 1.87 sec\n",
      "Epoch 113, Acc(train/val): 0.92/0.92, Loss(train/val) 0.65404/0.73330. Took 1.74 sec\n",
      "Epoch 114, Acc(train/val): 0.92/0.92, Loss(train/val) 0.65283/0.73072. Took 1.68 sec\n",
      "Epoch 115, Acc(train/val): 0.92/0.92, Loss(train/val) 0.65164/0.73117. Took 1.70 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 116, Acc(train/val): 0.92/0.92, Loss(train/val) 0.65060/0.73060. Took 1.65 sec\n",
      "Epoch 117, Acc(train/val): 0.92/0.92, Loss(train/val) 0.64941/0.72925. Took 1.69 sec\n",
      "Epoch 118, Acc(train/val): 0.92/0.92, Loss(train/val) 0.64836/0.72952. Took 1.82 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 119, Acc(train/val): 0.92/0.92, Loss(train/val) 0.64723/0.72972. Took 1.70 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 120, Acc(train/val): 0.92/0.92, Loss(train/val) 0.64610/0.72691. Took 1.67 sec\n",
      "Epoch 121, Acc(train/val): 0.92/0.92, Loss(train/val) 0.64505/0.72805. Took 1.73 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 122, Acc(train/val): 0.92/0.92, Loss(train/val) 0.64405/0.72544. Took 1.66 sec\n",
      "Epoch 123, Acc(train/val): 0.92/0.92, Loss(train/val) 0.64302/0.72553. Took 1.65 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 124, Acc(train/val): 0.92/0.92, Loss(train/val) 0.64196/0.72511. Took 1.66 sec\n",
      "Epoch 125, Acc(train/val): 0.92/0.92, Loss(train/val) 0.64098/0.72348. Took 1.68 sec\n",
      "Epoch 126, Acc(train/val): 0.92/0.92, Loss(train/val) 0.64005/0.72400. Took 1.72 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 127, Acc(train/val): 0.92/0.92, Loss(train/val) 0.63913/0.72458. Took 1.73 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 128, Acc(train/val): 0.92/0.92, Loss(train/val) 0.63835/0.72454. Took 1.67 sec\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 129, Acc(train/val): 0.92/0.92, Loss(train/val) 0.63736/0.72312. Took 1.73 sec\n",
      "Epoch 130, Acc(train/val): 0.92/0.92, Loss(train/val) 0.63660/0.72179. Took 1.68 sec\n",
      "Epoch 131, Acc(train/val): 0.92/0.93, Loss(train/val) 0.63564/0.72249. Took 1.69 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 132, Acc(train/val): 0.93/0.93, Loss(train/val) 0.63479/0.72201. Took 1.84 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 133, Acc(train/val): 0.93/0.93, Loss(train/val) 0.63399/0.72203. Took 1.68 sec\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 134, Acc(train/val): 0.93/0.93, Loss(train/val) 0.63312/0.72204. Took 1.67 sec\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 135, Acc(train/val): 0.93/0.93, Loss(train/val) 0.63232/0.72038. Took 1.67 sec\n",
      "Epoch 136, Acc(train/val): 0.93/0.93, Loss(train/val) 0.63148/0.72114. Took 1.67 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 137, Acc(train/val): 0.93/0.93, Loss(train/val) 0.63068/0.71991. Took 1.66 sec\n",
      "Epoch 138, Acc(train/val): 0.93/0.93, Loss(train/val) 0.62993/0.71948. Took 1.70 sec\n",
      "Epoch 139, Acc(train/val): 0.93/0.93, Loss(train/val) 0.62918/0.72025. Took 1.66 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 140, Acc(train/val): 0.93/0.93, Loss(train/val) 0.62834/0.71963. Took 1.70 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 141, Acc(train/val): 0.93/0.93, Loss(train/val) 0.62760/0.72176. Took 1.65 sec\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 142, Acc(train/val): 0.93/0.93, Loss(train/val) 0.62679/0.72093. Took 1.75 sec\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 143, Acc(train/val): 0.93/0.93, Loss(train/val) 0.62596/0.72092. Took 1.76 sec\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 144, Acc(train/val): 0.93/0.93, Loss(train/val) 0.62513/0.72183. Took 1.65 sec\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 145, Acc(train/val): 0.93/0.93, Loss(train/val) 0.62451/0.72019. Took 1.69 sec\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 146, Acc(train/val): 0.93/0.93, Loss(train/val) 0.62376/0.72027. Took 1.67 sec\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Epoch 147, Acc(train/val): 0.93/0.93, Loss(train/val) 0.62305/0.71953. Took 1.70 sec\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Epoch 148, Acc(train/val): 0.93/0.93, Loss(train/val) 0.62241/0.72020. Took 1.70 sec\n",
      "EarlyStopping counter: 10 out of 20\n",
      "Epoch 149, Acc(train/val): 0.93/0.93, Loss(train/val) 0.62170/0.71950. Took 1.67 sec\n",
      "EarlyStopping counter: 11 out of 20\n",
      "Epoch 150, Acc(train/val): 0.93/0.93, Loss(train/val) 0.62095/0.71829. Took 1.73 sec\n",
      "Epoch 151, Acc(train/val): 0.93/0.93, Loss(train/val) 0.62017/0.71878. Took 1.71 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 152, Acc(train/val): 0.93/0.93, Loss(train/val) 0.61946/0.71817. Took 1.71 sec\n",
      "Epoch 153, Acc(train/val): 0.93/0.93, Loss(train/val) 0.61878/0.71890. Took 1.67 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 154, Acc(train/val): 0.93/0.93, Loss(train/val) 0.61813/0.71901. Took 1.65 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 155, Acc(train/val): 0.93/0.93, Loss(train/val) 0.61754/0.71946. Took 1.68 sec\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 156, Acc(train/val): 0.93/0.93, Loss(train/val) 0.61687/0.72014. Took 1.69 sec\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 157, Acc(train/val): 0.93/0.93, Loss(train/val) 0.61630/0.71813. Took 1.67 sec\n",
      "Epoch 158, Acc(train/val): 0.93/0.93, Loss(train/val) 0.61560/0.71867. Took 1.70 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 159, Acc(train/val): 0.93/0.93, Loss(train/val) 0.61498/0.71758. Took 1.74 sec\n",
      "Epoch 160, Acc(train/val): 0.93/0.93, Loss(train/val) 0.61429/0.71759. Took 1.67 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 161, Acc(train/val): 0.93/0.93, Loss(train/val) 0.61393/0.71989. Took 1.67 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 162, Acc(train/val): 0.93/0.93, Loss(train/val) 0.61326/0.71811. Took 1.65 sec\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 163, Acc(train/val): 0.93/0.93, Loss(train/val) 0.61275/0.71892. Took 1.70 sec\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 164, Acc(train/val): 0.93/0.93, Loss(train/val) 0.61220/0.71821. Took 1.76 sec\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 165, Acc(train/val): 0.93/0.93, Loss(train/val) 0.61168/0.71622. Took 1.75 sec\n",
      "Epoch 166, Acc(train/val): 0.93/0.93, Loss(train/val) 0.61111/0.71744. Took 1.76 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 167, Acc(train/val): 0.93/0.93, Loss(train/val) 0.61060/0.71689. Took 1.71 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 168, Acc(train/val): 0.93/0.93, Loss(train/val) 0.61007/0.71827. Took 1.73 sec\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 169, Acc(train/val): 0.93/0.93, Loss(train/val) 0.60967/0.71641. Took 1.66 sec\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 170, Acc(train/val): 0.93/0.93, Loss(train/val) 0.60911/0.71770. Took 1.65 sec\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 171, Acc(train/val): 0.93/0.93, Loss(train/val) 0.60858/0.71798. Took 1.68 sec\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 172, Acc(train/val): 0.93/0.93, Loss(train/val) 0.60812/0.72092. Took 1.68 sec\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 173, Acc(train/val): 0.93/0.93, Loss(train/val) 0.60765/0.72041. Took 1.67 sec\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Epoch 174, Acc(train/val): 0.93/0.93, Loss(train/val) 0.60711/0.71934. Took 1.73 sec\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Epoch 175, Acc(train/val): 0.93/0.93, Loss(train/val) 0.60670/0.71937. Took 1.73 sec\n",
      "EarlyStopping counter: 10 out of 20\n",
      "Epoch 176, Acc(train/val): 0.93/0.93, Loss(train/val) 0.60624/0.72062. Took 1.71 sec\n",
      "EarlyStopping counter: 11 out of 20\n",
      "Epoch 177, Acc(train/val): 0.93/0.93, Loss(train/val) 0.60586/0.72167. Took 1.66 sec\n",
      "EarlyStopping counter: 12 out of 20\n",
      "Epoch 178, Acc(train/val): 0.93/0.93, Loss(train/val) 0.60532/0.72189. Took 1.69 sec\n",
      "EarlyStopping counter: 13 out of 20\n",
      "Epoch 179, Acc(train/val): 0.93/0.93, Loss(train/val) 0.60492/0.72247. Took 1.69 sec\n",
      "EarlyStopping counter: 14 out of 20\n",
      "Epoch 180, Acc(train/val): 0.93/0.93, Loss(train/val) 0.60447/0.72329. Took 1.74 sec\n",
      "EarlyStopping counter: 15 out of 20\n",
      "Epoch 181, Acc(train/val): 0.93/0.93, Loss(train/val) 0.60404/0.72585. Took 1.73 sec\n",
      "EarlyStopping counter: 16 out of 20\n",
      "Epoch 182, Acc(train/val): 0.93/0.93, Loss(train/val) 0.60367/0.72550. Took 1.67 sec\n",
      "EarlyStopping counter: 17 out of 20\n",
      "Epoch 183, Acc(train/val): 0.93/0.93, Loss(train/val) 0.60319/0.72295. Took 1.68 sec\n",
      "EarlyStopping counter: 18 out of 20\n",
      "Epoch 184, Acc(train/val): 0.93/0.93, Loss(train/val) 0.60281/0.72328. Took 1.68 sec\n",
      "EarlyStopping counter: 19 out of 20\n",
      "Epoch 185, Acc(train/val): 0.93/0.93, Loss(train/val) 0.60237/0.72514. Took 1.72 sec\n",
      "EarlyStopping counter: 20 out of 20\n",
      "Early stopping\n",
      "*** auc score : 0.92079 ***\n",
      "0.9207903049207962,0.9509260049500725,0.9830260512233143,0.9509260049500725,0.9644104974188338,11020,521,54,122\n",
      "Namespace(batch_size=128, device='cuda:0', dropout=0.0, epoch=1000, exp_name='exp1_lr', hid_dim=50, input_dim=20, l2=1e-05, lr=1e-05, n_layers=3, optim='Adam', use_bn=True)\n",
      "Epoch 1, Acc(train/val): 0.56/0.65, Loss(train/val) 1.26417/1.33455. Took 2.01 sec\n",
      "Epoch 2, Acc(train/val): 0.63/0.67, Loss(train/val) 1.25191/1.32328. Took 2.11 sec\n",
      "Epoch 3, Acc(train/val): 0.65/0.68, Loss(train/val) 1.24260/1.31414. Took 2.01 sec\n",
      "Epoch 4, Acc(train/val): 0.66/0.68, Loss(train/val) 1.23442/1.30596. Took 2.03 sec\n",
      "Epoch 5, Acc(train/val): 0.67/0.69, Loss(train/val) 1.22703/1.29822. Took 2.11 sec\n",
      "Epoch 6, Acc(train/val): 0.68/0.70, Loss(train/val) 1.21986/1.29064. Took 2.07 sec\n",
      "Epoch 7, Acc(train/val): 0.68/0.70, Loss(train/val) 1.21289/1.28298. Took 2.09 sec\n",
      "Epoch 8, Acc(train/val): 0.69/0.71, Loss(train/val) 1.20562/1.27499. Took 2.06 sec\n",
      "Epoch 9, Acc(train/val): 0.70/0.71, Loss(train/val) 1.19818/1.26667. Took 2.03 sec\n",
      "Epoch 10, Acc(train/val): 0.70/0.72, Loss(train/val) 1.19065/1.25806. Took 2.14 sec\n",
      "Epoch 11, Acc(train/val): 0.70/0.73, Loss(train/val) 1.18299/1.24916. Took 2.00 sec\n",
      "Epoch 12, Acc(train/val): 0.71/0.73, Loss(train/val) 1.17518/1.24073. Took 2.02 sec\n",
      "Epoch 13, Acc(train/val): 0.71/0.73, Loss(train/val) 1.16742/1.23220. Took 2.11 sec\n",
      "Epoch 14, Acc(train/val): 0.72/0.74, Loss(train/val) 1.15947/1.22352. Took 2.00 sec\n",
      "Epoch 15, Acc(train/val): 0.72/0.74, Loss(train/val) 1.15134/1.21513. Took 2.10 sec\n",
      "Epoch 16, Acc(train/val): 0.73/0.75, Loss(train/val) 1.14317/1.20704. Took 2.02 sec\n",
      "Epoch 17, Acc(train/val): 0.73/0.75, Loss(train/val) 1.13495/1.19910. Took 2.08 sec\n",
      "Epoch 18, Acc(train/val): 0.74/0.76, Loss(train/val) 1.12649/1.19109. Took 3.43 sec\n",
      "Epoch 19, Acc(train/val): 0.74/0.76, Loss(train/val) 1.11767/1.18301. Took 2.06 sec\n",
      "Epoch 20, Acc(train/val): 0.75/0.76, Loss(train/val) 1.10838/1.17461. Took 1.99 sec\n",
      "Epoch 21, Acc(train/val): 0.76/0.77, Loss(train/val) 1.09862/1.16582. Took 2.08 sec\n",
      "Epoch 22, Acc(train/val): 0.76/0.77, Loss(train/val) 1.08849/1.15641. Took 1.99 sec\n",
      "Epoch 23, Acc(train/val): 0.77/0.78, Loss(train/val) 1.07791/1.14661. Took 1.98 sec\n",
      "Epoch 24, Acc(train/val): 0.78/0.79, Loss(train/val) 1.06676/1.13605. Took 2.13 sec\n",
      "Epoch 25, Acc(train/val): 0.78/0.80, Loss(train/val) 1.05503/1.12470. Took 2.05 sec\n",
      "Epoch 26, Acc(train/val): 0.79/0.80, Loss(train/val) 1.04287/1.11252. Took 2.14 sec\n",
      "Epoch 27, Acc(train/val): 0.80/0.81, Loss(train/val) 1.03056/1.09972. Took 2.00 sec\n",
      "Epoch 28, Acc(train/val): 0.80/0.81, Loss(train/val) 1.01800/1.08650. Took 2.09 sec\n",
      "Epoch 29, Acc(train/val): 0.81/0.82, Loss(train/val) 1.00502/1.07266. Took 2.09 sec\n",
      "Epoch 30, Acc(train/val): 0.82/0.83, Loss(train/val) 0.99192/1.05864. Took 1.98 sec\n",
      "Epoch 31, Acc(train/val): 0.83/0.83, Loss(train/val) 0.97877/1.04437. Took 2.02 sec\n",
      "Epoch 32, Acc(train/val): 0.83/0.84, Loss(train/val) 0.96550/1.03026. Took 2.02 sec\n",
      "Epoch 33, Acc(train/val): 0.84/0.84, Loss(train/val) 0.95257/1.01606. Took 2.04 sec\n",
      "Epoch 34, Acc(train/val): 0.84/0.85, Loss(train/val) 0.93963/1.00234. Took 2.01 sec\n",
      "Epoch 35, Acc(train/val): 0.85/0.85, Loss(train/val) 0.92705/0.98850. Took 2.10 sec\n",
      "Epoch 36, Acc(train/val): 0.86/0.86, Loss(train/val) 0.91475/0.97621. Took 2.05 sec\n",
      "Epoch 37, Acc(train/val): 0.86/0.86, Loss(train/val) 0.90239/0.96230. Took 2.08 sec\n",
      "Epoch 38, Acc(train/val): 0.87/0.87, Loss(train/val) 0.89034/0.95058. Took 2.09 sec\n",
      "Epoch 39, Acc(train/val): 0.87/0.87, Loss(train/val) 0.87847/0.93694. Took 2.06 sec\n",
      "Epoch 40, Acc(train/val): 0.88/0.88, Loss(train/val) 0.86690/0.92404. Took 2.01 sec\n",
      "Epoch 41, Acc(train/val): 0.88/0.88, Loss(train/val) 0.85574/0.91261. Took 2.25 sec\n",
      "Epoch 42, Acc(train/val): 0.88/0.88, Loss(train/val) 0.84507/0.90312. Took 1.99 sec\n",
      "Epoch 43, Acc(train/val): 0.89/0.89, Loss(train/val) 0.83471/0.89281. Took 2.04 sec\n",
      "Epoch 44, Acc(train/val): 0.89/0.89, Loss(train/val) 0.82481/0.88154. Took 2.11 sec\n",
      "Epoch 45, Acc(train/val): 0.89/0.89, Loss(train/val) 0.81522/0.87235. Took 2.01 sec\n",
      "Epoch 46, Acc(train/val): 0.89/0.90, Loss(train/val) 0.80617/0.86265. Took 2.13 sec\n",
      "Epoch 47, Acc(train/val): 0.90/0.90, Loss(train/val) 0.79761/0.85538. Took 2.06 sec\n",
      "Epoch 48, Acc(train/val): 0.90/0.90, Loss(train/val) 0.78950/0.84630. Took 1.95 sec\n",
      "Epoch 49, Acc(train/val): 0.90/0.90, Loss(train/val) 0.78175/0.83949. Took 2.04 sec\n",
      "Epoch 50, Acc(train/val): 0.90/0.90, Loss(train/val) 0.77437/0.83302. Took 2.06 sec\n",
      "Epoch 51, Acc(train/val): 0.90/0.91, Loss(train/val) 0.76752/0.82639. Took 1.98 sec\n",
      "Epoch 52, Acc(train/val): 0.90/0.91, Loss(train/val) 0.76092/0.82305. Took 2.19 sec\n",
      "Epoch 53, Acc(train/val): 0.91/0.91, Loss(train/val) 0.75473/0.81900. Took 2.04 sec\n",
      "Epoch 54, Acc(train/val): 0.91/0.91, Loss(train/val) 0.74891/0.81574. Took 2.01 sec\n",
      "Epoch 55, Acc(train/val): 0.91/0.91, Loss(train/val) 0.74332/0.81167. Took 2.08 sec\n",
      "Epoch 56, Acc(train/val): 0.91/0.91, Loss(train/val) 0.73802/0.80917. Took 2.07 sec\n",
      "Epoch 57, Acc(train/val): 0.91/0.91, Loss(train/val) 0.73296/0.80327. Took 2.15 sec\n",
      "Epoch 58, Acc(train/val): 0.91/0.91, Loss(train/val) 0.72821/0.80232. Took 2.03 sec\n",
      "Epoch 59, Acc(train/val): 0.91/0.91, Loss(train/val) 0.72363/0.80092. Took 2.12 sec\n",
      "Epoch 60, Acc(train/val): 0.91/0.91, Loss(train/val) 0.71914/0.79931. Took 2.06 sec\n",
      "Epoch 61, Acc(train/val): 0.91/0.91, Loss(train/val) 0.71490/0.79535. Took 2.05 sec\n",
      "Epoch 62, Acc(train/val): 0.91/0.92, Loss(train/val) 0.71090/0.79573. Took 2.08 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 63, Acc(train/val): 0.92/0.92, Loss(train/val) 0.70714/0.79605. Took 2.06 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 64, Acc(train/val): 0.92/0.92, Loss(train/val) 0.70339/0.79720. Took 2.04 sec\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 65, Acc(train/val): 0.92/0.92, Loss(train/val) 0.69986/0.79862. Took 2.03 sec\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 66, Acc(train/val): 0.92/0.92, Loss(train/val) 0.69658/0.79915. Took 2.01 sec\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 67, Acc(train/val): 0.92/0.92, Loss(train/val) 0.69328/0.79578. Took 2.07 sec\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 68, Acc(train/val): 0.92/0.92, Loss(train/val) 0.69016/0.79528. Took 1.99 sec\n",
      "Epoch 69, Acc(train/val): 0.92/0.92, Loss(train/val) 0.68724/0.79835. Took 2.08 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 70, Acc(train/val): 0.92/0.92, Loss(train/val) 0.68434/0.79626. Took 2.05 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 71, Acc(train/val): 0.92/0.92, Loss(train/val) 0.68154/0.78826. Took 2.03 sec\n",
      "Epoch 72, Acc(train/val): 0.92/0.92, Loss(train/val) 0.67885/0.78822. Took 1.97 sec\n",
      "Epoch 73, Acc(train/val): 0.92/0.92, Loss(train/val) 0.67625/0.78976. Took 2.11 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 74, Acc(train/val): 0.92/0.92, Loss(train/val) 0.67387/0.79037. Took 1.99 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 75, Acc(train/val): 0.92/0.92, Loss(train/val) 0.67148/0.78310. Took 2.04 sec\n",
      "Epoch 76, Acc(train/val): 0.92/0.93, Loss(train/val) 0.66921/0.78168. Took 2.04 sec\n",
      "Epoch 77, Acc(train/val): 0.92/0.93, Loss(train/val) 0.66717/0.78608. Took 2.04 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 78, Acc(train/val): 0.92/0.93, Loss(train/val) 0.66500/0.78501. Took 2.06 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 79, Acc(train/val): 0.92/0.93, Loss(train/val) 0.66290/0.78349. Took 2.13 sec\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 80, Acc(train/val): 0.92/0.93, Loss(train/val) 0.66113/0.78514. Took 1.98 sec\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 81, Acc(train/val): 0.92/0.93, Loss(train/val) 0.65932/0.78562. Took 2.06 sec\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 82, Acc(train/val): 0.92/0.93, Loss(train/val) 0.65738/0.78636. Took 2.00 sec\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 83, Acc(train/val): 0.92/0.93, Loss(train/val) 0.65571/0.78642. Took 2.00 sec\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 84, Acc(train/val): 0.93/0.93, Loss(train/val) 0.65407/0.78764. Took 2.06 sec\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Epoch 85, Acc(train/val): 0.93/0.93, Loss(train/val) 0.65233/0.78813. Took 2.00 sec\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Epoch 86, Acc(train/val): 0.93/0.93, Loss(train/val) 0.65088/0.78479. Took 2.11 sec\n",
      "EarlyStopping counter: 10 out of 20\n",
      "Epoch 87, Acc(train/val): 0.93/0.93, Loss(train/val) 0.64941/0.78771. Took 2.00 sec\n",
      "EarlyStopping counter: 11 out of 20\n",
      "Epoch 88, Acc(train/val): 0.93/0.93, Loss(train/val) 0.64791/0.78246. Took 2.09 sec\n",
      "EarlyStopping counter: 12 out of 20\n",
      "Epoch 89, Acc(train/val): 0.93/0.93, Loss(train/val) 0.64652/0.78147. Took 2.14 sec\n",
      "Epoch 90, Acc(train/val): 0.93/0.93, Loss(train/val) 0.64507/0.78219. Took 2.10 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 91, Acc(train/val): 0.93/0.93, Loss(train/val) 0.64383/0.79045. Took 2.12 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 92, Acc(train/val): 0.93/0.93, Loss(train/val) 0.64263/0.78595. Took 2.07 sec\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 93, Acc(train/val): 0.93/0.93, Loss(train/val) 0.64120/0.79061. Took 2.05 sec\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 94, Acc(train/val): 0.93/0.93, Loss(train/val) 0.63988/0.79460. Took 2.33 sec\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 95, Acc(train/val): 0.93/0.93, Loss(train/val) 0.63869/0.79305. Took 2.01 sec\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 96, Acc(train/val): 0.93/0.93, Loss(train/val) 0.63747/0.78470. Took 2.24 sec\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 97, Acc(train/val): 0.93/0.93, Loss(train/val) 0.63630/0.78649. Took 2.08 sec\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Epoch 98, Acc(train/val): 0.93/0.93, Loss(train/val) 0.63510/0.78884. Took 1.98 sec\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Epoch 99, Acc(train/val): 0.93/0.93, Loss(train/val) 0.63404/0.78824. Took 2.05 sec\n",
      "EarlyStopping counter: 10 out of 20\n",
      "Epoch 100, Acc(train/val): 0.93/0.93, Loss(train/val) 0.63290/0.78892. Took 2.06 sec\n",
      "EarlyStopping counter: 11 out of 20\n",
      "Epoch 101, Acc(train/val): 0.93/0.93, Loss(train/val) 0.63187/0.78165. Took 2.00 sec\n",
      "EarlyStopping counter: 12 out of 20\n",
      "Epoch 102, Acc(train/val): 0.93/0.93, Loss(train/val) 0.63094/0.77964. Took 2.09 sec\n",
      "Epoch 103, Acc(train/val): 0.93/0.93, Loss(train/val) 0.63000/0.78590. Took 2.13 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 104, Acc(train/val): 0.93/0.93, Loss(train/val) 0.62903/0.78116. Took 2.12 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 105, Acc(train/val): 0.93/0.93, Loss(train/val) 0.62815/0.77998. Took 2.14 sec\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 106, Acc(train/val): 0.93/0.93, Loss(train/val) 0.62735/0.78432. Took 2.00 sec\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 107, Acc(train/val): 0.93/0.93, Loss(train/val) 0.62645/0.78358. Took 2.08 sec\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 108, Acc(train/val): 0.93/0.93, Loss(train/val) 0.62582/0.78576. Took 2.08 sec\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 109, Acc(train/val): 0.93/0.94, Loss(train/val) 0.62492/0.78729. Took 2.04 sec\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 110, Acc(train/val): 0.93/0.94, Loss(train/val) 0.62407/0.78105. Took 2.04 sec\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Epoch 111, Acc(train/val): 0.93/0.94, Loss(train/val) 0.62327/0.77984. Took 2.06 sec\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Epoch 112, Acc(train/val): 0.93/0.94, Loss(train/val) 0.62268/0.77614. Took 2.05 sec\n",
      "Epoch 113, Acc(train/val): 0.93/0.94, Loss(train/val) 0.62196/0.77790. Took 2.01 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 114, Acc(train/val): 0.93/0.94, Loss(train/val) 0.62131/0.78397. Took 2.07 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 115, Acc(train/val): 0.93/0.94, Loss(train/val) 0.62069/0.78005. Took 2.12 sec\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 116, Acc(train/val): 0.93/0.94, Loss(train/val) 0.61982/0.77832. Took 2.18 sec\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 117, Acc(train/val): 0.93/0.94, Loss(train/val) 0.61930/0.77961. Took 2.02 sec\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 118, Acc(train/val): 0.93/0.94, Loss(train/val) 0.61866/0.77991. Took 1.99 sec\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 119, Acc(train/val): 0.93/0.94, Loss(train/val) 0.61810/0.77815. Took 2.02 sec\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 120, Acc(train/val): 0.93/0.94, Loss(train/val) 0.61745/0.77477. Took 2.02 sec\n",
      "Epoch 121, Acc(train/val): 0.93/0.94, Loss(train/val) 0.61692/0.77904. Took 2.01 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 122, Acc(train/val): 0.93/0.94, Loss(train/val) 0.61628/0.77741. Took 2.04 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 123, Acc(train/val): 0.93/0.94, Loss(train/val) 0.61578/0.77376. Took 2.16 sec\n",
      "Epoch 124, Acc(train/val): 0.93/0.94, Loss(train/val) 0.61519/0.77912. Took 2.06 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 125, Acc(train/val): 0.93/0.94, Loss(train/val) 0.61470/0.77571. Took 2.01 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 126, Acc(train/val): 0.93/0.94, Loss(train/val) 0.61411/0.77448. Took 2.04 sec\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 127, Acc(train/val): 0.93/0.94, Loss(train/val) 0.61361/0.77223. Took 2.03 sec\n",
      "Epoch 128, Acc(train/val): 0.93/0.94, Loss(train/val) 0.61306/0.77423. Took 2.02 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 129, Acc(train/val): 0.93/0.94, Loss(train/val) 0.61243/0.77744. Took 2.01 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 130, Acc(train/val): 0.93/0.94, Loss(train/val) 0.61205/0.77085. Took 2.02 sec\n",
      "Epoch 131, Acc(train/val): 0.93/0.94, Loss(train/val) 0.61151/0.77009. Took 2.08 sec\n",
      "Epoch 132, Acc(train/val): 0.93/0.94, Loss(train/val) 0.61118/0.77387. Took 2.29 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 133, Acc(train/val): 0.93/0.94, Loss(train/val) 0.61068/0.77458. Took 2.06 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 134, Acc(train/val): 0.93/0.94, Loss(train/val) 0.61018/0.77582. Took 2.14 sec\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 135, Acc(train/val): 0.93/0.94, Loss(train/val) 0.60975/0.77229. Took 2.20 sec\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 136, Acc(train/val): 0.93/0.94, Loss(train/val) 0.60922/0.77106. Took 2.06 sec\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 137, Acc(train/val): 0.93/0.94, Loss(train/val) 0.60880/0.76704. Took 2.05 sec\n",
      "Epoch 138, Acc(train/val): 0.93/0.94, Loss(train/val) 0.60835/0.77072. Took 2.00 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 139, Acc(train/val): 0.93/0.94, Loss(train/val) 0.60791/0.76736. Took 2.06 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 140, Acc(train/val): 0.93/0.94, Loss(train/val) 0.60751/0.76560. Took 2.01 sec\n",
      "Epoch 141, Acc(train/val): 0.93/0.94, Loss(train/val) 0.60709/0.76546. Took 2.12 sec\n",
      "Epoch 142, Acc(train/val): 0.93/0.94, Loss(train/val) 0.60668/0.76882. Took 2.18 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 143, Acc(train/val): 0.93/0.94, Loss(train/val) 0.60629/0.76702. Took 2.07 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 144, Acc(train/val): 0.93/0.94, Loss(train/val) 0.60587/0.76465. Took 2.15 sec\n",
      "Epoch 145, Acc(train/val): 0.93/0.94, Loss(train/val) 0.60548/0.76434. Took 2.01 sec\n",
      "Epoch 146, Acc(train/val): 0.93/0.94, Loss(train/val) 0.60511/0.76972. Took 2.06 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 147, Acc(train/val): 0.93/0.94, Loss(train/val) 0.60486/0.76893. Took 2.01 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 148, Acc(train/val): 0.93/0.94, Loss(train/val) 0.60434/0.77066. Took 2.04 sec\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 149, Acc(train/val): 0.93/0.94, Loss(train/val) 0.60406/0.77329. Took 2.02 sec\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 150, Acc(train/val): 0.93/0.94, Loss(train/val) 0.60351/0.77066. Took 2.04 sec\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 151, Acc(train/val): 0.93/0.94, Loss(train/val) 0.60311/0.76642. Took 1.98 sec\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 152, Acc(train/val): 0.93/0.94, Loss(train/val) 0.60260/0.76876. Took 2.11 sec\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 153, Acc(train/val): 0.93/0.94, Loss(train/val) 0.60243/0.76490. Took 2.00 sec\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Epoch 154, Acc(train/val): 0.94/0.94, Loss(train/val) 0.60196/0.76398. Took 1.99 sec\n",
      "Epoch 155, Acc(train/val): 0.93/0.94, Loss(train/val) 0.60166/0.76069. Took 1.99 sec\n",
      "Epoch 156, Acc(train/val): 0.94/0.94, Loss(train/val) 0.60129/0.76188. Took 2.02 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 157, Acc(train/val): 0.94/0.94, Loss(train/val) 0.60089/0.75931. Took 2.09 sec\n",
      "Epoch 158, Acc(train/val): 0.94/0.94, Loss(train/val) 0.60056/0.76232. Took 2.11 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 159, Acc(train/val): 0.94/0.94, Loss(train/val) 0.60014/0.76199. Took 2.06 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 160, Acc(train/val): 0.94/0.94, Loss(train/val) 0.59980/0.75938. Took 2.13 sec\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 161, Acc(train/val): 0.94/0.94, Loss(train/val) 0.59941/0.76592. Took 1.99 sec\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 162, Acc(train/val): 0.94/0.94, Loss(train/val) 0.59909/0.75933. Took 2.14 sec\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 163, Acc(train/val): 0.94/0.94, Loss(train/val) 0.59867/0.76547. Took 2.58 sec\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 164, Acc(train/val): 0.94/0.94, Loss(train/val) 0.59848/0.76190. Took 3.05 sec\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 165, Acc(train/val): 0.94/0.94, Loss(train/val) 0.59807/0.75964. Took 2.08 sec\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Epoch 166, Acc(train/val): 0.94/0.94, Loss(train/val) 0.59769/0.75967. Took 2.02 sec\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Epoch 167, Acc(train/val): 0.94/0.94, Loss(train/val) 0.59740/0.75545. Took 2.18 sec\n",
      "Epoch 168, Acc(train/val): 0.94/0.94, Loss(train/val) 0.59714/0.75835. Took 2.21 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 169, Acc(train/val): 0.94/0.94, Loss(train/val) 0.59663/0.75878. Took 2.11 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 170, Acc(train/val): 0.94/0.94, Loss(train/val) 0.59648/0.76139. Took 1.99 sec\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 171, Acc(train/val): 0.94/0.94, Loss(train/val) 0.59619/0.75765. Took 2.01 sec\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 172, Acc(train/val): 0.94/0.94, Loss(train/val) 0.59567/0.75633. Took 2.16 sec\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 173, Acc(train/val): 0.94/0.94, Loss(train/val) 0.59536/0.75190. Took 2.04 sec\n",
      "Epoch 174, Acc(train/val): 0.94/0.94, Loss(train/val) 0.59511/0.75265. Took 2.04 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 175, Acc(train/val): 0.94/0.94, Loss(train/val) 0.59474/0.75274. Took 2.13 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 176, Acc(train/val): 0.94/0.94, Loss(train/val) 0.59443/0.75165. Took 2.15 sec\n",
      "Epoch 177, Acc(train/val): 0.94/0.94, Loss(train/val) 0.59411/0.74835. Took 2.05 sec\n",
      "Epoch 178, Acc(train/val): 0.94/0.94, Loss(train/val) 0.59379/0.75336. Took 2.21 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 179, Acc(train/val): 0.94/0.94, Loss(train/val) 0.59365/0.75735. Took 1.98 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 180, Acc(train/val): 0.94/0.94, Loss(train/val) 0.59314/0.74860. Took 2.17 sec\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 181, Acc(train/val): 0.94/0.94, Loss(train/val) 0.59293/0.75752. Took 2.09 sec\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 182, Acc(train/val): 0.94/0.94, Loss(train/val) 0.59245/0.75131. Took 2.06 sec\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 183, Acc(train/val): 0.94/0.94, Loss(train/val) 0.59221/0.74995. Took 2.17 sec\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 184, Acc(train/val): 0.94/0.94, Loss(train/val) 0.59193/0.74886. Took 2.06 sec\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 185, Acc(train/val): 0.94/0.94, Loss(train/val) 0.59173/0.74898. Took 2.06 sec\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Epoch 186, Acc(train/val): 0.94/0.94, Loss(train/val) 0.59134/0.74796. Took 1.99 sec\n",
      "Epoch 187, Acc(train/val): 0.94/0.94, Loss(train/val) 0.59108/0.75211. Took 2.06 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 188, Acc(train/val): 0.94/0.94, Loss(train/val) 0.59074/0.74939. Took 2.02 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 189, Acc(train/val): 0.94/0.94, Loss(train/val) 0.59033/0.74969. Took 2.21 sec\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 190, Acc(train/val): 0.94/0.94, Loss(train/val) 0.58997/0.75243. Took 2.06 sec\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 191, Acc(train/val): 0.94/0.94, Loss(train/val) 0.58969/0.74846. Took 2.06 sec\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 192, Acc(train/val): 0.94/0.94, Loss(train/val) 0.58944/0.74994. Took 2.13 sec\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 193, Acc(train/val): 0.94/0.94, Loss(train/val) 0.58917/0.75140. Took 2.10 sec\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 194, Acc(train/val): 0.94/0.94, Loss(train/val) 0.58877/0.74970. Took 2.04 sec\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Epoch 195, Acc(train/val): 0.94/0.94, Loss(train/val) 0.58856/0.74996. Took 2.12 sec\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Epoch 196, Acc(train/val): 0.94/0.94, Loss(train/val) 0.58823/0.74766. Took 2.24 sec\n",
      "Epoch 197, Acc(train/val): 0.94/0.94, Loss(train/val) 0.58787/0.74871. Took 2.06 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 198, Acc(train/val): 0.94/0.94, Loss(train/val) 0.58773/0.75437. Took 2.10 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 199, Acc(train/val): 0.94/0.94, Loss(train/val) 0.58733/0.75294. Took 2.01 sec\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 200, Acc(train/val): 0.94/0.94, Loss(train/val) 0.58698/0.74656. Took 2.07 sec\n",
      "Epoch 201, Acc(train/val): 0.94/0.94, Loss(train/val) 0.58682/0.75244. Took 2.07 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 202, Acc(train/val): 0.94/0.94, Loss(train/val) 0.58646/0.74782. Took 2.10 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 203, Acc(train/val): 0.94/0.94, Loss(train/val) 0.58632/0.74549. Took 2.18 sec\n",
      "Epoch 204, Acc(train/val): 0.94/0.94, Loss(train/val) 0.58598/0.74214. Took 1.98 sec\n",
      "Epoch 205, Acc(train/val): 0.94/0.94, Loss(train/val) 0.58581/0.74730. Took 2.06 sec\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 206, Acc(train/val): 0.94/0.94, Loss(train/val) 0.58556/0.74756. Took 2.07 sec\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 207, Acc(train/val): 0.94/0.94, Loss(train/val) 0.58518/0.74890. Took 2.02 sec\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 208, Acc(train/val): 0.94/0.94, Loss(train/val) 0.58491/0.74825. Took 2.14 sec\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 209, Acc(train/val): 0.94/0.94, Loss(train/val) 0.58456/0.74872. Took 2.07 sec\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 210, Acc(train/val): 0.94/0.94, Loss(train/val) 0.58429/0.75007. Took 2.12 sec\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 211, Acc(train/val): 0.94/0.94, Loss(train/val) 0.58410/0.75088. Took 2.01 sec\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 212, Acc(train/val): 0.94/0.94, Loss(train/val) 0.58377/0.75306. Took 2.05 sec\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Epoch 213, Acc(train/val): 0.94/0.94, Loss(train/val) 0.58350/0.75492. Took 2.09 sec\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Epoch 214, Acc(train/val): 0.94/0.94, Loss(train/val) 0.58333/0.75963. Took 2.03 sec\n",
      "EarlyStopping counter: 10 out of 20\n",
      "Epoch 215, Acc(train/val): 0.94/0.94, Loss(train/val) 0.58313/0.75727. Took 2.03 sec\n",
      "EarlyStopping counter: 11 out of 20\n",
      "Epoch 216, Acc(train/val): 0.94/0.94, Loss(train/val) 0.58284/0.75533. Took 2.09 sec\n",
      "EarlyStopping counter: 12 out of 20\n",
      "Epoch 217, Acc(train/val): 0.94/0.94, Loss(train/val) 0.58262/0.75397. Took 2.12 sec\n",
      "EarlyStopping counter: 13 out of 20\n",
      "Epoch 218, Acc(train/val): 0.94/0.94, Loss(train/val) 0.58237/0.75478. Took 2.09 sec\n",
      "EarlyStopping counter: 14 out of 20\n",
      "Epoch 219, Acc(train/val): 0.94/0.94, Loss(train/val) 0.58207/0.75306. Took 2.07 sec\n",
      "EarlyStopping counter: 15 out of 20\n",
      "Epoch 220, Acc(train/val): 0.94/0.94, Loss(train/val) 0.58167/0.75586. Took 2.01 sec\n",
      "EarlyStopping counter: 16 out of 20\n",
      "Epoch 221, Acc(train/val): 0.94/0.94, Loss(train/val) 0.58139/0.75096. Took 2.11 sec\n",
      "EarlyStopping counter: 17 out of 20\n",
      "Epoch 222, Acc(train/val): 0.94/0.94, Loss(train/val) 0.58109/0.75811. Took 2.09 sec\n",
      "EarlyStopping counter: 18 out of 20\n",
      "Epoch 223, Acc(train/val): 0.94/0.94, Loss(train/val) 0.58081/0.76088. Took 1.97 sec\n",
      "EarlyStopping counter: 19 out of 20\n",
      "Epoch 224, Acc(train/val): 0.94/0.94, Loss(train/val) 0.58062/0.75817. Took 2.03 sec\n",
      "EarlyStopping counter: 20 out of 20\n",
      "Early stopping\n",
      "*** auc score : 0.93368 ***\n",
      "0.9336776590968169,0.9618503029785781,0.9827603429779,0.9618503029785781,0.9706513592265015,11158,383,64,112\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ====== Random Seed Initialization ====== #\n",
    "seed = 666\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args(\"\")\n",
    "args.exp_name = \"exp1_lr\"\n",
    "args.device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "# args.device = 'cpu'\n",
    "args.batch_size = 128\n",
    "\n",
    "# ====== Model Capacity ===== #\n",
    "args.input_dim = partition['train'].X.shape[1]\n",
    "args.hid_dim = 50\n",
    "args.n_layers = 2\n",
    "\n",
    "# ====== Regularization ======= #\n",
    "args.l2 = 0.00001\n",
    "args.dropout = 0.0\n",
    "args.use_bn = True\n",
    "\n",
    "# ====== Optimizer & Training ====== #\n",
    "args.optim = 'Adam' #'RMSprop' #SGD, RMSprop, ADAM...\n",
    "args.lr = 0.0001\n",
    "args.epoch = 1000\n",
    "\n",
    "\n",
    "# ====== Experiment Variable ====== #\n",
    "name_var1 = 'lr'\n",
    "name_var2 = 'n_layers'\n",
    "list_var1 = [0.001, 0.0001, 0.00001]\n",
    "list_var2 = [1,2,3]\n",
    "\n",
    "for var1 in list_var1:\n",
    "    for var2 in list_var2:\n",
    "        setattr(args, name_var1, var1)\n",
    "        setattr(args, name_var2, var2)\n",
    "        print(args)\n",
    "                \n",
    "        setting, result, y_true, prediction, e = experiment(partition, deepcopy(args))\n",
    "\n",
    "        y_true = y_true.cpu().detach().numpy()\n",
    "        prediction = prediction.cpu().detach().numpy()\n",
    "\n",
    "        auc_score = roc_auc_score(y_true, prediction)\n",
    "        print('*** auc score : {:.5f} ***'.format(auc_score))\n",
    "                    \n",
    "        y_pred = np.where(prediction >= 0.5, 1, 0)\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred,average='weighted') # None, 'micro', 'macro', 'weighted'\n",
    "        recall = recall_score(y_true, y_pred,average='weighted')\n",
    "        F1 = f1_score(y_true, y_pred,average='weighted')\n",
    "                    \n",
    "        tt, tf, ft, ff = get_clf_eval(y_true, y_pred)\n",
    "                    \n",
    "        print(f'{auc_score},{accuracy},{precision},{recall},{F1},{tt},{tf},{ft},{ff}')\n",
    "                    \n",
    "        save_exp_result(setting, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Sepsis_with_LSTM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
